{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Computer Vision Algorithm for Tracking Planarian Motion\n",
    "developed by Hokin Deng xueqiandeng@yahoo.com"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Dependencies and Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import packages and make sure of the python technicality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.11.4 (main, Jul  5 2023, 08:41:25) [Clang 14.0.6 ]\n",
      "Python Executable: /Users/billdeng/anaconda3/envs/unlearning_Version1/bin/python\n",
      "Python Path: ['/Users/billdeng/PycharmProjects/unicellular', '/Users/billdeng/PycharmProjects/unicellular', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python311.zip', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11/lib-dynload', '', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "print(\"Python Version:\", sys.version)\n",
    "print(\"Python Executable:\", sys.executable)\n",
    "print(\"Python Path:\", sys.path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(threshold=50)\n",
    "import queue\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The video data should be named as \"sample.avi\" and put in the folder as the notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open a video file (replace 'sample.avi' with the path)\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "\n",
    "# Check if the video file was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display the video if want to have a look at it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#cv2.startWindowThread()\n",
    "# Loop to read and display frames\n",
    "#while True:\n",
    "    # Read a frame from the video\n",
    "#    ret, frame = cap.read()\n",
    "    # If the video has ended, break out of the loop\n",
    "#    if not ret:\n",
    "#        break\n",
    "    # Display the frame in a window\n",
    "#    cv2.imshow('Video', frame)\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "#    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#        break\n",
    "\n",
    "# Release the video capture object and close the window"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, get basic properties about our video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Count: 1202\n",
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Frame Rate: 10.0 frames per second\n",
      "Video Duration: 120.20 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get basic video properties\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "video_duration_sec = frame_count / frame_rate if frame_rate > 0 else 0\n",
    "\n",
    "# Print the video properties\n",
    "print(f\"Frame Count: {frame_count}\")\n",
    "print(f\"Frame Width: {frame_width}\")\n",
    "print(f\"Frame Height: {frame_height}\")\n",
    "print(f\"Frame Rate: {frame_rate} frames per second\")\n",
    "print(f\"Video Duration: {video_duration_sec:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret <class 'bool'>\n",
      "frame <class 'numpy.ndarray'>\n",
      "ret True\n",
      "frame [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "example_ret, example_frame = cap.read()\n",
    "print( 'ret', type(example_ret))\n",
    "print( 'frame', type(example_frame))\n",
    "print('ret', example_ret)\n",
    "print('frame', example_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# frame_number = 100  # The frame you want to access\n",
    "# Set the video position to the desired frame\n",
    "# cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)\n",
    "# Read the frame\n",
    "# ret, frame = cap.read()\n",
    "# if ret:\n",
    "    # Process the frame\n",
    "#     cv2.imshow('Frame 100', frame)\n",
    "#    cv2.waitKey(0)  # Wait for a key press to close the image window\n",
    "# else:\n",
    "#    print(\"Error: Unable to read the frame\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspect function for a frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def inspect_frame_from_video(cap_for_here, frame_number):\n",
    "    \"\"\"\n",
    "    Inspects a specific frame in a video.\n",
    "\n",
    "    :param cap_for_here: video reference\n",
    "    :param frame_number: The frame number to inspect (1-based index).\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Open the video file\n",
    "    if not cap_for_here.isOpened():\n",
    "        print(\"Error: Unable to open video file\")\n",
    "        return\n",
    "    # Check if the frame number is valid\n",
    "    total_frames = cap_for_here.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if frame_number < 1 or frame_number > total_frames:\n",
    "        print(f\"Frame number should be between 1 and {int(total_frames)}\")\n",
    "        return\n",
    "    # Set the video position to the desired frame (0-based index for frame_number)\n",
    "    cap_for_here.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)\n",
    "    # Read the frame\n",
    "    ret_temp, frame_temp = cap_for_here.read()\n",
    "    if ret_temp:\n",
    "        # Display the frame\n",
    "        # cv2.imshow(f'Frame {frame_number}', frame)\n",
    "        # cv2.waitKey(0)  # Wait for a key press to close the image window\n",
    "        # cv2.destroyAllWindows()\n",
    "        frame_h, frame_w = frame_temp.shape[:2]\n",
    "        print(f\"Frame Width: {frame_h}\")\n",
    "        print(f\"Frame Height: {frame_w}\")\n",
    "        # Color Channels\n",
    "        channels = frame_temp.shape[2] if len(frame_temp.shape) == 3 else 1\n",
    "        print(f\"Color Channels: {channels}\")\n",
    "        # Data Type\n",
    "        data_type = frame_temp.dtype\n",
    "        print(f\"Data Type: {data_type}\")\n",
    "        # Aspect Ratio\n",
    "        aspect_ratio = frame_w / frame_h\n",
    "        print(f\"Aspect Ratio: {aspect_ratio}\")\n",
    "        # Resolution (assuming a standard display resolution of 96 PPI)\n",
    "        # Color Space (assuming default BGR)\n",
    "        color_space = \"BGR\" if channels == 3 else \"Grayscale\"\n",
    "        print(f\"Color Space: {color_space}\")\n",
    "        # Histogram for each channel\n",
    "        if channels > 1:\n",
    "            for i, col in enumerate(['Blue', 'Green', 'Red']):\n",
    "                hist = cv2.calcHist([frame_temp], [i], None, [256], [0, 256])\n",
    "                print(f\"Histogram for {col} channel: {np.array(hist).flatten()}\")\n",
    "        else:\n",
    "            hist = cv2.calcHist([frame_temp], [0], None, [256], [0, 256])\n",
    "            print(f\"Histogram for Grayscale: {np.array(hist).flatten()}\")\n",
    "    else:\n",
    "        print(\"Error: Unable to read the frame\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def inspect_given_a_frame(this_frame):\n",
    "    frame_h, frame_w = this_frame.shape[:2]\n",
    "    print(f\"Frame Width: {frame_h}\")\n",
    "    print(f\"Frame Height: {frame_w}\")\n",
    "    channels = this_frame.shape[2] if len(this_frame.shape) == 3 else 1\n",
    "    print(f\"Color Channels: {channels}\")\n",
    "    data_type = this_frame.dtype\n",
    "    print(f\"Data Type: {data_type}\")\n",
    "    aspect_ratio = frame_w / frame_h\n",
    "    print(f\"Aspect Ratio: {aspect_ratio}\")\n",
    "    color_space = \"BGR\" if channels == 3 else \"Grayscale\"\n",
    "    print(f\"Color Space: {color_space}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Color Channels: 3\n",
      "Data Type: uint8\n",
      "Aspect Ratio: 1.0\n",
      "Color Space: BGR\n",
      "Histogram for Blue channel: [      0.       0.       0. ...   31073.   57326. 3775011.]\n",
      "Histogram for Green channel: [      0.       0.       0. ...   31073.   57326. 3775011.]\n",
      "Histogram for Red channel: [      0.       0.       0. ...   31073.   57326. 3775011.]\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "video_file = 'sample.avi'\n",
    "frame_to_inspect = 100  # Adjust the frame number as needed\n",
    "inspect_frame_from_video(cap, frame_to_inspect)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Color Channels: 3\n",
      "Data Type: uint8\n",
      "Aspect Ratio: 1.0\n",
      "Color Space: BGR\n"
     ]
    }
   ],
   "source": [
    "ret, frame_for_use = cap.read()\n",
    "inspect_given_a_frame(frame_for_use)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Processing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Background subtraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('background_remove.avi', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "while True:\n",
    "    i += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    fgMask = backSub.apply(frame)\n",
    "    out.write(fgMask)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spatial Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "cap = cv2.VideoCapture('background_remove.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('background_remove_spatial_smoothed.avi', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "while True:\n",
    "    i += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    out.write(blurred_frame)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Temporal Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('background_remove_spatial_smooth.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') # You can also use 'XVID'\n",
    "out = cv2.VideoWriter('b_r_s_s_t_s.avi', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "buffer_size = 5\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_buffer.append(frame)\n",
    "    if len(frame_buffer) > buffer_size:\n",
    "        frame_buffer.pop(0)\n",
    "    # Temporal smoothing (average of frames in buffer)\n",
    "    temp_smoothed = np.mean(frame_buffer, axis=0).astype(np.uint8)\n",
    "    # Write frame to video\n",
    "    out.write(temp_smoothed)\n",
    "    # Break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "do everything all at once"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # You can also use 'XVID'\n",
    "out = cv2.VideoWriter('pre_dense.mp4', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "# Background subtractor\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "# Buffer for temporal smoothing\n",
    "buffer_size = 5\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Background subtraction\n",
    "    fgMask = backSub.apply(frame)\n",
    "    # Spatial smoothing (Gaussian blur)\n",
    "    blurred = cv2.GaussianBlur(fgMask, (5, 5), 0)\n",
    "    # Add frame to buffer for temporal smoothing\n",
    "    frame_buffer.append(blurred)\n",
    "    if len(frame_buffer) > buffer_size:\n",
    "        frame_buffer.pop(0)\n",
    "    # Temporal smoothing (average of frames in buffer)\n",
    "    temp_smoothed = np.mean(frame_buffer, axis=0).astype(np.uint8)\n",
    "    # Write frame to video\n",
    "    out.write(temp_smoothed)\n",
    "    # Display result\n",
    "    # cv2.imshow('Frame', frame)\n",
    "    # cv2.imshow('FG Mask', fgMask)\n",
    "    # cv2.imshow('Blurred', blurred)\n",
    "    # cv2.imshow('Temporally Smoothed', temp_smoothed)\n",
    "    # Break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dense opti flow\n",
    "this takes a very very long time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"pre_dense.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('dense_opti_flow_v2.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "ret, first_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error reading first frame\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "mask = np.zeros_like(first_frame)\n",
    "mask[..., 1] = 255\n",
    "i = 0\n",
    "while True:\n",
    "    i += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    out.write(rgb)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    prev_gray = gray\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "segment each worm in dense optical flow video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('dense_opti_flow_v2.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('dense_opt_segmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 3  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(motion_mask), connectivity=8)\n",
    "    min_area = 50  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # Display the result\n",
    "    out.write(frame2)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "segment each worm without optical flow processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('pre_dense.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('predense_degmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 3  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(motion_mask), connectivity=8)\n",
    "    min_area = 50  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # Display the result\n",
    "    out.write(frame2)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a function for video to image and use it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to extract and save frames from a video file\n",
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/raw_images'\n",
    "video_path = current_location + '/sample.avi'\n",
    "\n",
    "def video2image(video_path, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Load the video\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Initialize frame count\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through video frames\n",
    "    while True:\n",
    "        # Read a frame\n",
    "        success, frame = video.read()\n",
    "        # Break if no frame is read (end of video)\n",
    "        if not success:\n",
    "            break\n",
    "        # Save the frame as an image\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"frame_{count}.jpg\"), frame)\n",
    "        # Increment frame count\n",
    "        count += 1\n",
    "\n",
    "    # Release the video object\n",
    "    video.release()\n",
    "\n",
    "    return count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the video into images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frame_count = video2image(video_path, output_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Design a crop function that remove the dish"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def crop_circle(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Create a mask with the same dimensions as the image\n",
    "    mask = np.zeros_like(image)\n",
    "    rows, cols, _ = mask.shape\n",
    "    # Compute the center and radius of the circle\n",
    "    center = (cols // 2, rows // 2)\n",
    "    radius = min(center[0], center[1], rows - center[1], cols - center[0])\n",
    "    # Draw the circular mask\n",
    "    cv2.circle(mask, center, radius, (255, 255, 255), -1)\n",
    "    # Apply the mask\n",
    "    circular_image = cv2.bitwise_and(image, mask)\n",
    "    # Optionally, you can remove the black background\n",
    "    masked_data = cv2.cvtColor(circular_image, cv2.COLOR_BGR2BGRA)\n",
    "    masked_data[mask == 0] = [0, 0, 0, 0]\n",
    "    # Save or display the result\n",
    "    cv2.imwrite('circular_image.png', masked_data)\n",
    "    # cv2.imshow('Circular Image', masked_data)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "threshold the original video and set the threshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thresh = 127"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "apply to original video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('threshold_original.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "# Read until video is completed\n",
    "j = 0\n",
    "while cap.isOpened():\n",
    "    j += 1\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Convert to grayscale\n",
    "        # Apply threshold for each channel\n",
    "        _, red_channel = cv2.threshold(frame[:,:,0], thresh, 255, cv2.THRESH_BINARY)\n",
    "        _, green_channel = cv2.threshold(frame[:,:,1], thresh, 255, cv2.THRESH_BINARY)\n",
    "        _, blue_channel = cv2.threshold(frame[:,:,2], thresh, 255, cv2.THRESH_BINARY)\n",
    "    # Combine the channels back\n",
    "        thresh_frame = cv2.merge([red_channel, green_channel, blue_channel])\n",
    "        # Display the resulting frame\n",
    "        out.write(thresh_frame)\n",
    "        # Press Q on keyboard to exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        print(f'\\rProgress: {j}', end='')\n",
    "    else:\n",
    "        break\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "apply erode and dilate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('pre_dense.mp4')\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('pre_dense_erode_dilate.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    # Read each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Apply erosion and then dilation\n",
    "    eroded_frame = cv2.erode(frame, kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, kernel, iterations=1)\n",
    "    # Display the processed frame\n",
    "    out.write(dilated_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    # Break the loop with a key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "motion segmentation using connectivity after erode and dilate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('pre_dense_erode_dilate_segmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    cv2.imshow('Segmented Frame', motion_mask)\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(motion_mask), connectivity=8)\n",
    "    min_area = 300  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Display the result\n",
    "    out.write(frame2)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "erode and dilate also motion mask, save motion mask actually"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('motion_mask_segmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    save_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Display the result\n",
    "    rgb_frame = cv2.cvtColor(save_frame, cv2.COLOR_GRAY2RGB)\n",
    "    # inspect_given_a_frame(frame2)\n",
    "    # inspect_given_a_frame(rgb_frame)\n",
    "    out.write(save_frame)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('motion_mask_segmented_v2.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    t_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Display the result\n",
    "    rgb_frame = cv2.cvtColor(t_frame, cv2.COLOR_GRAY2RGB)\n",
    "    # inspect_given_a_frame(frame2)\n",
    "    # inspect_given_a_frame(rgb_frame)\n",
    "    # inspect_given_a_frame(rgb_frame)\n",
    "    out.write(rgb_frame)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dilate even more for segmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overlay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_cap = cv2.VideoCapture('sample.avi')\n",
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('overlay.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "not_useful, ori_frame = original_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    not_useful, ori_frame = original_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    out.write(ori_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize Paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/worm_segmentation'\n",
    "video_path = current_location + '/sample.avi'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize input videos and output videos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "motion_mask_cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "original_video_cap = cv2.VideoCapture('sample.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "f_worm_1 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_2 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_3 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_4 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_5 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_6 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_7 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_8 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_9 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_10 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "worm_1_out = cv2.VideoWriter(output_folder + '/worm_1_out.mp4', f_worm_1, frame_rate, (frame_width, frame_height), True)\n",
    "worm_2_out = cv2.VideoWriter(output_folder + '/worm_2_out.mp4', f_worm_2, frame_rate, (frame_width, frame_height), True)\n",
    "worm_3_out = cv2.VideoWriter(output_folder + '/worm_3_out.mp4', f_worm_3, frame_rate, (frame_width, frame_height), True)\n",
    "worm_4_out = cv2.VideoWriter(output_folder + '/worm_4_out.mp4', f_worm_4, frame_rate, (frame_width, frame_height), True)\n",
    "worm_5_out = cv2.VideoWriter(output_folder + '/worm_5_out.mp4', f_worm_5, frame_rate, (frame_width, frame_height), True)\n",
    "worm_6_out = cv2.VideoWriter(output_folder + '/worm_6_out.mp4', f_worm_6, frame_rate, (frame_width, frame_height), True)\n",
    "worm_7_out = cv2.VideoWriter(output_folder + '/worm_7_out.mp4', f_worm_7, frame_rate, (frame_width, frame_height), True)\n",
    "worm_8_out = cv2.VideoWriter(output_folder + '/worm_8_out.mp4', f_worm_8, frame_rate, (frame_width, frame_height), True)\n",
    "worm_9_out = cv2.VideoWriter(output_folder + '/worm_9_out.mp4', f_worm_9, frame_rate, (frame_width, frame_height), True)\n",
    "worm_10_out = cv2.VideoWriter(output_folder + '/worm_10_out.mp4', f_worm_10, frame_rate, (frame_width, frame_height), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "clean up make sure all number is good"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_it_number = 0\n",
    "\n",
    "if not motion_mask_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(motion_mask_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the motion mask: {total_it_number}\")\n",
    "\n",
    "if not original_video_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(original_video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the original video: {total_it_number}\")\n",
    "\n",
    "print(f\"to process the video need to iterate over: {total_it_number}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the first motion\n",
    "ret, motion_frame_init = motion_mask_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the motion ask\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"motion frame read\")\n",
    "print(\"Shape of Frame\", motion_frame_init.shape)\n",
    "print(\"First Row\", motion_frame_init[:,1])\n",
    "previous_motion_frame = cv2.cvtColor(motion_frame_init, cv2.COLOR_BGR2GRAY)\n",
    "inspect_given_a_frame(previous_motion_frame)\n",
    "print(\"Shape of Frame\", previous_motion_frame.shape)\n",
    "print(\"First Row\", previous_motion_frame[:,1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pilot the code a bit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for j in range(total_it_number):\n",
    "    ret, temporal_motion_frame = motion_mask_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    current_motion_frame = cv2.cvtColor(temporal_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    print('Number of labels', num_labels, '\\n')\n",
    "    print('labels', labels, '\\n')\n",
    "    print('stats', stats, '\\n')\n",
    "    print('centroids', centroids, '\\n')\n",
    "    min_area = 5000\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imshow('Segmented Frame', rgb_frame)\n",
    "    out.write(rgb_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tye = num_labels, labels, stats, centroids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_la, la, st, cent = tye"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(num_la))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(centroids[2][0])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(st)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(st[1][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(centroids.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats_2 = stats\n",
    "print(stats_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hum = stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hum = np.append(hum, stats_2)\n",
    "print(hum)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "make an object array and work with that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hum = np.array(None,dtype=object)\n",
    "print(hum)\n",
    "hum = np.append(hum, stats_2)\n",
    "print(hum)\n",
    "hum = np.append(hum, stats_2)\n",
    "print(hum)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tye[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tye[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tye[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tye[3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Construction of a Worm Object\n",
    "## the idea is that, to make a worm object, this object should be able to take each frame as input,\n",
    "## find the motion mask to correspond to the worm, and append to the worm object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Worm:\n",
    "    def __init__(self, worm_index, original_cap, label_history, stats_history, centroid_history, another_variable_in_case=None):\n",
    "        self.worm_index = worm_index\n",
    "        self.original_cap = original_cap\n",
    "        self.label_history = label_history\n",
    "        self.stats_history = stats_history\n",
    "        self.centroid_history = centroid_history\n",
    "        self.another_variable_in_case = another_variable_in_case\n",
    "\n",
    "    def display_info(self):\n",
    "        info = f\"worn index: {self.worm_index}, video_cap: {self.original_cap}, label_history: {self.label_history}, stats_history: {self.stats_history}, centroid_history: {self.centroid_history}\"\n",
    "        print(info)\n",
    "\n",
    "    def update_another_variable(self, another_variable_in_case):\n",
    "        \"\"\"Update the car's mileage.\"\"\"\n",
    "        if another_variable_in_case >= self.another_variable_in_case:\n",
    "            self.another_variable_in_case = another_variable_in_case\n",
    "        else:\n",
    "            print(\"Error: another_variable_in_case cannot be reduced.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pilot with Single Worm first before doing 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Basic set up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/worm_segmentation'\n",
    "video_path = current_location + '/sample.avi'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "motion_mask_cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "original_video_cap = cv2.VideoCapture('sample.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "f_worm_1 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "worm_1_out = cv2.VideoWriter(output_folder + '/worm_1_out.mp4', f_worm_1, frame_rate, (frame_width, frame_height), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loop through the first 1/10 of the video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_it_number = 0\n",
    "\n",
    "if not motion_mask_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(motion_mask_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the motion mask: {total_it_number}\")\n",
    "\n",
    "if not original_video_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(original_video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the original video: {total_it_number}\")\n",
    "\n",
    "print(f\"to process the video need to iterate over: {total_it_number}\")\n",
    "\n",
    "total_it_number = int(total_it_number / 10)\n",
    "\n",
    "print(f\"to process the video need to iterate over: {total_it_number}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "actually, construct the worm object before looping, that means, I need to make the first frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the first motion\n",
    "ret, motion_frame_init = motion_mask_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the motion ask\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"motion frame read\")\n",
    "print(\"Shape of Frame\", motion_frame_init.shape)\n",
    "print(\"First Row\", motion_frame_init[:,1])\n",
    "previous_motion_frame = cv2.cvtColor(motion_frame_init, cv2.COLOR_BGR2GRAY)\n",
    "inspect_given_a_frame(previous_motion_frame)\n",
    "print(\"Shape of Frame\", previous_motion_frame.shape)\n",
    "print(\"First Row\", previous_motion_frame[:,1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "for worm initialization, let us analyze frame by frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ret, current_motion_frame = motion_mask_cap.read()\n",
    "current_motion_frame = cv2.cvtColor(current_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "print('Number of labels', num_labels, '\\n')\n",
    "print('labels', labels, '\\n')\n",
    "print('stats', stats, '\\n')\n",
    "print('centroids', centroids, '\\n')\n",
    "min_area = 5000\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "previous_motion_frame = current_motion_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sum(sum(labels)))\n",
    "print('Number of labels', num_labels)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.imshow(labels, cmap='hot', interpolation='nearest')\n",
    "\n",
    "# Adding a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Adding titles and labels (optional)\n",
    "plt.title('Heatmap of a 2D NumPy Array')\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "let us look at next frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ret, current_motion_frame = motion_mask_cap.read()\n",
    "current_motion_frame = cv2.cvtColor(current_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "print('Number of labels', num_labels, '\\n')\n",
    "print('labels', labels, '\\n')\n",
    "print('stats', stats, '\\n')\n",
    "print('centroids', centroids, '\\n')\n",
    "min_area = 5000\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "previous_motion_frame = current_motion_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sum(sum(labels)))\n",
    "print('Number of labels', num_labels)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.imshow(labels, cmap='hot', interpolation='nearest')\n",
    "\n",
    "# Adding a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Adding titles and labels (optional)\n",
    "plt.title('Heatmap of a 2D NumPy Array')\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "standard initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reset cap\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "# Read the first motion\n",
    "ret, motion_frame_init = motion_mask_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the motion ask\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"motion frame read\")\n",
    "print(\"Shape of Frame\", motion_frame_init.shape)\n",
    "print(\"First Row\", motion_frame_init[:,1])\n",
    "previous_motion_frame = cv2.cvtColor(motion_frame_init, cv2.COLOR_BGR2GRAY)\n",
    "inspect_given_a_frame(previous_motion_frame)\n",
    "print(\"Shape of Frame\", previous_motion_frame.shape)\n",
    "print(\"First Row\", previous_motion_frame[:,1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loop through the video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for j in range(total_it_number):\n",
    "    ret, temporal_motion_frame = motion_mask_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    current_motion_frame = cv2.cvtColor(temporal_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    print('Number of labels', num_labels, '\\n')\n",
    "    print('labels', labels, '\\n')\n",
    "    print('stats', stats, '\\n')\n",
    "    print('centroids', centroids, '\\n')\n",
    "    min_area = 5000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imshow('Segmented Frame', rgb_frame)\n",
    "    out.write(rgb_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cut to 1/4 of the original for easy processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('shorter.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "for i in range(int(frame_count/4)):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    out.write(frame)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Background Subtraction, Spatial Smoothing, Temporal Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('shorter.mp4')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # You can also use 'XVID'\n",
    "out = cv2.VideoWriter('processed_v1.mp4', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "# Background subtractor\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "# Buffer for temporal smoothing\n",
    "buffer_size = 5\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Background subtraction\n",
    "    fgMask = backSub.apply(frame)\n",
    "    # Spatial smoothing (Gaussian blur)\n",
    "    blurred = cv2.GaussianBlur(fgMask, (5, 5), 0)\n",
    "    # Add frame to buffer for temporal smoothing\n",
    "    frame_buffer.append(blurred)\n",
    "    if len(frame_buffer) > buffer_size:\n",
    "        frame_buffer.pop(0)\n",
    "    # Temporal smoothing (average of frames in buffer)\n",
    "    temp_smoothed = np.mean(frame_buffer, axis=0).astype(np.uint8)\n",
    "    # Write frame to video\n",
    "    out.write(temp_smoothed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erode and Dilate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('processed_v1.mp4')\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('processed_v2.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    # Read each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Apply erosion and then dilation\n",
    "    eroded_frame = cv2.erode(frame, kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, kernel, iterations=1)\n",
    "    # Display the processed frame\n",
    "    out.write(dilated_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    # Break the loop with a key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overlay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_cap = cv2.VideoCapture('shorter.mp4')\n",
    "cap = cv2.VideoCapture('processed_v2.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (75, 75))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('processed_v3.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "not_useful, ori_frame = original_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    not_useful, ori_frame = original_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    out.write(ori_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Worm Object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make Minimum Area a Global Parameter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "min_area = 2000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def create_list_of_n_objects(n):\n",
    "    \"\"\"\n",
    "    Create a list of n objects, each object is its index in the list.\n",
    "    \"\"\"\n",
    "    return [i for i in range(n)]\n",
    "\n",
    "# Example usage\n",
    "n = 10\n",
    "list_of_n_objects = create_list_of_n_objects(n)\n",
    "\n",
    "def iterate_and_print_list(input_list):\n",
    "    \"\"\"\n",
    "    Iteratively list all objects in the provided list.\n",
    "    \"\"\"\n",
    "    for item in input_list:\n",
    "        print(item)\n",
    "\n",
    "# Example usage with a list of 10 items\n",
    "iterate_and_print_list(list_of_n_objects)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the squares overlap? True\n"
     ]
    }
   ],
   "source": [
    "def check_overlap(x1, y1, width1, height1, x2, y2, width2, height2):\n",
    "    # Check if one square is to the left of the other\n",
    "    if x1 + width1 <= x2 or x2 + width2 <= x1:\n",
    "        return False\n",
    "    # Check if one square is above the other\n",
    "    if y1 + height1 <= y2 or y2 + height2 <= y1:\n",
    "        return False\n",
    "    # If neither condition is true, squares must be overlapping\n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "x1, y1, width1, height1 = 10, 10, 30, 30  # Square 1\n",
    "x2, y2, width2, height2 = 20, 20, 30, 30  # Square 2\n",
    "\n",
    "overlap = check_overlap(x1, y1, width1, height1, x2, y2, width2, height2)\n",
    "print(\"Do the squares overlap?\", overlap)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2nd item in the queue is: item2\n"
     ]
    }
   ],
   "source": [
    "def get_nth_item(q, n):\n",
    "    if n >= q.qsize():\n",
    "        return None  # or raise an exception if you prefer\n",
    "\n",
    "    for _ in range(n - 1):\n",
    "        q.get()\n",
    "\n",
    "    nth_item = q.get()\n",
    "    return nth_item\n",
    "\n",
    "# Example\n",
    "q = queue.Queue()\n",
    "q.put('item1')\n",
    "q.put('item2')\n",
    "q.put('item3')\n",
    "\n",
    "nth_item = get_nth_item(q, 2)  # Get the 2nd item\n",
    "print(\"The 2nd item in the queue is:\", nth_item)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the points is: 5.0\n"
     ]
    }
   ],
   "source": [
    "def distance_between_points(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "# Example usage\n",
    "x1, y1 = 1, 2\n",
    "x2, y2 = 4, 6\n",
    "distance = distance_between_points(x1, y1, x2, y2)\n",
    "print(\"The distance between the points is:\", distance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def white_outside_rectangle(fra, x, y, width, height):\n",
    "    \"\"\"\n",
    "    Makes everything outside a specified rectangle in the frame purely white.\n",
    "    :param fra: The original image/frame.\n",
    "    :param x: The x-coordinate of the top-left corner of the rectangle.\n",
    "    :param y: The y-coordinate of the top-left corner of the rectangle.\n",
    "    :param width: The width of the rectangle.\n",
    "    :param height: The height of the rectangle.\n",
    "    :return: Modified frame with white outside the specified rectangle.\n",
    "    \"\"\"\n",
    "    # Make a copy of the frame\n",
    "    modified_frame = np.copy(fra)\n",
    "    # Draw white rectangles over the areas outside the specified rectangle\n",
    "    # Top\n",
    "    modified_frame[0:y, :] = 255\n",
    "    # Bottom\n",
    "    modified_frame[y+height:fra.shape[0], :] = 255\n",
    "    # Left\n",
    "    modified_frame[:, 0:x] = 255\n",
    "    # Right\n",
    "    modified_frame[:, x+width:fra.shape[1]] = 255\n",
    "    return modified_frame\n",
    "# Example usage\n",
    "# frame = cv2.imread('path_to_your_image.jpg')  # Load your frame or image\n",
    "# modified_frame = white_outside_rectangle(frame, 50, 50, 100, 100)\n",
    "# cv2.imshow('Modified Frame', modified_frame)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/pilot_images'\n",
    "monitor_folder = current_location + '/monitor_images'\n",
    "video_path = current_location + '/sample.avi'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "if not os.path.exists(monitor_folder):\n",
    "    os.makedirs(monitor_folder)\n",
    "\n",
    "class Worm:\n",
    "    def __init__(self, worm_index, original_Cap, init_label, init_stats,init_centroid,another_variable_in_case=None):\n",
    "        self.worm_index = worm_index\n",
    "        self.original_cap = original_Cap\n",
    "        self.current_label = init_label\n",
    "        self.current_stats = init_stats\n",
    "        self.current_centroid = init_centroid\n",
    "        self.label_history = queue.Queue()\n",
    "        self.stats_history = queue.Queue()\n",
    "        self.centroid_history = queue.Queue()\n",
    "        self.another_variable_in_case = another_variable_in_case\n",
    "        # also establish the output flow\n",
    "        self.frame_width = int(original_Cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.frame_height = int(original_Cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.frame_rate = original_Cap.get(cv2.CAP_PROP_FPS)\n",
    "        cur_location = os.getcwd()\n",
    "        text = '/worm_' + str(worm_index)\n",
    "        self.output_folder = cur_location + text\n",
    "        if not os.path.exists(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "\n",
    "    def display_info(self):\n",
    "        info = f\"worn index: {self.worm_index}, video_cap: {self.original_cap}, label_history: {self.label_history}, stats_history: {self.stats_history}, centroid_history: {self.centroid_history}, \\n\"\n",
    "        print(info)\n",
    "        info = f\"current label: {self.current_label}, current_stats: {self.current_stats}, current_centroid: {self.current_centroid}, stats_history: {self.stats_history}, centroid_history: {self.centroid_history}, \\n\"\n",
    "        print(info)\n",
    "        print('Current Stats \\n')\n",
    "        print(self.current_stats)\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('Current Label \\n')\n",
    "        print(self.current_label)\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('Current Centroid\\n')\n",
    "        print(self.current_centroid)\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "\n",
    "    def update_another_variable(self, another_variable_in_case):\n",
    "        \"\"\"Update the car's mileage.\"\"\"\n",
    "        if another_variable_in_case >= self.another_variable_in_case:\n",
    "            self.another_variable_in_case = another_variable_in_case\n",
    "        else:\n",
    "            print(\"Error: another_variable_in_case cannot be reduced.\")\n",
    "\n",
    "    def take_the_bundle_in(self, bundle):\n",
    "        num_labels, labels, stats, centroids = bundle\n",
    "        # save the previous iteration\n",
    "        labels_modified = np.where(labels == self.current_label, self.current_label, 0)\n",
    "        self.label_history.put(labels_modified)\n",
    "        self.stats_history.put(self.current_stats)\n",
    "        self.centroid_history.put(self.current_centroid)\n",
    "        overlap_labels = queue.Queue()\n",
    "        # determine which one is the next label\n",
    "        for i in range(1, num_labels):\n",
    "            x, y, w, h, area = stats[i]\n",
    "            if area > min_area:\n",
    "                overlap_yes = check_overlap(x, y, w, h, self.current_stats[0], self.current_stats[1], self.current_stats[2], self.current_stats[3])\n",
    "                if overlap_yes:\n",
    "                    overlap_labels.put(i)\n",
    "        # find the closest centroid\n",
    "        try:\n",
    "            centroid_distance = 10000000000 # first assume that the two centroids are very far away\n",
    "            best_label = -1 # let us not know which one is the best label at the beginning\n",
    "            for j in range(overlap_labels.qsize()):\n",
    "                this_label_selected = get_nth_item(overlap_labels, j)\n",
    "                this_centroid = centroids[this_label_selected]\n",
    "                this_distance = distance_between_points(this_centroid[0], this_centroid[1], self.current_centroid[0], self.current_centroid[1])\n",
    "                if this_distance < centroid_distance:\n",
    "                    centroid_distance = this_distance\n",
    "                    best_label = this_label_selected\n",
    "            # update the current frame\n",
    "            if best_label == -1: # make sure some labels are selected, if  no overlapping frames exist, jump to the nea\n",
    "                print('No Criterion satisfied, jump to the nearest frame')\n",
    "                for l in range(1, num_labels):\n",
    "                    this_centroid = centroids[l]\n",
    "                    this_distance = distance_between_points(this_centroid[0], this_centroid[1], self.current_centroid[0], self.current_centroid[1])\n",
    "                    if this_distance < centroid_distance:\n",
    "                        centroid_distance = this_distance\n",
    "                        best_label = l\n",
    "            self.current_label = best_label\n",
    "            self.current_stats = stats[best_label]\n",
    "            self.current_centroid = centroids[best_label]\n",
    "        except Exception as e:\n",
    "            self.display_info()\n",
    "\n",
    "    def write_frame(self, n_th_frame):\n",
    "        self.original_cap.set(cv2.CAP_PROP_POS_FRAMES, n_th_frame)\n",
    "        get, this_frame = original_cap.read()\n",
    "        if not get:\n",
    "            print('something wrong happened')\n",
    "        x, y, w, h, area = self.current_stats\n",
    "        cv2.rectangle(this_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        this_frame = white_outside_rectangle(this_frame, x, y, w, h)\n",
    "        cv2.imwrite(os.path.join(self.output_folder, f\"frame_{n_th_frame}.jpg\"), this_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Frame-by-frame processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the First Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_cap = cv2.VideoCapture('shorter.mp4')\n",
    "\n",
    "cap = cv2.VideoCapture('processed_v2.mp4')\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (75, 75))\n",
    "\n",
    "# Read the first frame\n",
    "ret1, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{1}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{1}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the Second Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{2}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{2}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the Third Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{3}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{3}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Up the First Worm Object: Worm_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x122177390>, stats_history: <queue.Queue object at 0x124e64fd0>, centroid_history: <queue.Queue object at 0x124dca050>, \n",
      "\n",
      "current label: 4, current_stats: [1010  120   86   87 7454], current_centroid: [1052.49946338  163.04292997], stats_history: <queue.Queue object at 0x124e64fd0>, centroid_history: <queue.Queue object at 0x124dca050>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1010  120   86   87 7454]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1052.49946338  163.04292997]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worm_1 = Worm(4, original_cap, 4, stats[4], centroids[4])\n",
    "worm_1.display_info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up the Worm List"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# set up the number that I want to track for worms\n",
    "track_number = 10\n",
    "\n",
    "# create the list of n tracking number\n",
    "w_list = create_list_of_n_objects(track_number)\n",
    "\n",
    "for i in range(1, len(w_list)):\n",
    "    temp_Worm = Worm(i, original_cap, i, stats[i], centroids[i])\n",
    "    w_list[i] = temp_Worm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check everything in the list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x124fb2f90>, stats_history: <queue.Queue object at 0x124fb1210>, centroid_history: <queue.Queue object at 0x124fb1b90>, \n",
      "\n",
      "current label: 1, current_stats: [ 935    0   78   77 6003], current_centroid: [973.48075962  37.98150925], stats_history: <queue.Queue object at 0x124fb1210>, centroid_history: <queue.Queue object at 0x124fb1b90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 935    0   78   77 6003]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[973.48075962  37.98150925]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x124e3cb50>, stats_history: <queue.Queue object at 0x1236b9b10>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "current label: 2, current_stats: [1053   12   79   79 6233], current_centroid: [1092.04925397   50.97561367], stats_history: <queue.Queue object at 0x1236b9b10>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1053   12   79   79 6233]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1092.04925397   50.97561367]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x124fc8450>, stats_history: <queue.Queue object at 0x124e3c4d0>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "current label: 3, current_stats: [1122  102   82  104 8225], current_centroid: [1162.04863222  153.05471125], stats_history: <queue.Queue object at 0x124e3c4d0>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1122  102   82  104 8225]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1162.04863222  153.05471125]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x124f4eb90>, stats_history: <queue.Queue object at 0x124e3d0d0>, centroid_history: <queue.Queue object at 0x124e3c390>, \n",
      "\n",
      "current label: 4, current_stats: [1010  120   86   87 7454], current_centroid: [1052.49946338  163.04292997], stats_history: <queue.Queue object at 0x124e3d0d0>, centroid_history: <queue.Queue object at 0x124e3c390>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1010  120   86   87 7454]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1052.49946338  163.04292997]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x124e3e610>, stats_history: <queue.Queue object at 0x124e3e710>, centroid_history: <queue.Queue object at 0x124e3d290>, \n",
      "\n",
      "current label: 5, current_stats: [  359   124   443   377 67112], current_centroid: [574.51002801 280.78412206], stats_history: <queue.Queue object at 0x124e3e710>, centroid_history: <queue.Queue object at 0x124e3d290>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  359   124   443   377 67112]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[574.51002801 280.78412206]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x122f491d0>, stats_history: <queue.Queue object at 0x124e3ecd0>, centroid_history: <queue.Queue object at 0x124e3fd90>, \n",
      "\n",
      "current label: 6, current_stats: [1277  158   76   76 5776], current_centroid: [1314.5  195.5], stats_history: <queue.Queue object at 0x124e3ecd0>, centroid_history: <queue.Queue object at 0x124e3fd90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1277  158   76   76 5776]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1314.5  195.5]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x124faf4d0>, stats_history: <queue.Queue object at 0x124e28690>, centroid_history: <queue.Queue object at 0x124e28550>, \n",
      "\n",
      "current label: 7, current_stats: [ 156  463   78   76 5925], current_centroid: [194.49367089 500.51898734], stats_history: <queue.Queue object at 0x124e28690>, centroid_history: <queue.Queue object at 0x124e28550>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 156  463   78   76 5925]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[194.49367089 500.51898734]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x124718f90>, stats_history: <queue.Queue object at 0x1246f1810>, centroid_history: <queue.Queue object at 0x124f3e990>, \n",
      "\n",
      "current label: 8, current_stats: [  172   564   122   141 16269], current_centroid: [231.24426824 633.56358719], stats_history: <queue.Queue object at 0x1246f1810>, centroid_history: <queue.Queue object at 0x124f3e990>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  172   564   122   141 16269]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[231.24426824 633.56358719]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x124fc1b10>, stats_history: <queue.Queue object at 0x124fc3c10>, centroid_history: <queue.Queue object at 0x124e5bd50>, \n",
      "\n",
      "current label: 9, current_stats: [ 1887   653   156   195 25521], current_centroid: [1964.71074801  741.59680263], stats_history: <queue.Queue object at 0x124fc3c10>, centroid_history: <queue.Queue object at 0x124e5bd50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1887   653   156   195 25521]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1964.71074801  741.59680263]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(w_list)):\n",
    "    temp_Worm = Worm(i, original_cap, i, stats[i], centroids[i])\n",
    "    temp_Worm.display_info()\n",
    "    w_list[i] = temp_Worm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the Fourth Frame and take the bundle in by the Worm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "bundle = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "\n",
    "worm_1.take_the_bundle_in(bundle)\n",
    "worm_1.write_frame(4)\n",
    "\n",
    "# process the worm list\n",
    "for i in range(1, len(w_list)):\n",
    "    temp_Worm = Worm(i, original_cap, i, stats[i], centroids[i])\n",
    "    temp_Worm.take_the_bundle_in(bundle)\n",
    "    temp_Worm.write_frame(4)\n",
    "    w_list[i] = temp_Worm\n",
    "\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{4}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{4}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x122177390>, stats_history: <queue.Queue object at 0x124e64fd0>, centroid_history: <queue.Queue object at 0x124dca050>, \n",
      "\n",
      "current label: 1, current_stats: [ 1026   117   210    97 18763], current_centroid: [1129.28305708  165.21739594], stats_history: <queue.Queue object at 0x124e64fd0>, centroid_history: <queue.Queue object at 0x124dca050>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1026   117   210    97 18763]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1129.28305708  165.21739594]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/Users/billdeng/PycharmProjects/unicellular/worm_4\n"
     ]
    }
   ],
   "source": [
    "worm_1.display_info()\n",
    "print(worm_1.output_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Proceed to the Fifth Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "bundle = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "\n",
    "worm_1.take_the_bundle_in(bundle)\n",
    "worm_1.write_frame(5)\n",
    "\n",
    "# process the worm list\n",
    "for i in range(1, len(w_list)):\n",
    "    temp_Worm = Worm(i, original_cap, i, stats[i], centroids[i])\n",
    "    temp_Worm.take_the_bundle_in(bundle)\n",
    "    temp_Worm.write_frame(5)\n",
    "    w_list[i] = temp_Worm\n",
    "\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{5}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{5}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x122177390>, stats_history: <queue.Queue object at 0x124e64fd0>, centroid_history: <queue.Queue object at 0x124dca050>, \n",
      "\n",
      "current label: 1, current_stats: [1027  119   88   86 7537], current_centroid: [1070.38675866  161.48401221], stats_history: <queue.Queue object at 0x124e64fd0>, centroid_history: <queue.Queue object at 0x124dca050>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1027  119   88   86 7537]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1070.38675866  161.48401221]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/Users/billdeng/PycharmProjects/unicellular/worm_4\n"
     ]
    }
   ],
   "source": [
    "worm_1.display_info()\n",
    "print(worm_1.output_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Proceed to the Sixth Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Criterion satisfied, jump to the nearest frame\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "bundle = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "\n",
    "worm_1.take_the_bundle_in(bundle)\n",
    "worm_1.write_frame(6)\n",
    "\n",
    "# process the worm list\n",
    "for i in range(1, len(w_list)):\n",
    "    temp_Worm = Worm(i, original_cap, i, stats[i], centroids[i])\n",
    "    temp_Worm.take_the_bundle_in(bundle)\n",
    "    temp_Worm.write_frame(6)\n",
    "    w_list[i] = temp_Worm\n",
    "\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{6}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{6}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba190>, label_history: <queue.Queue object at 0x122177390>, stats_history: <queue.Queue object at 0x124e64fd0>, centroid_history: <queue.Queue object at 0x124dca050>, \n",
      "\n",
      "current label: 1, current_stats: [  425   123   397   267 57098], current_centroid: [617.63856878 248.42047007], stats_history: <queue.Queue object at 0x124e64fd0>, centroid_history: <queue.Queue object at 0x124dca050>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  425   123   397   267 57098]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[617.63856878 248.42047007]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/Users/billdeng/PycharmProjects/unicellular/worm_4\n"
     ]
    }
   ],
   "source": [
    "worm_1.display_info()\n",
    "print(worm_1.output_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reset and Process all the frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Start with the First Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_cap = cv2.VideoCapture('shorter.mp4')\n",
    "\n",
    "cap = cv2.VideoCapture('processed_v2.mp4')\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (75, 75))\n",
    "\n",
    "# Read the first frame\n",
    "ret1, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{1}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{1}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the Second Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{2}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{2}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set up worm list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# set up the number that I want to track for worms\n",
    "track_number = 10\n",
    "\n",
    "# create the list of n tracking number\n",
    "w_list = create_list_of_n_objects(track_number)\n",
    "\n",
    "for i in range(1, len(w_list)):\n",
    "    temp_Worm = Worm(i, original_cap, i, stats[i], centroids[i])\n",
    "    w_list[i] = temp_Worm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make sure the list is well set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221b0c50>, stats_history: <queue.Queue object at 0x124ff5c50>, centroid_history: <queue.Queue object at 0x124ff5fd0>, \n",
      "\n",
      "current label: 1, current_stats: [  924     0   537   250 75010], current_centroid: [1172.90573257  136.73210239], stats_history: <queue.Queue object at 0x124ff5c50>, centroid_history: <queue.Queue object at 0x124ff5fd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  924     0   537   250 75010]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1172.90573257  136.73210239]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124fb0550>, centroid_history: <queue.Queue object at 0x124b3fad0>, \n",
      "\n",
      "current label: 2, current_stats: [ 810   31  112   89 9733], current_centroid: [865.21103462  75.09339361], stats_history: <queue.Queue object at 0x124fb0550>, centroid_history: <queue.Queue object at 0x124b3fad0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 810   31  112   89 9733]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[865.21103462  75.09339361]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124fb1c50>, centroid_history: <queue.Queue object at 0x122f491d0>, \n",
      "\n",
      "current label: 3, current_stats: [  313    94   493   460 83193], current_centroid: [568.12996286 289.41301552], stats_history: <queue.Queue object at 0x124fb1c50>, centroid_history: <queue.Queue object at 0x122f491d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  313    94   493   460 83193]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[568.12996286 289.41301552]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122217dd0>, stats_history: <queue.Queue object at 0x124fc9990>, centroid_history: <queue.Queue object at 0x124b4d150>, \n",
      "\n",
      "current label: 4, current_stats: [ 845  134  108   87 8724], current_centroid: [898.27086199 177.18924805], stats_history: <queue.Queue object at 0x124fc9990>, centroid_history: <queue.Queue object at 0x124b4d150>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 845  134  108   87 8724]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[898.27086199 177.18924805]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f4eb90>, stats_history: <queue.Queue object at 0x124e3eed0>, centroid_history: <queue.Queue object at 0x124e3e8d0>, \n",
      "\n",
      "current label: 5, current_stats: [ 1483   226   219   169 23599], current_centroid: [1591.12521717  311.15767617], stats_history: <queue.Queue object at 0x124e3eed0>, centroid_history: <queue.Queue object at 0x124e3e8d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1483   226   219   169 23599]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1591.12521717  311.15767617]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3c3d0>, stats_history: <queue.Queue object at 0x124e3c4d0>, centroid_history: <queue.Queue object at 0x124e3fc50>, \n",
      "\n",
      "current label: 6, current_stats: [1725  400   79   77 6076], current_centroid: [1763.98156682  437.99374589], stats_history: <queue.Queue object at 0x124e3c4d0>, centroid_history: <queue.Queue object at 0x124e3fc50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1725  400   79   77 6076]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1763.98156682  437.99374589]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3d590>, stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "current label: 7, current_stats: [  103   553   219   167 27210], current_centroid: [211.98834987 627.30812201], stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  103   553   219   167 27210]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[211.98834987 627.30812201]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fed990>, stats_history: <queue.Queue object at 0x124e3d290>, centroid_history: <queue.Queue object at 0x124e3d190>, \n",
      "\n",
      "current label: 8, current_stats: [ 1885   632   229   417 54610], current_centroid: [1992.21197583  839.92440945], stats_history: <queue.Queue object at 0x124e3d290>, centroid_history: <queue.Queue object at 0x124e3d190>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1885   632   229   417 54610]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1992.21197583  839.92440945]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fec8d0>, stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "current label: 9, current_stats: [    0   647   210   412 46450], current_centroid: [119.48213132 871.19386437], stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[    0   647   210   412 46450]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[119.48213132 871.19386437]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(w_list)):\n",
    "    temp_Worm = Worm(i, original_cap, i, stats[i], centroids[i])\n",
    "    temp_Worm.display_info()\n",
    "    w_list[i] = temp_Worm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run the loop to parse the video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1236bb110>, stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x124ffa010>, \n",
      "\n",
      "current label: 1, current_stats: [  213   140   544   506 91647], current_centroid: [474.7242572  364.63155368], stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x124ffa010>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  213   140   544   506 91647]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[474.7242572  364.63155368]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fe4310>, stats_history: <queue.Queue object at 0x124ff7190>, centroid_history: <queue.Queue object at 0x124ff5fd0>, \n",
      "\n",
      "current label: 2, current_stats: [  635   636   235   350 52884], current_centroid: [750.17806898 812.13879434], stats_history: <queue.Queue object at 0x124ff7190>, centroid_history: <queue.Queue object at 0x124ff5fd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  635   636   235   350 52884]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[750.17806898 812.13879434]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3fc50>, stats_history: <queue.Queue object at 0x124e3c4d0>, centroid_history: <queue.Queue object at 0x124e3c3d0>, \n",
      "\n",
      "current label: 8, current_stats: [ 1865   985   254   547 92201], current_centroid: [1986.38508259 1246.04952224], stats_history: <queue.Queue object at 0x124e3c4d0>, centroid_history: <queue.Queue object at 0x124e3c3d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1865   985   254   547 92201]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1986.38508259 1246.04952224]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3e410>, stats_history: <queue.Queue object at 0x124e3fb50>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "current label: 1, current_stats: [  217   147   525   490 93608], current_centroid: [463.93167251 371.4304333 ], stats_history: <queue.Queue object at 0x124e3fb50>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  217   147   525   490 93608]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[463.93167251 371.4304333 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fed490>, stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "current label: 2, current_stats: [  624   617   238   355 54156], current_centroid: [740.96613487 794.72241303], stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  624   617   238   355 54156]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[740.96613487 794.72241303]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fc9990>, stats_history: <queue.Queue object at 0x124b4d150>, centroid_history: <queue.Queue object at 0x124e67410>, \n",
      "\n",
      "current label: 7, current_stats: [ 1864   982   258   551 92912], current_centroid: [1987.37163122 1243.42643577], stats_history: <queue.Queue object at 0x124b4d150>, centroid_history: <queue.Queue object at 0x124e67410>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1864   982   258   551 92912]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1987.37163122 1243.42643577]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3f210>, stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3e650>, \n",
      "\n",
      "current label: 1, current_stats: [  223   150   516   479 92039], current_centroid: [463.80940688 368.09926227], stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3e650>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  223   150   516   479 92039]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[463.80940688 368.09926227]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa650>, stats_history: <queue.Queue object at 0x124fed990>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "current label: 2, current_stats: [  618   610   238   354 53986], current_centroid: [736.37100359 785.7639388 ], stats_history: <queue.Queue object at 0x124fed990>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  618   610   238   354 53986]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[736.37100359 785.7639388 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1244b5c10>, stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb1ad0>, \n",
      "\n",
      "current label: 7, current_stats: [ 1866   984   251   554 86035], current_centroid: [1984.56919858 1241.20008136], stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb1ad0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1866   984   251   554 86035]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1984.56919858 1241.20008136]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3d350>, stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3c690>, \n",
      "\n",
      "current label: 1, current_stats: [  222   153   506   465 92566], current_centroid: [458.98612882 368.12800596], stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3c690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  222   153   506   465 92566]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[458.98612882 368.12800596]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3f210>, \n",
      "\n",
      "current label: 2, current_stats: [  614   596   236   361 54224], current_centroid: [730.67138168 775.73952493], stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3f210>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  614   596   236   361 54224]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[730.67138168 775.73952493]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221cfb10>, stats_history: <queue.Queue object at 0x124fb0950>, centroid_history: <queue.Queue object at 0x124b3fad0>, \n",
      "\n",
      "current label: 7, current_stats: [ 1860   982   263   583 93448], current_centroid: [1981.78895214 1260.54113518], stats_history: <queue.Queue object at 0x124fb0950>, centroid_history: <queue.Queue object at 0x124b3fad0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1860   982   263   583 93448]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1981.78895214 1260.54113518]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124d7f9d0>, stats_history: <queue.Queue object at 0x124e3cb50>, centroid_history: <queue.Queue object at 0x124e3fe50>, \n",
      "\n",
      "current label: 1, current_stats: [  193   158   520   534 97464], current_centroid: [435.45486539 393.44219404], stats_history: <queue.Queue object at 0x124e3cb50>, centroid_history: <queue.Queue object at 0x124e3fe50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  193   158   520   534 97464]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[435.45486539 393.44219404]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3cc10>, stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "current label: 2, current_stats: [  609   590   233   359 53366], current_centroid: [724.95317243 767.43046134], stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  609   590   233   359 53366]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[724.95317243 767.43046134]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fec8d0>, stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "current label: 5, current_stats: [ 1029   837   224   178 29280], current_centroid: [1139.72827869  928.70218579], stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1029   837   224   178 29280]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1139.72827869  928.70218579]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122fd1090>, stats_history: <queue.Queue object at 0x124ff5a90>, centroid_history: <queue.Queue object at 0x124ff7d90>, \n",
      "\n",
      "current label: 7, current_stats: [   916    972   1203   1139 343863], current_centroid: [1610.66139713 1677.79437741], stats_history: <queue.Queue object at 0x124ff5a90>, centroid_history: <queue.Queue object at 0x124ff7d90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   916    972   1203   1139 343863]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1610.66139713 1677.79437741]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b3fad0>, stats_history: <queue.Queue object at 0x1221cfb10>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "current label: 8, current_stats: [ 1489  1015   169   234 30609], current_centroid: [1569.59462903 1128.28455683], stats_history: <queue.Queue object at 0x1221cfb10>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1489  1015   169   234 30609]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1569.59462903 1128.28455683]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1244b5c10>, stats_history: <queue.Queue object at 0x124f1d0d0>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "current label: 9, current_stats: [  834  1041   325   350 62513], current_centroid: [ 985.49485707 1223.13304433], stats_history: <queue.Queue object at 0x124f1d0d0>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  834  1041   325   350 62513]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 985.49485707 1223.13304433]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124d7f9d0>, stats_history: <queue.Queue object at 0x124e3f7d0>, centroid_history: <queue.Queue object at 0x124e3ee90>, \n",
      "\n",
      "current label: 2, current_stats: [  223   164   483   438 82491], current_centroid: [447.25996775 371.05640615], stats_history: <queue.Queue object at 0x124e3f7d0>, centroid_history: <queue.Queue object at 0x124e3ee90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  223   164   483   438 82491]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[447.25996775 371.05640615]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3d350>, stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "current label: 3, current_stats: [  605   581   229   358 53051], current_centroid: [719.34947503 758.27694106], stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  605   581   229   358 53051]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[719.34947503 758.27694106]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fed490>, stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "current label: 6, current_stats: [ 1036   847   220   170 28019], current_centroid: [1145.27249367  932.81658874], stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1036   847   220   170 28019]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1145.27249367  932.81658874]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fe5710>, stats_history: <queue.Queue object at 0x124ff5910>, centroid_history: <queue.Queue object at 0x124ff7190>, \n",
      "\n",
      "current label: 8, current_stats: [   909    990   1209   1120 340294], current_centroid: [1601.79413096 1683.27047788], stats_history: <queue.Queue object at 0x124ff5910>, centroid_history: <queue.Queue object at 0x124ff7190>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   909    990   1209   1120 340294]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1601.79413096 1683.27047788]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221cfb10>, stats_history: <queue.Queue object at 0x124fb2a10>, centroid_history: <queue.Queue object at 0x124b3fad0>, \n",
      "\n",
      "current label: 9, current_stats: [ 1489  1012   173   234 31015], current_centroid: [1571.05784298 1124.4699339 ], stats_history: <queue.Queue object at 0x124fb2a10>, centroid_history: <queue.Queue object at 0x124b3fad0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1489  1012   173   234 31015]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1571.05784298 1124.4699339 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fe6750>, stats_history: <queue.Queue object at 0x124fb3d10>, centroid_history: <queue.Queue object at 0x1244b5c10>, \n",
      "\n",
      "current label: 1, current_stats: [  179   166   518   468 92598], current_centroid: [431.53101579 386.32063328], stats_history: <queue.Queue object at 0x124fb3d10>, centroid_history: <queue.Queue object at 0x1244b5c10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  179   166   518   468 92598]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[431.53101579 386.32063328]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fc9990>, stats_history: <queue.Queue object at 0x124b4e650>, centroid_history: <queue.Queue object at 0x122f6f710>, \n",
      "\n",
      "current label: 2, current_stats: [  600   572   230   360 53888], current_centroid: [715.99376485 750.07966523], stats_history: <queue.Queue object at 0x124b4e650>, centroid_history: <queue.Queue object at 0x122f6f710>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  600   572   230   360 53888]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[715.99376485 750.07966523]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3f210>, centroid_history: <queue.Queue object at 0x124e3d0d0>, \n",
      "\n",
      "current label: 5, current_stats: [ 1037   848   220   175 28272], current_centroid: [1146.40184635  935.14530277], stats_history: <queue.Queue object at 0x124e3f210>, centroid_history: <queue.Queue object at 0x124e3d0d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1037   848   220   175 28272]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1146.40184635  935.14530277]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa650>, stats_history: <queue.Queue object at 0x124fed990>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "current label: 6, current_stats: [   886    936   1226   1178 354605], current_centroid: [1600.61519719 1682.75715796], stats_history: <queue.Queue object at 0x124fed990>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   886    936   1226   1178 354605]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1600.61519719 1682.75715796]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f73850>, stats_history: <queue.Queue object at 0x12301f950>, centroid_history: <queue.Queue object at 0x124ffa010>, \n",
      "\n",
      "current label: 8, current_stats: [ 1489  1008   177   234 31223], current_centroid: [1573.20068539 1120.43522403], stats_history: <queue.Queue object at 0x12301f950>, centroid_history: <queue.Queue object at 0x124ffa010>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1489  1008   177   234 31223]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1573.20068539 1120.43522403]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff7190>, stats_history: <queue.Queue object at 0x124ff5910>, centroid_history: <queue.Queue object at 0x124ff7d90>, \n",
      "\n",
      "current label: 9, current_stats: [  814  1028   330   353 63260], current_centroid: [ 971.11977553 1210.48804932], stats_history: <queue.Queue object at 0x124ff5910>, centroid_history: <queue.Queue object at 0x124ff7d90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  814  1028   330   353 63260]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 971.11977553 1210.48804932]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1220a46d0>, stats_history: <queue.Queue object at 0x124fe6750>, centroid_history: <queue.Queue object at 0x124fb1b90>, \n",
      "\n",
      "current label: 2, current_stats: [  177   167   511   472 92196], current_centroid: [428.56894008 387.92381448], stats_history: <queue.Queue object at 0x124fe6750>, centroid_history: <queue.Queue object at 0x124fb1b90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  177   167   511   472 92196]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[428.56894008 387.92381448]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221b2250>, stats_history: <queue.Queue object at 0x124e67410>, centroid_history: <queue.Queue object at 0x124fc9990>, \n",
      "\n",
      "current label: 3, current_stats: [  597   563   232   370 55171], current_centroid: [713.20904098 745.91147523], stats_history: <queue.Queue object at 0x124e67410>, centroid_history: <queue.Queue object at 0x124fc9990>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  597   563   232   370 55171]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[713.20904098 745.91147523]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3e510>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "current label: 6, current_stats: [ 1039   853   218   176 29021], current_centroid: [1149.46425003  939.19737432], stats_history: <queue.Queue object at 0x124e3e510>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1039   853   218   176 29021]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1149.46425003  939.19737432]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fed490>, stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "current label: 8, current_stats: [   873    940   1242   1176 358361], current_centroid: [1598.50377413 1684.65386859], stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   873    940   1242   1176 358361]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1598.50377413 1684.65386859]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77250>, stats_history: <queue.Queue object at 0x12301f950>, centroid_history: <queue.Queue object at 0x122f5f090>, \n",
      "\n",
      "current label: 9, current_stats: [ 1490  1005   181   239 32261], current_centroid: [1574.87108273 1118.77821518], stats_history: <queue.Queue object at 0x12301f950>, centroid_history: <queue.Queue object at 0x122f5f090>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1490  1005   181   239 32261]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1574.87108273 1118.77821518]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdc8d0>, stats_history: <queue.Queue object at 0x124fb1190>, centroid_history: <queue.Queue object at 0x124dbdd90>, \n",
      "\n",
      "current label: 2, current_stats: [  174   172   507   470 89210], current_centroid: [424.6692187  392.29544894], stats_history: <queue.Queue object at 0x124fb1190>, centroid_history: <queue.Queue object at 0x124dbdd90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  174   172   507   470 89210]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[424.6692187  392.29544894]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f442d0>, stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1220a46d0>, \n",
      "\n",
      "current label: 3, current_stats: [  595   554   229   371 54963], current_centroid: [709.46074632 737.54916944], stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1220a46d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  595   554   229   371 54963]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[709.46074632 737.54916944]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3cc10>, stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "current label: 6, current_stats: [ 1041   854   216   180 29616], current_centroid: [1150.71562669  942.31712588], stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1041   854   216   180 29616]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1150.71562669  942.31712588]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa990>, stats_history: <queue.Queue object at 0x124fef2d0>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "current label: 8, current_stats: [   868    999   1247   1118 348146], current_centroid: [1595.47999977 1689.83939784], stats_history: <queue.Queue object at 0x124fef2d0>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   868    999   1247   1118 348146]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1595.47999977 1689.83939784]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fec8d0>, stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "current label: 9, current_stats: [ 1491  1002   183   237 32476], current_centroid: [1577.47419633 1115.08760315], stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1491  1002   183   237 32476]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1577.47419633 1115.08760315]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221760d0>, stats_history: <queue.Queue object at 0x124ff5fd0>, centroid_history: <queue.Queue object at 0x124ff7990>, \n",
      "\n",
      "current label: 2, current_stats: [  172   179   497   462 88143], current_centroid: [415.40758767 401.47489874], stats_history: <queue.Queue object at 0x124ff5fd0>, centroid_history: <queue.Queue object at 0x124ff7990>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  172   179   497   462 88143]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[415.40758767 401.47489874]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b3fad0>, stats_history: <queue.Queue object at 0x1221cfb10>, centroid_history: <queue.Queue object at 0x124fb2a10>, \n",
      "\n",
      "current label: 3, current_stats: [  591   546   229   363 54475], current_centroid: [704.9699128  726.29815512], stats_history: <queue.Queue object at 0x1221cfb10>, centroid_history: <queue.Queue object at 0x124fb2a10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  591   546   229   363 54475]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[704.9699128  726.29815512]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124d7f9d0>, stats_history: <queue.Queue object at 0x124e3fe50>, centroid_history: <queue.Queue object at 0x124e3eed0>, \n",
      "\n",
      "current label: 6, current_stats: [ 1045   857   213   182 29605], current_centroid: [1153.20368181  945.70214491], stats_history: <queue.Queue object at 0x124e3fe50>, centroid_history: <queue.Queue object at 0x124e3eed0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1045   857   213   182 29605]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1153.20368181  945.70214491]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3d0d0>, centroid_history: <queue.Queue object at 0x124e3eb50>, \n",
      "\n",
      "current label: 8, current_stats: [   911    994   1204   1123 347467], current_centroid: [1600.57413222 1693.02211433], stats_history: <queue.Queue object at 0x124e3d0d0>, centroid_history: <queue.Queue object at 0x124e3eb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   911    994   1204   1123 347467]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1600.57413222 1693.02211433]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3e410>, stats_history: <queue.Queue object at 0x124e3fb50>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "current label: 9, current_stats: [ 1492   999   186   237 32749], current_centroid: [1579.54361965 1111.69715106], stats_history: <queue.Queue object at 0x124e3fb50>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1492   999   186   237 32749]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1579.54361965 1111.69715106]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x11e7b9890>, stats_history: <queue.Queue object at 0x124fefcd0>, centroid_history: <queue.Queue object at 0x124fefe90>, \n",
      "\n",
      "current label: 1, current_stats: [  173   185   485   455 85846], current_centroid: [413.96351606 401.91801598], stats_history: <queue.Queue object at 0x124fefcd0>, centroid_history: <queue.Queue object at 0x124fefe90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  173   185   485   455 85846]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[413.96351606 401.91801598]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77250>, stats_history: <queue.Queue object at 0x124e5bd50>, centroid_history: <queue.Queue object at 0x124fe57d0>, \n",
      "\n",
      "current label: 2, current_stats: [  587   533   228   369 54003], current_centroid: [699.23806085 717.2395978 ], stats_history: <queue.Queue object at 0x124e5bd50>, centroid_history: <queue.Queue object at 0x124fe57d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  587   533   228   369 54003]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[699.23806085 717.2395978 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f1d0d0>, stats_history: <queue.Queue object at 0x124fb1c50>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 5, current_stats: [ 1047   860   211   185 29961], current_centroid: [1155.54364007  948.77968025], stats_history: <queue.Queue object at 0x124fb1c50>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1047   860   211   185 29961]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1155.54364007  948.77968025]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124d7f9d0>, stats_history: <queue.Queue object at 0x124e3ee90>, centroid_history: <queue.Queue object at 0x124e3ecd0>, \n",
      "\n",
      "current label: 7, current_stats: [   894    987   1219   1130 343933], current_centroid: [1583.51976693 1705.28492177], stats_history: <queue.Queue object at 0x124e3ee90>, centroid_history: <queue.Queue object at 0x124e3ecd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   894    987   1219   1130 343933]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1583.51976693 1705.28492177]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3cc10>, stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "current label: 8, current_stats: [ 1493   996   188   236 32723], current_centroid: [1581.49261987 1108.0982795 ], stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1493   996   188   236 32723]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1581.49261987 1108.0982795 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3d710>, centroid_history: <queue.Queue object at 0x124e3e650>, \n",
      "\n",
      "current label: 9, current_stats: [  780  1016   334   352 65130], current_centroid: [ 947.32410563 1189.11174574], stats_history: <queue.Queue object at 0x124e3d710>, centroid_history: <queue.Queue object at 0x124e3e650>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  780  1016   334   352 65130]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 947.32410563 1189.11174574]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5390>, stats_history: <queue.Queue object at 0x124e3fb50>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "current label: 1, current_stats: [    96    186    560    708 119587], current_centroid: [345.00487511 505.56827247], stats_history: <queue.Queue object at 0x124e3fb50>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[    96    186    560    708 119587]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[345.00487511 505.56827247]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x11e7b9890>, stats_history: <queue.Queue object at 0x124fef390>, centroid_history: <queue.Queue object at 0x124fef550>, \n",
      "\n",
      "current label: 2, current_stats: [  584   525   230   371 55092], current_centroid: [697.49954621 710.22807304], stats_history: <queue.Queue object at 0x124fef390>, centroid_history: <queue.Queue object at 0x124fef550>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  584   525   230   371 55092]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[697.49954621 710.22807304]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff5450>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "current label: 4, current_stats: [ 1047   862   210   187 29940], current_centroid: [1156.24021376  950.99195057], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1047   862   210   187 29940]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1156.24021376  950.99195057]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x1220a46d0>, centroid_history: <queue.Queue object at 0x124fb3d10>, \n",
      "\n",
      "current label: 6, current_stats: [   880    983   1234   1136 344055], current_centroid: [1583.6587348  1705.01452965], stats_history: <queue.Queue object at 0x1220a46d0>, centroid_history: <queue.Queue object at 0x124fb3d10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   880    983   1234   1136 344055]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1583.6587348  1705.01452965]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122217dd0>, stats_history: <queue.Queue object at 0x124b4d490>, centroid_history: <queue.Queue object at 0x124fc9990>, \n",
      "\n",
      "current label: 7, current_stats: [ 1494   992   190   236 33343], current_centroid: [1583.87160723 1104.44354137], stats_history: <queue.Queue object at 0x124b4d490>, centroid_history: <queue.Queue object at 0x124fc9990>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1494   992   190   236 33343]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1583.87160723 1104.44354137]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124d7f9d0>, stats_history: <queue.Queue object at 0x124e3e8d0>, centroid_history: <queue.Queue object at 0x124e3fd90>, \n",
      "\n",
      "current label: 8, current_stats: [  774  1014   334   351 64158], current_centroid: [ 943.13348296 1185.11470121], stats_history: <queue.Queue object at 0x124e3e8d0>, centroid_history: <queue.Queue object at 0x124e3fd90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  774  1014   334   351 64158]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 943.13348296 1185.11470121]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3d350>, stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "current label: 9, current_stats: [   182   1524    760    493 190678], current_centroid: [ 572.12665856 1751.48100987], stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   182   1524    760    493 190678]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 572.12665856 1751.48100987]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3f210>, \n",
      "\n",
      "current label: 1, current_stats: [  230   188   422   379 71358], current_centroid: [439.08747442 375.29391239], stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3f210>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  230   188   422   379 71358]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[439.08747442 375.29391239]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124feeb90>, stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3ccd0>, \n",
      "\n",
      "current label: 2, current_stats: [  581   517   230   372 54312], current_centroid: [693.54997054 703.49723818], stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3ccd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  581   517   230   372 54312]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[693.54997054 703.49723818]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124ff5450>, \n",
      "\n",
      "current label: 5, current_stats: [ 1049   865   208   187 29808], current_centroid: [1156.97728798  953.90224101], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124ff5450>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1049   865   208   187 29808]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1156.97728798  953.90224101]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f442d0>, stats_history: <queue.Queue object at 0x124fb0890>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 7, current_stats: [   949    977   1167   1142 328375], current_centroid: [1600.74018424 1695.44720213], stats_history: <queue.Queue object at 0x124fb0890>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   949    977   1167   1142 328375]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1600.74018424 1695.44720213]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e51250>, stats_history: <queue.Queue object at 0x124fc9250>, centroid_history: <queue.Queue object at 0x124b4ead0>, \n",
      "\n",
      "current label: 8, current_stats: [ 1495   989   191   237 33591], current_centroid: [1585.10342056 1101.73311304], stats_history: <queue.Queue object at 0x124fc9250>, centroid_history: <queue.Queue object at 0x124b4ead0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1495   989   191   237 33591]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1585.10342056 1101.73311304]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124d7f9d0>, stats_history: <queue.Queue object at 0x124e3d050>, centroid_history: <queue.Queue object at 0x124e3cb50>, \n",
      "\n",
      "current label: 9, current_stats: [  769  1012   333   349 64237], current_centroid: [ 938.01727976 1180.94373959], stats_history: <queue.Queue object at 0x124e3d050>, centroid_history: <queue.Queue object at 0x124e3cb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  769  1012   333   349 64237]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 938.01727976 1180.94373959]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3ef90>, stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3c810>, \n",
      "\n",
      "current label: 1, current_stats: [   101    191    544    688 112541], current_centroid: [346.08033517 504.94037728], stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3c810>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   101    191    544    688 112541]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[346.08033517 504.94037728]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3eb50>, centroid_history: <queue.Queue object at 0x124e3e510>, \n",
      "\n",
      "current label: 2, current_stats: [  578   510   228   372 54142], current_centroid: [690.32629013 695.33883122], stats_history: <queue.Queue object at 0x124e3eb50>, centroid_history: <queue.Queue object at 0x124e3e510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  578   510   228   372 54142]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[690.32629013 695.33883122]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77310>, stats_history: <queue.Queue object at 0x124fef3d0>, centroid_history: <queue.Queue object at 0x124fefd10>, \n",
      "\n",
      "current label: 4, current_stats: [ 1050   868   207   187 29371], current_centroid: [1157.60229478  956.76864935], stats_history: <queue.Queue object at 0x124fef3d0>, centroid_history: <queue.Queue object at 0x124fefd10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1050   868   207   187 29371]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1157.60229478  956.76864935]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff5450>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "current label: 6, current_stats: [ 1496   986   193   237 33231], current_centroid: [1588.20793837 1099.75932112], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1496   986   193   237 33231]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1588.20793837 1099.75932112]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b3fad0>, stats_history: <queue.Queue object at 0x124b7a150>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "current label: 7, current_stats: [   952    994   1161   1125 334076], current_centroid: [1599.89035429 1704.41184641], stats_history: <queue.Queue object at 0x124b7a150>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   952    994   1161   1125 334076]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1599.89035429 1704.41184641]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb1b90>, \n",
      "\n",
      "current label: 8, current_stats: [  762  1011   325   347 63405], current_centroid: [ 929.8434666  1175.50838262], stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb1b90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  762  1011   325   347 63405]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 929.8434666  1175.50838262]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122f6f710>, stats_history: <queue.Queue object at 0x124b4d490>, centroid_history: <queue.Queue object at 0x124fc9250>, \n",
      "\n",
      "current label: 9, current_stats: [   179   1519    775    507 194082], current_centroid: [ 570.78359147 1752.36685525], stats_history: <queue.Queue object at 0x124b4d490>, centroid_history: <queue.Queue object at 0x124fc9250>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   179   1519    775    507 194082]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 570.78359147 1752.36685525]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124d7f9d0>, stats_history: <queue.Queue object at 0x124e3e2d0>, centroid_history: <queue.Queue object at 0x124e3f7d0>, \n",
      "\n",
      "current label: 1, current_stats: [   103    197    532    670 109839], current_centroid: [345.47504985 503.27955462], stats_history: <queue.Queue object at 0x124e3e2d0>, centroid_history: <queue.Queue object at 0x124e3f7d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   103    197    532    670 109839]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[345.47504985 503.27955462]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3cc10>, stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3ef90>, \n",
      "\n",
      "current label: 2, current_stats: [  575   501   228   375 54529], current_centroid: [686.92178474 687.25063728], stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3ef90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  575   501   228   375 54529]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[686.92178474 687.25063728]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124feeb90>, stats_history: <queue.Queue object at 0x124e3ea10>, centroid_history: <queue.Queue object at 0x124e3ccd0>, \n",
      "\n",
      "current label: 4, current_stats: [ 1051   870   205   188 29456], current_centroid: [1157.49504345  959.38851168], stats_history: <queue.Queue object at 0x124e3ea10>, centroid_history: <queue.Queue object at 0x124e3ccd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1051   870   205   188 29456]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1157.49504345  959.38851168]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124ff5450>, \n",
      "\n",
      "current label: 7, current_stats: [ 1497   982   195   237 32981], current_centroid: [1591.17519178 1096.27124708], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124ff5450>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1497   982   195   237 32981]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1591.17519178 1096.27124708]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b7a150>, stats_history: <queue.Queue object at 0x124fb2690>, centroid_history: <queue.Queue object at 0x122197090>, \n",
      "\n",
      "current label: 8, current_stats: [   955    990   1158   1129 331191], current_centroid: [1598.72306011 1705.53103798], stats_history: <queue.Queue object at 0x124fb2690>, centroid_history: <queue.Queue object at 0x122197090>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   955    990   1158   1129 331191]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1598.72306011 1705.53103798]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b3fb50>, stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 9, current_stats: [  756  1009   325   346 62378], current_centroid: [ 924.79558498 1171.25808779], stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  756  1009   325   346 62378]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 924.79558498 1171.25808779]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fc8450>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x124b4d150>, \n",
      "\n",
      "current label: 1, current_stats: [   105    202    523    655 107104], current_centroid: [345.5479814  499.26659135], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x124b4d150>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   105    202    523    655 107104]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[345.5479814  499.26659135]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124d7f9d0>, stats_history: <queue.Queue object at 0x124e3eed0>, centroid_history: <queue.Queue object at 0x124e3f690>, \n",
      "\n",
      "current label: 2, current_stats: [  572   494   228   377 54865], current_centroid: [684.15162672 680.4805067 ], stats_history: <queue.Queue object at 0x124e3eed0>, centroid_history: <queue.Queue object at 0x124e3f690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  572   494   228   377 54865]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[684.15162672 680.4805067 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3f210>, centroid_history: <queue.Queue object at 0x124e3d0d0>, \n",
      "\n",
      "current label: 4, current_stats: [ 1052   872   201   191 28888], current_centroid: [1158.58830656  961.55746331], stats_history: <queue.Queue object at 0x124e3f210>, centroid_history: <queue.Queue object at 0x124e3d0d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1052   872   201   191 28888]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1158.58830656  961.55746331]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122f5f090>, stats_history: <queue.Queue object at 0x124b77250>, centroid_history: <queue.Queue object at 0x124e59d10>, \n",
      "\n",
      "current label: 7, current_stats: [ 1497   980   199   235 32739], current_centroid: [1593.74904548 1092.93439018], stats_history: <queue.Queue object at 0x124b77250>, centroid_history: <queue.Queue object at 0x124e59d10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1497   980   199   235 32739]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1593.74904548 1092.93439018]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff5450>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "current label: 8, current_stats: [   957    986   1149   1126 331075], current_centroid: [1599.86159329 1704.70483727], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   957    986   1149   1126 331075]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1599.86159329 1704.70483727]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122197090>, stats_history: <queue.Queue object at 0x124b3fad0>, centroid_history: <queue.Queue object at 0x124fb1ed0>, \n",
      "\n",
      "current label: 9, current_stats: [  751  1008   325   344 63055], current_centroid: [ 920.56187455 1168.23975894], stats_history: <queue.Queue object at 0x124b3fad0>, centroid_history: <queue.Queue object at 0x124fb1ed0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  751  1008   325   344 63055]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 920.56187455 1168.23975894]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x1220a46d0>, centroid_history: <queue.Queue object at 0x124fb0890>, \n",
      "\n",
      "current label: 1, current_stats: [  249   207   371   389 64955], current_centroid: [425.24512355 393.14737895], stats_history: <queue.Queue object at 0x1220a46d0>, centroid_history: <queue.Queue object at 0x124fb0890>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  249   207   371   389 64955]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[425.24512355 393.14737895]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124dc4c50>, stats_history: <queue.Queue object at 0x124b4ead0>, centroid_history: <queue.Queue object at 0x124fc8450>, \n",
      "\n",
      "current label: 2, current_stats: [  569   489   230   374 54643], current_centroid: [681.98534121 674.01271892], stats_history: <queue.Queue object at 0x124b4ead0>, centroid_history: <queue.Queue object at 0x124fc8450>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  569   489   230   374 54643]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[681.98534121 674.01271892]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3e510>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "current label: 5, current_stats: [ 1053   873   199   196 29066], current_centroid: [1157.50089452  966.31566091], stats_history: <queue.Queue object at 0x124e3e510>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1053   873   199   196 29066]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1157.50089452  966.31566091]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x11e7b9890>, stats_history: <queue.Queue object at 0x124fefd10>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "current label: 7, current_stats: [   963    972   1149   1146 338934], current_centroid: [1610.87347094 1693.13218208], stats_history: <queue.Queue object at 0x124fefd10>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   963    972   1149   1146 338934]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1610.87347094 1693.13218208]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124ff5450>, \n",
      "\n",
      "current label: 9, current_stats: [ 1498   979   201   232 32993], current_centroid: [1594.64501561 1089.76861759], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124ff5450>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1498   979   201   232 32993]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1594.64501561 1089.76861759]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e43d10>, stats_history: <queue.Queue object at 0x124fb1210>, centroid_history: <queue.Queue object at 0x1221cfb10>, \n",
      "\n",
      "current label: 1, current_stats: [  216   212   396   397 68277], current_centroid: [408.73200346 408.55223575], stats_history: <queue.Queue object at 0x124fb1210>, centroid_history: <queue.Queue object at 0x1221cfb10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  216   212   396   397 68277]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[408.73200346 408.55223575]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1220a46d0>, stats_history: <queue.Queue object at 0x124fb1b90>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 2, current_stats: [  566   474   231   385 55527], current_centroid: [678.22585409 664.32294199], stats_history: <queue.Queue object at 0x124fb1b90>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  566   474   231   385 55527]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[678.22585409 664.32294199]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3ef90>, stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "current label: 5, current_stats: [ 1053   875   196   199 29472], current_centroid: [1156.98110071  967.63012351], stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1053   875   196   199 29472]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1156.98110071  967.63012351]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x11e7b9890>, stats_history: <queue.Queue object at 0x124fef4d0>, centroid_history: <queue.Queue object at 0x124fefed0>, \n",
      "\n",
      "current label: 8, current_stats: [ 1499   977   204   231 33433], current_centroid: [1596.98830497 1087.29611462], stats_history: <queue.Queue object at 0x124fef4d0>, centroid_history: <queue.Queue object at 0x124fefed0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1499   977   204   231 33433]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1596.98830497 1087.29611462]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea4cd0>, stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x1236bb110>, \n",
      "\n",
      "current label: 9, current_stats: [   968    993   1143   1119 333492], current_centroid: [1604.70646372 1702.28013865], stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x1236bb110>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   968    993   1143   1119 333492]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1604.70646372 1702.28013865]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f1df50>, stats_history: <queue.Queue object at 0x124ff65d0>, centroid_history: <queue.Queue object at 0x1221760d0>, \n",
      "\n",
      "current label: 1, current_stats: [  113   220   494   605 96989], current_centroid: [342.54615472 498.78534679], stats_history: <queue.Queue object at 0x124ff65d0>, centroid_history: <queue.Queue object at 0x1221760d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  113   220   494   605 96989]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[342.54615472 498.78534679]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221cfb10>, stats_history: <queue.Queue object at 0x123d42150>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "current label: 2, current_stats: [  564   467   216   376 53114], current_centroid: [670.81744926 648.88854163], stats_history: <queue.Queue object at 0x123d42150>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  564   467   216   376 53114]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[670.81744926 648.88854163]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1245db650>, stats_history: <queue.Queue object at 0x124b4d490>, centroid_history: <queue.Queue object at 0x122f6f710>, \n",
      "\n",
      "current label: 4, current_stats: [ 1056   877   193   202 30096], current_centroid: [1160.00451887  969.63330675], stats_history: <queue.Queue object at 0x124b4d490>, centroid_history: <queue.Queue object at 0x122f6f710>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1056   877   193   202 30096]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1160.00451887  969.63330675]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3cc10>, stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3ef90>, \n",
      "\n",
      "current label: 6, current_stats: [ 1501   976   206   230 33079], current_centroid: [1599.05913117 1084.86786179], stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3ef90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1501   976   206   230 33079]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1599.05913117 1084.86786179]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3d0d0>, centroid_history: <queue.Queue object at 0x124e3eb50>, \n",
      "\n",
      "current label: 7, current_stats: [   969   1009   1142   1104 335599], current_centroid: [1605.13462495 1702.02391247], stats_history: <queue.Queue object at 0x124e3d0d0>, centroid_history: <queue.Queue object at 0x124e3eb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   969   1009   1142   1104 335599]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1605.13462495 1702.02391247]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124feeb90>, stats_history: <queue.Queue object at 0x124e3ccd0>, centroid_history: <queue.Queue object at 0x124e3edd0>, \n",
      "\n",
      "current label: 8, current_stats: [  728  1011   326   327 61740], current_centroid: [ 904.7069161  1156.92955944], stats_history: <queue.Queue object at 0x124e3ccd0>, centroid_history: <queue.Queue object at 0x124e3edd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  728  1011   326   327 61740]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 904.7069161  1156.92955944]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77310>, stats_history: <queue.Queue object at 0x124fef5d0>, centroid_history: <queue.Queue object at 0x124fefcd0>, \n",
      "\n",
      "current label: 9, current_stats: [   174   1520    804    507 197942], current_centroid: [ 577.02015742 1755.08313041], stats_history: <queue.Queue object at 0x124fef5d0>, centroid_history: <queue.Queue object at 0x124fefcd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   174   1520    804    507 197942]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 577.02015742 1755.08313041]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1236bb110>, stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x122ea4cd0>, \n",
      "\n",
      "current label: 1, current_stats: [  213   225   388   363 63721], current_centroid: [406.11183126 405.93000738], stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x122ea4cd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  213   225   388   363 63721]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[406.11183126 405.93000738]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221760d0>, stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff5910>, \n",
      "\n",
      "current label: 2, current_stats: [  558   460   215   346 50833], current_centroid: [663.34676293 632.21867684], stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff5910>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  558   460   215   346 50833]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[663.34676293 632.21867684]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124718f90>, stats_history: <queue.Queue object at 0x122f6f510>, centroid_history: <queue.Queue object at 0x124b4d490>, \n",
      "\n",
      "current label: 5, current_stats: [ 1058   879   190   205 30001], current_centroid: [1160.78577381  973.45605146], stats_history: <queue.Queue object at 0x122f6f510>, centroid_history: <queue.Queue object at 0x124b4d490>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1058   879   190   205 30001]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1160.78577381  973.45605146]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3ef90>, stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "current label: 7, current_stats: [ 1502   974   210   227 33921], current_centroid: [1603.4147873  1081.97674007], stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1502   974   210   227 33921]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1603.4147873  1081.97674007]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3d710>, centroid_history: <queue.Queue object at 0x124e3e650>, \n",
      "\n",
      "current label: 8, current_stats: [   971   1004   1143   1106 338632], current_centroid: [1611.23448759 1697.99743379], stats_history: <queue.Queue object at 0x124e3d710>, centroid_history: <queue.Queue object at 0x124e3e650>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   971   1004   1143   1106 338632]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1611.23448759 1697.99743379]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5390>, stats_history: <queue.Queue object at 0x124e3ccd0>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "current label: 9, current_stats: [  726  1008   322   326 60277], current_centroid: [ 900.66280671 1155.6531181 ], stats_history: <queue.Queue object at 0x124e3ccd0>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  726  1008   322   326 60277]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 900.66280671 1155.6531181 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x11e7b9890>, stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fefe90>, \n",
      "\n",
      "current label: 1, current_stats: [  119   235   475   578 89287], current_centroid: [338.41962436 498.79099981], stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fefe90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  119   235   475   578 89287]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[338.41962436 498.79099981]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea4cd0>, stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x1236bb110>, \n",
      "\n",
      "current label: 2, current_stats: [  552   453   216   345 50899], current_centroid: [658.85481051 623.49959724], stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x1236bb110>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  552   453   216   345 50899]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[658.85481051 623.49959724]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5310>, stats_history: <queue.Queue object at 0x1221cfb10>, centroid_history: <queue.Queue object at 0x124fb1210>, \n",
      "\n",
      "current label: 4, current_stats: [ 1061   879   185   210 30355], current_centroid: [1161.953352    975.29118761], stats_history: <queue.Queue object at 0x1221cfb10>, centroid_history: <queue.Queue object at 0x124fb1210>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1061   879   185   210 30355]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1161.953352    975.29118761]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1236b9b10>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "current label: 6, current_stats: [ 1503   973   214   223 33802], current_centroid: [1606.17564049 1079.30755577], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1503   973   214   223 33802]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1606.17564049 1079.30755577]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f4eb90>, stats_history: <queue.Queue object at 0x124e3eed0>, centroid_history: <queue.Queue object at 0x124e3cb50>, \n",
      "\n",
      "current label: 7, current_stats: [   972   1004   1143   1106 337947], current_centroid: [1607.23088236 1701.7778409 ], stats_history: <queue.Queue object at 0x124e3eed0>, centroid_history: <queue.Queue object at 0x124e3cb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   972   1004   1143   1106 337947]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1607.23088236 1701.7778409 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3cc10>, stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3ef90>, \n",
      "\n",
      "current label: 8, current_stats: [  724  1006   320   322 60699], current_centroid: [ 895.03238933 1151.96385443], stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3ef90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  724  1006   320   322 60699]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 895.03238933 1151.96385443]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3f210>, \n",
      "\n",
      "current label: 9, current_stats: [   193   1521    790    505 200079], current_centroid: [ 578.94753073 1755.16436508], stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3f210>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   193   1521    790    505 200079]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 578.94753073 1755.16436508]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124feeb90>, stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e710>, \n",
      "\n",
      "current label: 1, current_stats: [  118   239   470   569 88900], current_centroid: [335.12652418 504.58460067], stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e710>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  118   239   470   569 88900]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[335.12652418 504.58460067]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f8b090>, stats_history: <queue.Queue object at 0x124fef4d0>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "current label: 2, current_stats: [  546   449   217   339 50384], current_centroid: [654.58292315 615.31567561], stats_history: <queue.Queue object at 0x124fef4d0>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  546   449   217   339 50384]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[654.58292315 615.31567561]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221760d0>, stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff65d0>, \n",
      "\n",
      "current label: 4, current_stats: [ 1064   879   182   214 30410], current_centroid: [1162.7719829   978.39552779], stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff65d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1064   879   182   214 30410]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1162.7719829   978.39552779]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f1d0d0>, stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 6, current_stats: [ 1504   972   217   222 34425], current_centroid: [1608.21246187 1077.25966594], stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1504   972   217   222 34425]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1608.21246187 1077.25966594]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122f6f510>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x1236b9b10>, \n",
      "\n",
      "current label: 7, current_stats: [ 1285   987   115   115 12640], current_centroid: [1343.04841772 1043.18330696], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x1236b9b10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1285   987   115   115 12640]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1343.04841772 1043.18330696]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3c910>, centroid_history: <queue.Queue object at 0x124e3d050>, \n",
      "\n",
      "current label: 8, current_stats: [   979    997   1136   1115 337414], current_centroid: [1606.19978128 1705.27526125], stats_history: <queue.Queue object at 0x124e3c910>, centroid_history: <queue.Queue object at 0x124e3d050>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   979    997   1136   1115 337414]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1606.19978128 1705.27526125]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3ef90>, stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "current label: 9, current_stats: [  723  1009   317   314 61108], current_centroid: [ 889.20800877 1147.98625385], stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  723  1009   317   314 61108]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 889.20800877 1147.98625385]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3eb50>, centroid_history: <queue.Queue object at 0x124e3e510>, \n",
      "\n",
      "current label: 1, current_stats: [  121   243   461   563 86276], current_centroid: [342.03794798 500.30075571], stats_history: <queue.Queue object at 0x124e3eb50>, centroid_history: <queue.Queue object at 0x124e3e510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  121   243   461   563 86276]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[342.03794798 500.30075571]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa650>, stats_history: <queue.Queue object at 0x124e3edd0>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "current label: 2, current_stats: [  539   445   219   336 50093], current_centroid: [650.18918811 608.34869143], stats_history: <queue.Queue object at 0x124e3edd0>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  539   445   219   336 50093]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[650.18918811 608.34869143]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea4cd0>, stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "current label: 4, current_stats: [ 1067   880   179   217 30759], current_centroid: [1163.26297994  981.70548457], stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1067   880   179   217 30759]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1163.26297994  981.70548457]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5310>, stats_history: <queue.Queue object at 0x124fc07d0>, centroid_history: <queue.Queue object at 0x124fb1190>, \n",
      "\n",
      "current label: 6, current_stats: [ 1505   971   220   222 34919], current_centroid: [1610.44697729 1075.68744809], stats_history: <queue.Queue object at 0x124fc07d0>, centroid_history: <queue.Queue object at 0x124fb1190>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1505   971   220   222 34919]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1610.44697729 1075.68744809]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb0890>, \n",
      "\n",
      "current label: 7, current_stats: [1296  985  105   94 9232], current_centroid: [1348.05210139 1031.64893847], stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb0890>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1296  985  105   94 9232]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1348.05210139 1031.64893847]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1236b9b10>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "current label: 8, current_stats: [   984   1006   1132   1107 337122], current_centroid: [1601.84178131 1707.76677879], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   984   1006   1132   1107 337122]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1601.84178131 1707.76677879]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3fd90>, centroid_history: <queue.Queue object at 0x124e3f7d0>, \n",
      "\n",
      "current label: 9, current_stats: [  722  1014   314   308 60601], current_centroid: [ 885.74474019 1149.47175789], stats_history: <queue.Queue object at 0x124e3fd90>, centroid_history: <queue.Queue object at 0x124e3f7d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  722  1014   314   308 60601]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 885.74474019 1149.47175789]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3d690>, stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3d390>, \n",
      "\n",
      "current label: 1, current_stats: [  122   248   446   554 85768], current_centroid: [335.12652738 507.16291624], stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3d390>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  122   248   446   554 85768]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[335.12652738 507.16291624]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3e650>, centroid_history: <queue.Queue object at 0x124e3e7d0>, \n",
      "\n",
      "current label: 2, current_stats: [  533   438   220   335 49645], current_centroid: [645.07197099 600.54583543], stats_history: <queue.Queue object at 0x124e3e650>, centroid_history: <queue.Queue object at 0x124e3e7d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  533   438   220   335 49645]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[645.07197099 600.54583543]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f9a2d0>, stats_history: <queue.Queue object at 0x124fefe90>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "current label: 4, current_stats: [ 1069   881   176   219 30901], current_centroid: [1163.54163296  984.24646452], stats_history: <queue.Queue object at 0x124fefe90>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1069   881   176   219 30901]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1163.54163296  984.24646452]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221760d0>, stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff5450>, \n",
      "\n",
      "current label: 6, current_stats: [ 1508   971   222   217 34531], current_centroid: [1614.10408039 1073.16023283], stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff5450>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1508   971   222   217 34531]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1614.10408039 1073.16023283]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fc07d0>, stats_history: <queue.Queue object at 0x124fb1210>, centroid_history: <queue.Queue object at 0x122ea5310>, \n",
      "\n",
      "current label: 7, current_stats: [ 1285   979   115   120 12097], current_centroid: [1343.60056212 1036.87418368], stats_history: <queue.Queue object at 0x124fb1210>, centroid_history: <queue.Queue object at 0x122ea5310>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1285   979   115   120 12097]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1343.60056212 1036.87418368]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b3fb50>, stats_history: <queue.Queue object at 0x124fb1b90>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 8, current_stats: [   988    994   1124   1120 330243], current_centroid: [1604.34737148 1702.11514854], stats_history: <queue.Queue object at 0x124fb1b90>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   988    994   1124   1120 330243]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1604.34737148 1702.11514854]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122f6f510>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x124b4d490>, \n",
      "\n",
      "current label: 9, current_stats: [  721  1018   312   302 60813], current_centroid: [ 883.2978475  1151.04791739], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x124b4d490>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  721  1018   312   302 60813]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 883.2978475  1151.04791739]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3ecd0>, centroid_history: <queue.Queue object at 0x124e3e2d0>, \n",
      "\n",
      "current label: 1, current_stats: [  122   254   442   543 87098], current_centroid: [334.24114216 505.15193231], stats_history: <queue.Queue object at 0x124e3ecd0>, centroid_history: <queue.Queue object at 0x124e3e2d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  122   254   442   543 87098]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[334.24114216 505.15193231]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3cc10>, stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3d690>, \n",
      "\n",
      "current label: 2, current_stats: [  527   428   220   335 49297], current_centroid: [639.30957259 590.66815425], stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3d690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  527   428   220   335 49297]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[639.30957259 590.66815425]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5390>, stats_history: <queue.Queue object at 0x124e3edd0>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "current label: 4, current_stats: [ 1071   882   173   222 31648], current_centroid: [1163.51178589  986.62702224], stats_history: <queue.Queue object at 0x124e3edd0>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1071   882   173   222 31648]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1163.51178589  986.62702224]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea4cd0>, stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "current label: 6, current_stats: [ 1509   971   226   213 34588], current_centroid: [1617.38944142 1071.13513357], stats_history: <queue.Queue object at 0x124fefa10>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1509   971   226   213 34588]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1617.38944142 1071.13513357]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f1df50>, stats_history: <queue.Queue object at 0x124ff65d0>, centroid_history: <queue.Queue object at 0x1221760d0>, \n",
      "\n",
      "current label: 7, current_stats: [ 1273   975   130   104 12877], current_centroid: [1337.21581114 1027.20983148], stats_history: <queue.Queue object at 0x124ff65d0>, centroid_history: <queue.Queue object at 0x1221760d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1273   975   130   104 12877]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1337.21581114 1027.20983148]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5310>, stats_history: <queue.Queue object at 0x124b3fad0>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "current label: 8, current_stats: [   991    989   1125   1128 338333], current_centroid: [1606.85644025 1702.1433765 ], stats_history: <queue.Queue object at 0x124b3fad0>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   991    989   1125   1128 338333]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1606.85644025 1702.1433765 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x1220a46d0>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "current label: 9, current_stats: [  717  1022   314   292 60460], current_centroid: [ 878.74161429 1152.56042011], stats_history: <queue.Queue object at 0x1220a46d0>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  717  1022   314   292 60460]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 878.74161429 1152.56042011]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1236b9b10>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "current label: 1, current_stats: [  124   264   429   528 83783], current_centroid: [329.27121254 511.9363594 ], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  124   264   429   528 83783]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[329.27121254 511.9363594 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3fe90>, centroid_history: <queue.Queue object at 0x124e3eed0>, \n",
      "\n",
      "current label: 2, current_stats: [  522   420   221   336 50130], current_centroid: [635.40345103 583.13694395], stats_history: <queue.Queue object at 0x124e3fe90>, centroid_history: <queue.Queue object at 0x124e3eed0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  522   420   221   336 50130]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[635.40345103 583.13694395]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3e650>, centroid_history: <queue.Queue object at 0x124e3e7d0>, \n",
      "\n",
      "current label: 4, current_stats: [ 1075   881   168   227 32158], current_centroid: [1163.15414516  989.12416817], stats_history: <queue.Queue object at 0x124e3e650>, centroid_history: <queue.Queue object at 0x124e3e7d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1075   881   168   227 32158]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1163.15414516  989.12416817]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f8b090>, stats_history: <queue.Queue object at 0x124fef390>, centroid_history: <queue.Queue object at 0x124fef4d0>, \n",
      "\n",
      "current label: 6, current_stats: [ 1510   971   229   209 34448], current_centroid: [1620.46037506 1069.40063284], stats_history: <queue.Queue object at 0x124fef390>, centroid_history: <queue.Queue object at 0x124fef4d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1510   971   229   209 34448]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1620.46037506 1069.40063284]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77250>, stats_history: <queue.Queue object at 0x124f73850>, centroid_history: <queue.Queue object at 0x124fe69d0>, \n",
      "\n",
      "current label: 7, current_stats: [1313  980   89   92 8030], current_centroid: [1357.57210461 1024.94669988], stats_history: <queue.Queue object at 0x124f73850>, centroid_history: <queue.Queue object at 0x124fe69d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1313  980   89   92 8030]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1357.57210461 1024.94669988]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221760d0>, stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff5910>, \n",
      "\n",
      "current label: 8, current_stats: [   997    982   1119   1136 335857], current_centroid: [1607.62554004 1701.66922232], stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff5910>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   997    982   1119   1136 335857]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1607.62554004 1701.66922232]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b3fad0>, stats_history: <queue.Queue object at 0x124fb1190>, centroid_history: <queue.Queue object at 0x122ea5310>, \n",
      "\n",
      "current label: 9, current_stats: [  713  1022   315   287 59988], current_centroid: [ 875.22012736 1150.53842435], stats_history: <queue.Queue object at 0x124fb1190>, centroid_history: <queue.Queue object at 0x122ea5310>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  713  1022   315   287 59988]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 875.22012736 1150.53842435]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1220a46d0>, stats_history: <queue.Queue object at 0x124fb0890>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 1, current_stats: [  126   273   416   517 79517], current_centroid: [325.291925   517.73616962], stats_history: <queue.Queue object at 0x124fb0890>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  126   273   416   517 79517]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[325.291925   517.73616962]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122f6f510>, stats_history: <queue.Queue object at 0x124dc4c50>, centroid_history: <queue.Queue object at 0x124b4ead0>, \n",
      "\n",
      "current label: 2, current_stats: [  518   413   221   334 50011], current_centroid: [631.61466477 574.93815361], stats_history: <queue.Queue object at 0x124dc4c50>, centroid_history: <queue.Queue object at 0x124b4ead0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  518   413   221   334 50011]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[631.61466477 574.93815361]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3cc10>, stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3d690>, \n",
      "\n",
      "current label: 4, current_stats: [ 1077   882   165   228 32250], current_centroid: [1162.67531783  991.41389147], stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3d690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1077   882   165   228 32250]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1162.67531783  991.41389147]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa990>, stats_history: <queue.Queue object at 0x124e3e710>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "current label: 6, current_stats: [ 1511   970   232   208 34450], current_centroid: [1623.10142235 1067.90476052], stats_history: <queue.Queue object at 0x124e3e710>, centroid_history: <queue.Queue object at 0x124feeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1511   970   232   208 34450]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1623.10142235 1067.90476052]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e33d10>, stats_history: <queue.Queue object at 0x124fed490>, centroid_history: <queue.Queue object at 0x124fefed0>, \n",
      "\n",
      "current label: 7, current_stats: [   999    984   1116   1135 339343], current_centroid: [1607.44932119 1701.63372163], stats_history: <queue.Queue object at 0x124fed490>, centroid_history: <queue.Queue object at 0x124fefed0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   999    984   1116   1135 339343]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1607.44932119 1701.63372163]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221b3350>, stats_history: <queue.Queue object at 0x124f73850>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "current label: 8, current_stats: [1294 1019   96   87 8312], current_centroid: [1341.45813282 1062.14100096], stats_history: <queue.Queue object at 0x124f73850>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1294 1019   96   87 8312]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1341.45813282 1062.14100096]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f1df50>, stats_history: <queue.Queue object at 0x124ff5450>, centroid_history: <queue.Queue object at 0x1221760d0>, \n",
      "\n",
      "current label: 9, current_stats: [  708  1023   318   281 59845], current_centroid: [ 872.29307377 1150.17710753], stats_history: <queue.Queue object at 0x124ff5450>, centroid_history: <queue.Queue object at 0x1221760d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  708  1023   318   281 59845]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 872.29307377 1150.17710753]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 1, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5310>, stats_history: <queue.Queue object at 0x124fc07d0>, centroid_history: <queue.Queue object at 0x124fb2690>, \n",
      "\n",
      "current label: 1, current_stats: [  130   293   398   492 76200], current_centroid: [318.03877953 526.00332021], stats_history: <queue.Queue object at 0x124fc07d0>, centroid_history: <queue.Queue object at 0x124fb2690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  130   293   398   492 76200]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[318.03877953 526.00332021]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124f442d0>, centroid_history: <queue.Queue object at 0x124fb1b90>, \n",
      "\n",
      "current label: 2, current_stats: [  513   406   222   333 49970], current_centroid: [627.01761057 567.30710426], stats_history: <queue.Queue object at 0x124f442d0>, centroid_history: <queue.Queue object at 0x124fb1b90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  513   406   222   333 49970]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[627.01761057 567.30710426]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fcb150>, stats_history: <queue.Queue object at 0x124dc5050>, centroid_history: <queue.Queue object at 0x1245db650>, \n",
      "\n",
      "current label: 3, current_stats: [   997    835   1116   1286 361835], current_centroid: [1635.03382757 1648.75226001], stats_history: <queue.Queue object at 0x124dc5050>, centroid_history: <queue.Queue object at 0x1245db650>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   997    835   1116   1286 361835]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1635.03382757 1648.75226001]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3d050>, centroid_history: <queue.Queue object at 0x124e3fe50>, \n",
      "\n",
      "current label: 4, current_stats: [ 1078   882   162   230 32229], current_centroid: [1161.96788607  993.04952062], stats_history: <queue.Queue object at 0x124e3d050>, centroid_history: <queue.Queue object at 0x124e3fe50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1078   882   162   230 32229]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1161.96788607  993.04952062]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3c9d0>, centroid_history: <queue.Queue object at 0x124e3eb50>, \n",
      "\n",
      "current label: 6, current_stats: [ 1513   970   234   205 34507], current_centroid: [1625.81334222 1065.93908482], stats_history: <queue.Queue object at 0x124e3c9d0>, centroid_history: <queue.Queue object at 0x124e3eb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1513   970   234   205 34507]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1625.81334222 1065.93908482]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124feeb90>, stats_history: <queue.Queue object at 0x124e3e710>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "current label: 7, current_stats: [ 1277   975   111   105 10954], current_centroid: [1330.12716816 1025.75953989], stats_history: <queue.Queue object at 0x124e3e710>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1277   975   111   105 10954]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1330.12716816 1025.75953989]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f9a2d0>, stats_history: <queue.Queue object at 0x124fed490>, centroid_history: <queue.Queue object at 0x124fefe90>, \n",
      "\n",
      "current label: 8, current_stats: [  700  1024   324   276 60072], current_centroid: [ 868.61268145 1149.37659808], stats_history: <queue.Queue object at 0x124fed490>, centroid_history: <queue.Queue object at 0x124fefe90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  700  1024   324   276 60072]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 868.61268145 1149.37659808]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x121b60590>, stats_history: <queue.Queue object at 0x124fb1ed0>, centroid_history: <queue.Queue object at 0x122ea5310>, \n",
      "\n",
      "current label: 2, current_stats: [   993    841   1123   1282 348874], current_centroid: [1640.51369836 1643.75074096], stats_history: <queue.Queue object at 0x124fb1ed0>, centroid_history: <queue.Queue object at 0x122ea5310>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   993    841   1123   1282 348874]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1640.51369836 1643.75074096]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f442d0>, stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 3, current_stats: [ 1081   883   160   231 32133], current_centroid: [1162.33541842  994.8734323 ], stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1081   883   160   231 32133]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1162.33541842  994.8734323 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3f7d0>, centroid_history: <queue.Queue object at 0x124e3f690>, \n",
      "\n",
      "current label: 5, current_stats: [ 1515   968   235   206 34077], current_centroid: [1628.9577721  1065.31158846], stats_history: <queue.Queue object at 0x124e3f7d0>, centroid_history: <queue.Queue object at 0x124e3f690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1515   968   235   206 34077]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1628.9577721  1065.31158846]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3cc10>, stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3d690>, \n",
      "\n",
      "current label: 6, current_stats: [1277  989   79   79 6234], current_centroid: [1316.01860764 1027.98171319], stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3d690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1277  989   79   79 6234]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1316.01860764 1027.98171319]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3e7d0>, centroid_history: <queue.Queue object at 0x124e3dbd0>, \n",
      "\n",
      "current label: 7, current_stats: [  694  1026   325   268 59530], current_centroid: [ 863.84982362 1148.41651268], stats_history: <queue.Queue object at 0x124e3e7d0>, centroid_history: <queue.Queue object at 0x124e3dbd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  694  1026   325   268 59530]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 863.84982362 1148.41651268]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124dc99d0>, stats_history: <queue.Queue object at 0x124fef4d0>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "current label: 9, current_stats: [  201  1521   136   158 18823], current_centroid: [ 268.74249588 1595.72257345], stats_history: <queue.Queue object at 0x124fef4d0>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  201  1521   136   158 18823]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 268.74249588 1595.72257345]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff7990>, stats_history: <queue.Queue object at 0x124ff5fd0>, centroid_history: <queue.Queue object at 0x124fe5710>, \n",
      "\n",
      "current label: 2, current_stats: [   988    842   1129   1280 345235], current_centroid: [1638.83372196 1641.31370805], stats_history: <queue.Queue object at 0x124ff5fd0>, centroid_history: <queue.Queue object at 0x124fe5710>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   988    842   1129   1280 345235]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1638.83372196 1641.31370805]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5310>, stats_history: <queue.Queue object at 0x124b3fad0>, centroid_history: <queue.Queue object at 0x124fb1190>, \n",
      "\n",
      "current label: 3, current_stats: [ 1099   895   143   222 28401], current_centroid: [1169.60635189 1006.49248266], stats_history: <queue.Queue object at 0x124b3fad0>, centroid_history: <queue.Queue object at 0x124fb1190>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1099   895   143   222 28401]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1169.60635189 1006.49248266]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124f1d0d0>, centroid_history: <queue.Queue object at 0x124fb0890>, \n",
      "\n",
      "current label: 4, current_stats: [  462   906   229   242 38447], current_centroid: [ 568.86802611 1018.22956277], stats_history: <queue.Queue object at 0x124f1d0d0>, centroid_history: <queue.Queue object at 0x124fb0890>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  462   906   229   242 38447]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 568.86802611 1018.22956277]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122197190>, stats_history: <queue.Queue object at 0x124dc4c50>, centroid_history: <queue.Queue object at 0x124b4d150>, \n",
      "\n",
      "current label: 5, current_stats: [ 1534   967   220   178 30643], current_centroid: [1641.04128186 1052.15471723], stats_history: <queue.Queue object at 0x124dc4c50>, centroid_history: <queue.Queue object at 0x124b4d150>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1534   967   220   178 30643]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1641.04128186 1052.15471723]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3e2d0>, centroid_history: <queue.Queue object at 0x124e3e8d0>, \n",
      "\n",
      "current label: 6, current_stats: [1300 1020   88   85 7409], current_centroid: [1343.55432582 1062.24051829], stats_history: <queue.Queue object at 0x124e3e2d0>, centroid_history: <queue.Queue object at 0x124e3e8d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1300 1020   88   85 7409]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1343.55432582 1062.24051829]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3d690>, stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "current label: 7, current_stats: [  688  1028   307   228 53812], current_centroid: [ 849.03320821 1138.34860254], stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3cc10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  688  1028   307   228 53812]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 849.03320821 1138.34860254]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e43d10>, stats_history: <queue.Queue object at 0x124b77250>, centroid_history: <queue.Queue object at 0x124fe57d0>, \n",
      "\n",
      "current label: 2, current_stats: [   982    845   1132   1280 345594], current_centroid: [1633.17814256 1647.1813197 ], stats_history: <queue.Queue object at 0x124b77250>, centroid_history: <queue.Queue object at 0x124fe57d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   982    845   1132   1280 345594]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1633.17814256 1647.1813197 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124dbf9d0>, centroid_history: <queue.Queue object at 0x124ff65d0>, \n",
      "\n",
      "current label: 3, current_stats: [ 1103   899   139   220 26903], current_centroid: [1171.72560681 1009.85076014], stats_history: <queue.Queue object at 0x124dbf9d0>, centroid_history: <queue.Queue object at 0x124ff65d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1103   899   139   220 26903]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1171.72560681 1009.85076014]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b3fad0>, stats_history: <queue.Queue object at 0x124fb0550>, centroid_history: <queue.Queue object at 0x123c14850>, \n",
      "\n",
      "current label: 4, current_stats: [  463   908   232   236 38332], current_centroid: [ 570.89035271 1016.64893562], stats_history: <queue.Queue object at 0x124fb0550>, centroid_history: <queue.Queue object at 0x123c14850>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  463   908   232   236 38332]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 570.89035271 1016.64893562]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f1d0d0>, stats_history: <queue.Queue object at 0x124fb1b90>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 5, current_stats: [ 1536   966   221   175 30621], current_centroid: [1644.59243656 1050.15721237], stats_history: <queue.Queue object at 0x124fb1b90>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1536   966   221   175 30621]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1644.59243656 1050.15721237]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122f6f510>, stats_history: <queue.Queue object at 0x124b4d150>, centroid_history: <queue.Queue object at 0x122197190>, \n",
      "\n",
      "current label: 6, current_stats: [1297  974   77   81 6232], current_centroid: [1334.99390244 1013.99358151], stats_history: <queue.Queue object at 0x124b4d150>, centroid_history: <queue.Queue object at 0x122197190>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1297  974   77   81 6232]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1334.99390244 1013.99358151]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3eed0>, centroid_history: <queue.Queue object at 0x124e3c910>, \n",
      "\n",
      "current label: 7, current_stats: [  678  1030   316   222 54345], current_centroid: [ 844.10157328 1138.41214463], stats_history: <queue.Queue object at 0x124e3eed0>, centroid_history: <queue.Queue object at 0x124e3c910>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  678  1030   316   222 54345]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 844.10157328 1138.41214463]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3eb50>, centroid_history: <queue.Queue object at 0x124e3e650>, \n",
      "\n",
      "current label: 9, current_stats: [   205   1515    782    500 181590], current_centroid: [ 580.03892285 1742.40218624], stats_history: <queue.Queue object at 0x124e3eb50>, centroid_history: <queue.Queue object at 0x124e3e650>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   205   1515    782    500 181590]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 580.03892285 1742.40218624]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122fb6090>, stats_history: <queue.Queue object at 0x124fe57d0>, centroid_history: <queue.Queue object at 0x122f5f090>, \n",
      "\n",
      "current label: 3, current_stats: [   978    845   1135   1281 340613], current_centroid: [1628.42679816 1650.79014894], stats_history: <queue.Queue object at 0x124fe57d0>, centroid_history: <queue.Queue object at 0x122f5f090>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   978    845   1135   1281 340613]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1628.42679816 1650.79014894]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e4a110>, stats_history: <queue.Queue object at 0x124ff47d0>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "current label: 4, current_stats: [ 1098   902   145   220 27379], current_centroid: [1170.8457577 1013.6175536], stats_history: <queue.Queue object at 0x124ff47d0>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1098   902   145   220 27379]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1170.8457577 1013.6175536]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x123c14850>, stats_history: <queue.Queue object at 0x122ea5310>, centroid_history: <queue.Queue object at 0x124fb2f90>, \n",
      "\n",
      "current label: 5, current_stats: [  464   910   234   232 37423], current_centroid: [ 571.55519333 1014.89177778], stats_history: <queue.Queue object at 0x122ea5310>, centroid_history: <queue.Queue object at 0x124fb2f90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  464   910   234   232 37423]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 571.55519333 1014.89177778]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "current label: 6, current_stats: [ 1538   963   223   174 30773], current_centroid: [1647.67529978 1046.70340883], stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1538   963   223   174 30773]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1647.67529978 1046.70340883]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122197190>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "current label: 7, current_stats: [1318 1019   76   78 5925], current_centroid: [1355.48101266 1057.49367089], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1318 1019   76   78 5925]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1355.48101266 1057.49367089]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3ee90>, centroid_history: <queue.Queue object at 0x124e3fd90>, \n",
      "\n",
      "current label: 8, current_stats: [  671  1032   321   216 54627], current_centroid: [ 840.50156516 1137.8594651 ], stats_history: <queue.Queue object at 0x124e3ee90>, centroid_history: <queue.Queue object at 0x124e3fd90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  671  1032   321   216 54627]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 840.50156516 1137.8594651 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124feff90>, stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "current label: 2, current_stats: [   974    849   1142   1278 346621], current_centroid: [1638.40729211 1646.75569282], stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   974    849   1142   1278 346621]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1638.40729211 1646.75569282]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x11e7b9890>, stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fef550>, \n",
      "\n",
      "current label: 3, current_stats: [ 1098   904   146   220 27443], current_centroid: [1170.66104289 1015.41963342], stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fef550>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1098   904   146   220 27443]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1170.66104289 1015.41963342]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122f5f090>, stats_history: <queue.Queue object at 0x124fe69d0>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "current label: 4, current_stats: [  465   912   237   229 38168], current_centroid: [ 574.22579124 1015.62885139], stats_history: <queue.Queue object at 0x124fe69d0>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  465   912   237   229 38168]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 574.22579124 1015.62885139]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff5fd0>, \n",
      "\n",
      "current label: 5, current_stats: [ 1540   959   224   175 31120], current_centroid: [1650.96285347 1044.36384961], stats_history: <queue.Queue object at 0x124f1df50>, centroid_history: <queue.Queue object at 0x124ff5fd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1540   959   224   175 31120]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1650.96285347 1044.36384961]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5310>, stats_history: <queue.Queue object at 0x124fb2690>, centroid_history: <queue.Queue object at 0x123c14850>, \n",
      "\n",
      "current label: 6, current_stats: [ 1305   974    98   123 11354], current_centroid: [1353.98705302 1033.23057953], stats_history: <queue.Queue object at 0x124fb2690>, centroid_history: <queue.Queue object at 0x123c14850>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1305   974    98   123 11354]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1353.98705302 1033.23057953]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b3fb50>, stats_history: <queue.Queue object at 0x124fb0890>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 7, current_stats: [  663  1034   328   212 55351], current_centroid: [ 835.1988582  1138.74461166], stats_history: <queue.Queue object at 0x124fb0890>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  663  1034   328   212 55351]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 835.1988582  1138.74461166]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3fe50>, centroid_history: <queue.Queue object at 0x124e3ecd0>, \n",
      "\n",
      "current label: 9, current_stats: [   208   1517    779    476 178947], current_centroid: [ 578.61692009 1736.88384829], stats_history: <queue.Queue object at 0x124e3fe50>, centroid_history: <queue.Queue object at 0x124e3ecd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   208   1517    779    476 178947]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 578.61692009 1736.88384829]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3f450>, centroid_history: <queue.Queue object at 0x124e3eb50>, \n",
      "\n",
      "current label: 2, current_stats: [   971    854   1146   1272 342268], current_centroid: [1636.90301752 1644.068721  ], stats_history: <queue.Queue object at 0x124e3f450>, centroid_history: <queue.Queue object at 0x124e3eb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   971    854   1146   1272 342268]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1636.90301752 1644.068721  ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3e410>, stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "current label: 3, current_stats: [ 1098   905   145   221 27243], current_centroid: [1170.37470176 1016.97999486], stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1098   905   145   221 27243]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1170.37470176 1016.97999486]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2810>, stats_history: <queue.Queue object at 0x124fef390>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "current label: 4, current_stats: [  465   914   240   224 38497], current_centroid: [ 575.88038029 1015.17224719], stats_history: <queue.Queue object at 0x124fef390>, centroid_history: <queue.Queue object at 0x124fed490>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  465   914   240   224 38497]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 575.88038029 1015.17224719]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77250>, stats_history: <queue.Queue object at 0x122fb6090>, centroid_history: <queue.Queue object at 0x124fe69d0>, \n",
      "\n",
      "current label: 5, current_stats: [ 1542   957   225   173 30847], current_centroid: [1654.56297209 1042.23162706], stats_history: <queue.Queue object at 0x122fb6090>, centroid_history: <queue.Queue object at 0x124fe69d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1542   957   225   173 30847]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1654.56297209 1042.23162706]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ff3690>, stats_history: <queue.Queue object at 0x124ff65d0>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "current label: 6, current_stats: [1285  974   85   81 6856], current_centroid: [1327.02975496 1014.08415986], stats_history: <queue.Queue object at 0x124ff65d0>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1285  974   85   81 6856]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1327.02975496 1014.08415986]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x123c14850>, stats_history: <queue.Queue object at 0x124b3fad0>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "current label: 7, current_stats: [  649  1036   340   205 56162], current_centroid: [ 828.33390905 1137.70725758], stats_history: <queue.Queue object at 0x124b3fad0>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  649  1036   340   205 56162]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 828.33390905 1137.70725758]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122197190>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x124718f90>, \n",
      "\n",
      "current label: 9, current_stats: [  210  1519   172   174 23735], current_centroid: [ 294.5952391  1602.96667369], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x124718f90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  210  1519   172   174 23735]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 294.5952391  1602.96667369]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3c4d0>, centroid_history: <queue.Queue object at 0x124e3c0d0>, \n",
      "\n",
      "current label: 2, current_stats: [   969    857   1147   1267 340741], current_centroid: [1638.50631711 1641.11543078], stats_history: <queue.Queue object at 0x124e3c4d0>, centroid_history: <queue.Queue object at 0x124e3c0d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   969    857   1147   1267 340741]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1638.50631711 1641.11543078]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3ccd0>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "current label: 3, current_stats: [ 1098   906   146   222 27133], current_centroid: [1169.9849261  1018.61047433], stats_history: <queue.Queue object at 0x124e3ccd0>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1098   906   146   222 27133]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1169.9849261  1018.61047433]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124feff90>, stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "current label: 4, current_stats: [  466   916   242   218 37241], current_centroid: [ 579.93767622 1013.97202009], stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  466   916   242   218 37241]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 579.93767622 1013.97202009]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2810>, stats_history: <queue.Queue object at 0x124fefd10>, centroid_history: <queue.Queue object at 0x124fef4d0>, \n",
      "\n",
      "current label: 5, current_stats: [ 1544   954   227   173 30619], current_centroid: [1659.01593782 1040.03083053], stats_history: <queue.Queue object at 0x124fefd10>, centroid_history: <queue.Queue object at 0x124fef4d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1544   954   227   173 30619]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1659.01593782 1040.03083053]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fe69d0>, stats_history: <queue.Queue object at 0x122fb6090>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "current label: 6, current_stats: [1271 1004   76   84 6378], current_centroid: [1308.46472248 1045.48777046], stats_history: <queue.Queue object at 0x122fb6090>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1271 1004   76   84 6378]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1308.46472248 1045.48777046]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124dbf9d0>, centroid_history: <queue.Queue object at 0x124ff7990>, \n",
      "\n",
      "current label: 7, current_stats: [  642  1038   346   198 56155], current_centroid: [ 823.12526044 1136.72456593], stats_history: <queue.Queue object at 0x124dbf9d0>, centroid_history: <queue.Queue object at 0x124ff7990>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  642  1038   346   198 56155]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 823.12526044 1136.72456593]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1220a46d0>, stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 9, current_stats: [   212   1521    765    471 172194], current_centroid: [ 574.09634482 1732.43058411], stats_history: <queue.Queue object at 0x124fb3810>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   212   1521    765    471 172194]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 574.09634482 1732.43058411]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3e8d0>, centroid_history: <queue.Queue object at 0x124e3fe50>, \n",
      "\n",
      "current label: 2, current_stats: [   970    860   1147   1264 339601], current_centroid: [1638.62039276 1645.81754471], stats_history: <queue.Queue object at 0x124e3e8d0>, centroid_history: <queue.Queue object at 0x124e3fe50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   970    860   1147   1264 339601]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1638.62039276 1645.81754471]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3c690>, centroid_history: <queue.Queue object at 0x124e3ef90>, \n",
      "\n",
      "current label: 3, current_stats: [ 1096   911   148   218 26845], current_centroid: [1169.2272304 1022.1873347], stats_history: <queue.Queue object at 0x124e3c690>, centroid_history: <queue.Queue object at 0x124e3ef90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1096   911   148   218 26845]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1169.2272304 1022.1873347]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3e7d0>, centroid_history: <queue.Queue object at 0x124e3c9d0>, \n",
      "\n",
      "current label: 4, current_stats: [  467   917   244   213 37454], current_centroid: [ 581.67218455 1013.88679447], stats_history: <queue.Queue object at 0x124e3e7d0>, centroid_history: <queue.Queue object at 0x124e3c9d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  467   917   244   213 37454]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 581.67218455 1013.88679447]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3e410>, stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "current label: 5, current_stats: [ 1546   951   227   173 30982], current_centroid: [1660.87499193 1037.49748241], stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1546   951   227   173 30982]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1660.87499193 1037.49748241]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f9a2d0>, stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fefed0>, \n",
      "\n",
      "current label: 6, current_stats: [ 1272   988   129    95 10402], current_centroid: [1335.06748702 1034.35204768], stats_history: <queue.Queue object at 0x124fef550>, centroid_history: <queue.Queue object at 0x124fefed0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1272   988   129    95 10402]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1335.06748702 1034.35204768]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77250>, stats_history: <queue.Queue object at 0x122fb6090>, centroid_history: <queue.Queue object at 0x124fe69d0>, \n",
      "\n",
      "current label: 7, current_stats: [  636  1040   350   192 55952], current_centroid: [ 817.75434301 1134.59393766], stats_history: <queue.Queue object at 0x122fb6090>, centroid_history: <queue.Queue object at 0x124fe69d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  636  1040   350   192 55952]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 817.75434301 1134.59393766]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x123c14850>, stats_history: <queue.Queue object at 0x124fc07d0>, centroid_history: <queue.Queue object at 0x124fb2690>, \n",
      "\n",
      "current label: 9, current_stats: [   214   1522    511    471 133186], current_centroid: [ 495.20368507 1739.20089949], stats_history: <queue.Queue object at 0x124fc07d0>, centroid_history: <queue.Queue object at 0x124fb2690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   214   1522    511    471 133186]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 495.20368507 1739.20089949]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e52110>, stats_history: <queue.Queue object at 0x124b4d150>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "current label: 2, current_stats: [   982    863   1135   1263 339523], current_centroid: [1638.82159382 1650.4123108 ], stats_history: <queue.Queue object at 0x124b4d150>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   982    863   1135   1263 339523]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1638.82159382 1650.4123108 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3c910>, centroid_history: <queue.Queue object at 0x124e3d050>, \n",
      "\n",
      "current label: 3, current_stats: [  469   919   517   308 94275], current_centroid: [ 720.76727658 1084.57347123], stats_history: <queue.Queue object at 0x124e3c910>, centroid_history: <queue.Queue object at 0x124e3d050>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  469   919   517   308 94275]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 720.76727658 1084.57347123]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3d690>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "current label: 4, current_stats: [ 1092   921   151   209 25711], current_centroid: [1168.47201587 1028.9081716 ], stats_history: <queue.Queue object at 0x124e3d690>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1092   921   151   209 25711]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1168.47201587 1028.9081716 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3eb50>, centroid_history: <queue.Queue object at 0x124e3dbd0>, \n",
      "\n",
      "current label: 5, current_stats: [ 1548   949   228   172 30726], current_centroid: [1664.30921695 1035.62809998], stats_history: <queue.Queue object at 0x124e3eb50>, centroid_history: <queue.Queue object at 0x124e3dbd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1548   949   228   172 30726]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1664.30921695 1035.62809998]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124feff90>, stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "current label: 6, current_stats: [ 1269   979   123   104 10463], current_centroid: [1328.69358693 1029.62563318], stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1269   979   123   104 10463]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1328.69358693 1029.62563318]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fe69d0>, stats_history: <queue.Queue object at 0x122fb6090>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "current label: 8, current_stats: [   216   1524    508    471 132960], current_centroid: [ 495.15181258 1738.60429452], stats_history: <queue.Queue object at 0x122fb6090>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   216   1524    508    471 132960]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 495.15181258 1738.60429452]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124ff5a90>, centroid_history: <queue.Queue object at 0x124ff7990>, \n",
      "\n",
      "current label: 9, current_stats: [  698  1626   284   158 38698], current_centroid: [ 844.11791307 1703.80319396], stats_history: <queue.Queue object at 0x124ff5a90>, centroid_history: <queue.Queue object at 0x124ff7990>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  698  1626   284   158 38698]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 844.11791307 1703.80319396]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124d80250>, stats_history: <queue.Queue object at 0x124fb3d10>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 2, current_stats: [   986    866   1131   1260 343814], current_centroid: [1632.39481231 1655.63091963], stats_history: <queue.Queue object at 0x124fb3d10>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   986    866   1131   1260 343814]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1632.39481231 1655.63091963]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3fd90>, centroid_history: <queue.Queue object at 0x124e3f690>, \n",
      "\n",
      "current label: 4, current_stats: [ 1086   920   158   205 26124], current_centroid: [1167.75042107 1026.77890063], stats_history: <queue.Queue object at 0x124e3fd90>, centroid_history: <queue.Queue object at 0x124e3f690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1086   920   158   205 26124]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1167.75042107 1026.77890063]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3c0d0>, centroid_history: <queue.Queue object at 0x124e3c350>, \n",
      "\n",
      "current label: 5, current_stats: [ 1550   948   229   170 30907], current_centroid: [1666.53463617 1033.62115378], stats_history: <queue.Queue object at 0x124e3c0d0>, centroid_history: <queue.Queue object at 0x124e3c350>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1550   948   229   170 30907]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1666.53463617 1033.62115378]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3d710>, centroid_history: <queue.Queue object at 0x124e3d9d0>, \n",
      "\n",
      "current label: 6, current_stats: [ 1268   995   131    90 11443], current_centroid: [1333.10172158 1039.55798305], stats_history: <queue.Queue object at 0x124e3d710>, centroid_history: <queue.Queue object at 0x124e3d9d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1268   995   131    90 11443]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1333.10172158 1039.55798305]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124dc99d0>, stats_history: <queue.Queue object at 0x124fef4d0>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "current label: 8, current_stats: [   218   1524    505    471 133916], current_centroid: [ 495.80612473 1739.95581559], stats_history: <queue.Queue object at 0x124fef4d0>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   218   1524    505    471 133916]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 495.80612473 1739.95581559]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77250>, stats_history: <queue.Queue object at 0x124f3c4d0>, centroid_history: <queue.Queue object at 0x124ffa590>, \n",
      "\n",
      "current label: 9, current_stats: [  700  1623   274   159 38219], current_centroid: [ 842.31356132 1704.83309349], stats_history: <queue.Queue object at 0x124f3c4d0>, centroid_history: <queue.Queue object at 0x124ffa590>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  700  1623   274   159 38219]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 842.31356132 1704.83309349]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x121b60590>, stats_history: <queue.Queue object at 0x124fefad0>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "current label: 2, current_stats: [   966    867   1152   1262 334680], current_centroid: [1632.18075176 1654.45762818], stats_history: <queue.Queue object at 0x124fefad0>, centroid_history: <queue.Queue object at 0x124fb0550>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   966    867   1152   1262 334680]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1632.18075176 1654.45762818]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124fe46d0>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "current label: 3, current_stats: [  472   921   511   289 92407], current_centroid: [ 715.40997976 1079.56693757], stats_history: <queue.Queue object at 0x124fe46d0>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  472   921   511   289 92407]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 715.40997976 1079.56693757]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e52110>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "current label: 4, current_stats: [ 1083   920   161   209 26725], current_centroid: [1166.74963517 1028.75872778], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1083   920   161   209 26725]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1166.74963517 1028.75872778]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3cb50>, centroid_history: <queue.Queue object at 0x124e3e2d0>, \n",
      "\n",
      "current label: 5, current_stats: [ 1554   947   228   168 30380], current_centroid: [1670.28624095 1032.05371955], stats_history: <queue.Queue object at 0x124e3cb50>, centroid_history: <queue.Queue object at 0x124e3e2d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1554   947   228   168 30380]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1670.28624095 1032.05371955]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3ef90>, centroid_history: <queue.Queue object at 0x124e3d390>, \n",
      "\n",
      "current label: 6, current_stats: [1324 1004   75   75 5625], current_centroid: [1361. 1041.], stats_history: <queue.Queue object at 0x124e3ef90>, centroid_history: <queue.Queue object at 0x124e3d390>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1324 1004   75   75 5625]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1361. 1041.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124feff90>, stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "current label: 8, current_stats: [   220   1522    501    473 135501], current_centroid: [ 496.50577487 1740.86397148], stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124e3e410>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   220   1522    501    473 135501]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 496.50577487 1740.86397148]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124dc99d0>, stats_history: <queue.Queue object at 0x124fefed0>, centroid_history: <queue.Queue object at 0x124fef390>, \n",
      "\n",
      "current label: 9, current_stats: [  701  1623   285   154 39526], current_centroid: [ 846.12014876 1702.12657491], stats_history: <queue.Queue object at 0x124fefed0>, centroid_history: <queue.Queue object at 0x124fef390>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  701  1623   285   154 39526]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 846.12014876 1702.12657491]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124e4b650>, \n",
      "\n",
      "current label: 2, current_stats: [   965    871   1153   1258 339248], current_centroid: [1626.22638011 1658.72712293], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124e4b650>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   965    871   1153   1258 339248]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1626.22638011 1658.72712293]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fefad0>, stats_history: <queue.Queue object at 0x124fb1190>, centroid_history: <queue.Queue object at 0x121b60590>, \n",
      "\n",
      "current label: 3, current_stats: [ 1084   909   155   220 26849], current_centroid: [1163.74904093 1021.92651495], stats_history: <queue.Queue object at 0x124fb1190>, centroid_history: <queue.Queue object at 0x121b60590>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1084   909   155   220 26849]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1163.74904093 1021.92651495]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f1d0d0>, stats_history: <queue.Queue object at 0x124fb1c50>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 4, current_stats: [  470   922   511   285 91917], current_centroid: [ 712.12233863 1077.69399567], stats_history: <queue.Queue object at 0x124fb1c50>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  470   922   511   285 91917]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 712.12233863 1077.69399567]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122f6f510>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x124e52110>, \n",
      "\n",
      "current label: 5, current_stats: [ 1556   945   229   168 30413], current_centroid: [1673.11051195 1030.40742446], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x124e52110>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1556   945   229   168 30413]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1673.11051195 1030.40742446]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3fe90>, centroid_history: <queue.Queue object at 0x124e3ecd0>, \n",
      "\n",
      "current label: 6, current_stats: [1310  983   90  116 9741], current_centroid: [1353.14639154 1039.49419977], stats_history: <queue.Queue object at 0x124e3fe90>, centroid_history: <queue.Queue object at 0x124e3ecd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1310  983   90  116 9741]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1353.14639154 1039.49419977]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3ccd0>, \n",
      "\n",
      "current label: 8, current_stats: [   221   1520    497    467 136954], current_centroid: [ 493.11974824 1737.09756561], stats_history: <queue.Queue object at 0x124e3dbd0>, centroid_history: <queue.Queue object at 0x124e3ccd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   221   1520    497    467 136954]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 493.11974824 1737.09756561]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3e410>, stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "current label: 9, current_stats: [  702  1621   279   153 37509], current_centroid: [ 844.51419659 1699.16510704], stats_history: <queue.Queue object at 0x122ea5390>, centroid_history: <queue.Queue object at 0x124feff90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  702  1621   279   153 37509]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 844.51419659 1699.16510704]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77250>, stats_history: <queue.Queue object at 0x122f5f090>, centroid_history: <queue.Queue object at 0x124fefa10>, \n",
      "\n",
      "current label: 2, current_stats: [   965    875   1153   1253 335272], current_centroid: [1626.12392028 1660.36927629], stats_history: <queue.Queue object at 0x122f5f090>, centroid_history: <queue.Queue object at 0x124fefa10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   965    875   1153   1253 335272]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1626.12392028 1660.36927629]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e4b650>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "current label: 3, current_stats: [  472   925   505   284 90204], current_centroid: [ 709.82219192 1076.74299366], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  472   925   505   284 90204]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 709.82219192 1076.74299366]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x121b60590>, stats_history: <queue.Queue object at 0x124fc07d0>, centroid_history: <queue.Queue object at 0x124fb1210>, \n",
      "\n",
      "current label: 4, current_stats: [ 1558   943   229   168 30834], current_centroid: [1674.76688072 1028.4183369 ], stats_history: <queue.Queue object at 0x124fc07d0>, centroid_history: <queue.Queue object at 0x124fb1210>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1558   943   229   168 30834]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1674.76688072 1028.4183369 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb3d10>, \n",
      "\n",
      "current label: 5, current_stats: [ 1081   974   147   155 20659], current_centroid: [1152.95556416 1049.82554819], stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb3d10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1081   974   147   155 20659]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1152.95556416 1049.82554819]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e52110>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "current label: 6, current_stats: [ 1269   992   123   110 11313], current_centroid: [1328.9942544 1047.5129497], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122f6f510>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1269   992   123   110 11313]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1328.9942544 1047.5129497]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3c690>, \n",
      "\n",
      "current label: 8, current_stats: [   224   1520    490    479 136489], current_centroid: [ 495.13664105 1740.62689301], stats_history: <queue.Queue object at 0x124e3c350>, centroid_history: <queue.Queue object at 0x124e3c690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   224   1520    490    479 136489]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 495.13664105 1740.62689301]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3d9d0>, centroid_history: <queue.Queue object at 0x124e3e7d0>, \n",
      "\n",
      "current label: 9, current_stats: [  703  1621   281   158 38208], current_centroid: [ 845.27868509 1700.68946294], stats_history: <queue.Queue object at 0x124e3d9d0>, centroid_history: <queue.Queue object at 0x124e3e7d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  703  1621   281   158 38208]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 845.27868509 1700.68946294]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f9bd50>, stats_history: <queue.Queue object at 0x124fefcd0>, centroid_history: <queue.Queue object at 0x124fefd10>, \n",
      "\n",
      "current label: 2, current_stats: [   964    876   1155   1251 335997], current_centroid: [1623.44883734 1662.76861103], stats_history: <queue.Queue object at 0x124fefcd0>, centroid_history: <queue.Queue object at 0x124fefd10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   964    876   1155   1251 335997]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1623.44883734 1662.76861103]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fefa10>, stats_history: <queue.Queue object at 0x122f5f090>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "current label: 3, current_stats: [ 1082   917   160   207 27254], current_centroid: [1162.07279665 1024.75636604], stats_history: <queue.Queue object at 0x122f5f090>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1082   917   160   207 27254]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1162.07279665 1024.75636604]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124e4b650>, \n",
      "\n",
      "current label: 4, current_stats: [  473   925   499   285 88747], current_centroid: [ 707.36421513 1075.52267682], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124e4b650>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  473   925   499   285 88747]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 707.36421513 1075.52267682]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fc07d0>, stats_history: <queue.Queue object at 0x124fb0550>, centroid_history: <queue.Queue object at 0x121b60590>, \n",
      "\n",
      "current label: 5, current_stats: [ 1561   942   228   166 30391], current_centroid: [1677.74400316 1026.93159159], stats_history: <queue.Queue object at 0x124fb0550>, centroid_history: <queue.Queue object at 0x121b60590>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1561   942   228   166 30391]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1677.74400316 1026.93159159]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122f6f510>, stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122197190>, \n",
      "\n",
      "current label: 7, current_stats: [1305 1019   85   84 7048], current_centroid: [1347.10896708 1060.60201476], stats_history: <queue.Queue object at 0x122217dd0>, centroid_history: <queue.Queue object at 0x122197190>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1305 1019   85   84 7048]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1347.10896708 1060.60201476]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3d050>, centroid_history: <queue.Queue object at 0x124e3f7d0>, \n",
      "\n",
      "current label: 8, current_stats: [   227   1517    485    482 137134], current_centroid: [ 493.81215453 1740.71581081], stats_history: <queue.Queue object at 0x124e3d050>, centroid_history: <queue.Queue object at 0x124e3f7d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   227   1517    485    482 137134]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 493.81215453 1740.71581081]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3d390>, centroid_history: <queue.Queue object at 0x124e3d690>, \n",
      "\n",
      "current label: 9, current_stats: [  705  1621   276   144 33116], current_centroid: [ 849.68924387 1694.12851794], stats_history: <queue.Queue object at 0x124e3d390>, centroid_history: <queue.Queue object at 0x124e3d690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  705  1621   276   144 33116]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 849.68924387 1694.12851794]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5390>, stats_history: <queue.Queue object at 0x124feee90>, centroid_history: <queue.Queue object at 0x124e3ea10>, \n",
      "\n",
      "current label: 2, current_stats: [   963    879   1156   1248 335601], current_centroid: [1629.14750552 1658.82203867], stats_history: <queue.Queue object at 0x124feee90>, centroid_history: <queue.Queue object at 0x124e3ea10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   963    879   1156   1248 335601]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1629.14750552 1658.82203867]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x11e7b9890>, stats_history: <queue.Queue object at 0x124fefcd0>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "current label: 3, current_stats: [ 1081   912   162   206 28524], current_centroid: [1162.00946571 1017.40793718], stats_history: <queue.Queue object at 0x124fefcd0>, centroid_history: <queue.Queue object at 0x124fec8d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1081   912   162   206 28524]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1162.00946571 1017.40793718]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124b77250>, stats_history: <queue.Queue object at 0x122f5f090>, centroid_history: <queue.Queue object at 0x124fefa10>, \n",
      "\n",
      "current label: 4, current_stats: [  472   925   496   285 87849], current_centroid: [ 705.51110428 1074.70836321], stats_history: <queue.Queue object at 0x122f5f090>, centroid_history: <queue.Queue object at 0x124fefa10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  472   925   496   285 87849]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 705.51110428 1074.70836321]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e4b650>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "current label: 5, current_stats: [ 1563   940   228   167 30175], current_centroid: [1680.12109362 1025.73835957], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1563   940   228   167 30175]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1680.12109362 1025.73835957]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124fe46d0>, centroid_history: <queue.Queue object at 0x124fb1c50>, \n",
      "\n",
      "current label: 7, current_stats: [1309 1008   87   93 7969], current_centroid: [1351.87074915 1053.79432802], stats_history: <queue.Queue object at 0x124fe46d0>, centroid_history: <queue.Queue object at 0x124fb1c50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1309 1008   87   93 7969]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1351.87074915 1053.79432802]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f51610>, stats_history: <queue.Queue object at 0x124e3f690>, centroid_history: <queue.Queue object at 0x124e3eed0>, \n",
      "\n",
      "current label: 9, current_stats: [  710  1622   271   153 36036], current_centroid: [ 847.23878899 1700.11285936], stats_history: <queue.Queue object at 0x124e3f690>, centroid_history: <queue.Queue object at 0x124e3eed0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  710  1622   271   153 36036]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 847.23878899 1700.11285936]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e5abd0>, stats_history: <queue.Queue object at 0x124e3ccd0>, centroid_history: <queue.Queue object at 0x124e3d9d0>, \n",
      "\n",
      "current label: 2, current_stats: [   961    881   1159   1244 333863], current_centroid: [1620.7383268  1663.01949602], stats_history: <queue.Queue object at 0x124e3ccd0>, centroid_history: <queue.Queue object at 0x124e3d9d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   961    881   1159   1244 333863]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1620.7383268  1663.01949602]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e3ea10>, stats_history: <queue.Queue object at 0x123b29190>, centroid_history: <queue.Queue object at 0x122ea5390>, \n",
      "\n",
      "current label: 3, current_stats: [ 1082   922   162   180 25208], current_centroid: [1163.55823548 1015.15844176], stats_history: <queue.Queue object at 0x123b29190>, centroid_history: <queue.Queue object at 0x122ea5390>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1082   922   162   180 25208]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1163.55823548 1015.15844176]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2810>, stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "current label: 4, current_stats: [  473   927   490   283 86997], current_centroid: [ 702.7101969  1074.86220214], stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  473   927   490   283 86997]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 702.7101969  1074.86220214]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fefa10>, stats_history: <queue.Queue object at 0x122f5f090>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "current label: 5, current_stats: [ 1567   939   226   167 30281], current_centroid: [1683.01030349 1024.56461147], stats_history: <queue.Queue object at 0x122f5f090>, centroid_history: <queue.Queue object at 0x124b77250>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1567   939   226   167 30281]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1683.01030349 1024.56461147]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124e4b650>, \n",
      "\n",
      "current label: 6, current_stats: [ 1278   973   122   113 12453], current_centroid: [1340.13145427 1027.00634385], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124e4b650>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1278   973   122   113 12453]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1340.13145427 1027.00634385]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124f1d0d0>, stats_history: <queue.Queue object at 0x124fb3d10>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "current label: 8, current_stats: [   226   1512    482    487 137874], current_centroid: [ 493.0010952  1738.56067134], stats_history: <queue.Queue object at 0x124fb3d10>, centroid_history: <queue.Queue object at 0x1221dded0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   226   1512    482    487 137874]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 493.0010952  1738.56067134]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124dc4c50>, stats_history: <queue.Queue object at 0x122f6f510>, centroid_history: <queue.Queue object at 0x122217dd0>, \n",
      "\n",
      "current label: 9, current_stats: [  707  1622   274   153 36116], current_centroid: [ 846.31819692 1701.02273231], stats_history: <queue.Queue object at 0x122f6f510>, centroid_history: <queue.Queue object at 0x122217dd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  707  1622   274   153 36116]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 846.31819692 1701.02273231]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3da90>, centroid_history: <queue.Queue object at 0x124e3c350>, \n",
      "\n",
      "current label: 2, current_stats: [   959    884   1159   1242 342086], current_centroid: [1619.88050081 1664.95239501], stats_history: <queue.Queue object at 0x124e3da90>, centroid_history: <queue.Queue object at 0x124e3c350>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   959    884   1159   1242 342086]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1619.88050081 1664.95239501]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124dc5bd0>, stats_history: <queue.Queue object at 0x124e3d0d0>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "current label: 3, current_stats: [ 1080   920   163   175 24852], current_centroid: [1161.85059553 1010.10111862], stats_history: <queue.Queue object at 0x124e3d0d0>, centroid_history: <queue.Queue object at 0x124e3d710>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1080   920   163   175 24852]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1161.85059553 1010.10111862]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fefc90>, stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fb2810>, \n",
      "\n",
      "current label: 5, current_stats: [ 1570   938   224   166 30202], current_centroid: [1684.50629097 1023.06443282], stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fb2810>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1570   938   224   166 30202]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1684.50629097 1023.06443282]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 7, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124e4b650>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "current label: 7, current_stats: [1319 1009   76   81 6152], current_centroid: [1356.51219116 1048.98748375], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124fdeb90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1319 1009   76   81 6152]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1356.51219116 1048.98748375]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "current label: 9, current_stats: [  708  1622   271   154 35906], current_centroid: [ 845.81529549 1699.63524202], stats_history: <queue.Queue object at 0x124b3fb50>, centroid_history: <queue.Queue object at 0x124fb3810>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  708  1622   271   154 35906]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 845.81529549 1699.63524202]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3d690>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "current label: 3, current_stats: [   956    884   1162   1231 332505], current_centroid: [1619.74816319 1666.24988496], stats_history: <queue.Queue object at 0x124e3d690>, centroid_history: <queue.Queue object at 0x124e3d350>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   956    884   1162   1231 332505]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1619.74816319 1666.24988496]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124dc5bd0>, stats_history: <queue.Queue object at 0x124e3e510>, centroid_history: <queue.Queue object at 0x124e3f210>, \n",
      "\n",
      "current label: 4, current_stats: [ 1081   924   162   164 23974], current_centroid: [1162.25598565 1007.64106949], stats_history: <queue.Queue object at 0x124e3e510>, centroid_history: <queue.Queue object at 0x124e3f210>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1081   924   162   164 23974]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1162.25598565 1007.64106949]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2810>, stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "current label: 6, current_stats: [ 1572   937   224   166 29865], current_centroid: [1686.27138791 1021.97944082], stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1572   937   224   166 29865]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1686.27138791 1021.97944082]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fdeb90>, stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124e4b650>, \n",
      "\n",
      "current label: 8, current_stats: [1267 1012   75   77 5775], current_centroid: [1304. 1050.], stats_history: <queue.Queue object at 0x124ff7990>, centroid_history: <queue.Queue object at 0x124e4b650>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1267 1012   75   77 5775]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1304. 1050.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fc99d0>, stats_history: <queue.Queue object at 0x122f6f510>, centroid_history: <queue.Queue object at 0x122217dd0>, \n",
      "\n",
      "current label: 2, current_stats: [   954    885   1165   1241 337754], current_centroid: [1620.93177283 1662.98923181], stats_history: <queue.Queue object at 0x122f6f510>, centroid_history: <queue.Queue object at 0x122217dd0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   954    885   1165   1241 337754]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1620.93177283 1662.98923181]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 4, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ff9f50>, stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3da90>, \n",
      "\n",
      "current label: 4, current_stats: [ 1083   928   159   156 22900], current_centroid: [1162.0689083  1005.99126638], stats_history: <queue.Queue object at 0x124e3ced0>, centroid_history: <queue.Queue object at 0x124e3da90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1083   928   159   156 22900]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1162.0689083  1005.99126638]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2a10>, stats_history: <queue.Queue object at 0x124e3d9d0>, centroid_history: <queue.Queue object at 0x124e3c610>, \n",
      "\n",
      "current label: 5, current_stats: [ 1574   943   224   159 28841], current_centroid: [1687.55889186 1023.49492043], stats_history: <queue.Queue object at 0x124e3d9d0>, centroid_history: <queue.Queue object at 0x124e3c610>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1574   943   224   159 28841]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1687.55889186 1023.49492043]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 6, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x122ea5390>, stats_history: <queue.Queue object at 0x123b29190>, centroid_history: <queue.Queue object at 0x124e3ea10>, \n",
      "\n",
      "current label: 6, current_stats: [1326  982   75   80 6000], current_centroid: [1363.  1021.5], stats_history: <queue.Queue object at 0x123b29190>, centroid_history: <queue.Queue object at 0x124e3ea10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1326  982   75   80 6000]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1363.  1021.5]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 9, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fcd910>, stats_history: <queue.Queue object at 0x124ff47d0>, centroid_history: <queue.Queue object at 0x1221760d0>, \n",
      "\n",
      "current label: 9, current_stats: [  710  1623   270   152 35664], current_centroid: [ 847.97700763 1701.38229026], stats_history: <queue.Queue object at 0x124ff47d0>, centroid_history: <queue.Queue object at 0x1221760d0>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  710  1623   270   152 35664]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 847.97700763 1701.38229026]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 2, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x1221dded0>, stats_history: <queue.Queue object at 0x124fe46d0>, centroid_history: <queue.Queue object at 0x124fb3d10>, \n",
      "\n",
      "current label: 2, current_stats: [   950    887   1170   1225 342246], current_centroid: [1626.75196496 1661.52277894], stats_history: <queue.Queue object at 0x124fe46d0>, centroid_history: <queue.Queue object at 0x124fb3d10>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[   950    887   1170   1225 342246]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1626.75196496 1661.52277894]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 3, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa450>, stats_history: <queue.Queue object at 0x124ff7710>, centroid_history: <queue.Queue object at 0x124dc4c50>, \n",
      "\n",
      "current label: 3, current_stats: [ 1084   926   145   153 20779], current_centroid: [1156.00255065 1004.19654459], stats_history: <queue.Queue object at 0x124ff7710>, centroid_history: <queue.Queue object at 0x124dc4c50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1084   926   145   153 20779]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1156.00255065 1004.19654459]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 5, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124ffa490>, stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3c690>, \n",
      "\n",
      "current label: 5, current_stats: [ 1576   939   225   162 29044], current_centroid: [1689.54847817 1020.54465638], stats_history: <queue.Queue object at 0x124e3c710>, centroid_history: <queue.Queue object at 0x124e3c690>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1576   939   225   162 29044]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1689.54847817 1020.54465638]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "worn index: 8, video_cap: < cv2.VideoCapture 0x124dba250>, label_history: <queue.Queue object at 0x124fb2810>, stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "current label: 8, current_stats: [  749  1624   229   155 29636], current_centroid: [ 868.45437981 1697.70552706], stats_history: <queue.Queue object at 0x124fec8d0>, centroid_history: <queue.Queue object at 0x124fefc90>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  749  1624   229   155 29636]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 868.45437981 1697.70552706]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 0 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 24\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# process the worm list\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(w_list)):\n\u001B[0;32m---> 24\u001B[0m     temp_Worm \u001B[38;5;241m=\u001B[39m Worm(i, original_cap, i, stats[i], centroids[i])\n\u001B[1;32m     25\u001B[0m     temp_Worm\u001B[38;5;241m.\u001B[39mtake_the_bundle_in(bundle)\n\u001B[1;32m     26\u001B[0m     temp_Worm\u001B[38;5;241m.\u001B[39mwrite_frame(iteration_Number)\n",
      "\u001B[0;31mIndexError\u001B[0m: index 9 is out of bounds for axis 0 with size 9"
     ]
    }
   ],
   "source": [
    "for iteration_Number in range(3, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)-1)):\n",
    "\n",
    "\n",
    "    # Read the second frame\n",
    "    ret2, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Read the original frame\n",
    "    ret3, ori_frame = original_cap.read()\n",
    "\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    bundle = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "\n",
    "    # process the worm list\n",
    "    for i in range(1, len(w_list)):\n",
    "        temp_Worm = Worm(i, original_cap, i, stats[i], centroids[i])\n",
    "        temp_Worm.take_the_bundle_in(bundle)\n",
    "        temp_Worm.write_frame(iteration_Number)\n",
    "        w_list[i] = temp_Worm\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    prvs = next\n",
    "    cv2.imwrite(os.path.join(monitor_folder, f\"frame_{iteration_Number}.jpg\"), rgb_frame)\n",
    "    cv2.imwrite(os.path.join(output_folder, f\"frame_{iteration_Number}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
