{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Computer Vision Algorithm for Tracking Planarian Motion\n",
    "developed by Hokin Deng xueqiandeng@yahoo.com"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Dependencies and Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import packages and make sure of the python technicality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.11.4 (main, Jul  5 2023, 08:41:25) [Clang 14.0.6 ]\n",
      "Python Executable: /Users/billdeng/anaconda3/envs/unlearning_Version1/bin/python\n",
      "Python Path: ['/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug', '/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev', '/Users/billdeng/PycharmProjects/unicellular', '/Users/billdeng/PycharmProjects/unicellular', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python311.zip', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11/lib-dynload', '', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "print(\"Python Version:\", sys.version)\n",
    "print(\"Python Executable:\", sys.executable)\n",
    "print(\"Python Path:\", sys.path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(threshold=50)\n",
    "import queue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The video data should be named as \"sample.avi\" and put in the folder as the notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open a video file (replace 'sample.avi' with the path)\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "\n",
    "# Check if the video file was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display the video if want to have a look at it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#cv2.startWindowThread()\n",
    "# Loop to read and display frames\n",
    "#while True:\n",
    "    # Read a frame from the video\n",
    "#    ret, frame = cap.read()\n",
    "    # If the video has ended, break out of the loop\n",
    "#    if not ret:\n",
    "#        break\n",
    "    # Display the frame in a window\n",
    "#    cv2.imshow('Video', frame)\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "#    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#        break\n",
    "\n",
    "# Release the video capture object and close the window"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, get basic properties about our video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Count: 1202\n",
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Frame Rate: 10.0 frames per second\n",
      "Video Duration: 120.20 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get basic video properties\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "video_duration_sec = frame_count / frame_rate if frame_rate > 0 else 0\n",
    "\n",
    "# Print the video properties\n",
    "print(f\"Frame Count: {frame_count}\")\n",
    "print(f\"Frame Width: {frame_width}\")\n",
    "print(f\"Frame Height: {frame_height}\")\n",
    "print(f\"Frame Rate: {frame_rate} frames per second\")\n",
    "print(f\"Video Duration: {video_duration_sec:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret <class 'bool'>\n",
      "frame <class 'numpy.ndarray'>\n",
      "ret True\n",
      "frame [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "example_ret, example_frame = cap.read()\n",
    "print( 'ret', type(example_ret))\n",
    "print( 'frame', type(example_frame))\n",
    "print('ret', example_ret)\n",
    "print('frame', example_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# frame_number = 100  # The frame you want to access\n",
    "# Set the video position to the desired frame\n",
    "# cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)\n",
    "# Read the frame\n",
    "# ret, frame = cap.read()\n",
    "# if ret:\n",
    "    # Process the frame\n",
    "#     cv2.imshow('Frame 100', frame)\n",
    "#    cv2.waitKey(0)  # Wait for a key press to close the image window\n",
    "# else:\n",
    "#    print(\"Error: Unable to read the frame\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspect function for a frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def inspect_frame_from_video(cap_for_here, frame_number):\n",
    "    \"\"\"\n",
    "    Inspects a specific frame in a video.\n",
    "\n",
    "    :param cap_for_here: video reference\n",
    "    :param frame_number: The frame number to inspect (1-based index).\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Open the video file\n",
    "    if not cap_for_here.isOpened():\n",
    "        print(\"Error: Unable to open video file\")\n",
    "        return\n",
    "    # Check if the frame number is valid\n",
    "    total_frames = cap_for_here.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if frame_number < 1 or frame_number > total_frames:\n",
    "        print(f\"Frame number should be between 1 and {int(total_frames)}\")\n",
    "        return\n",
    "    # Set the video position to the desired frame (0-based index for frame_number)\n",
    "    cap_for_here.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)\n",
    "    # Read the frame\n",
    "    ret_temp, frame_temp = cap_for_here.read()\n",
    "    if ret_temp:\n",
    "        # Display the frame\n",
    "        # cv2.imshow(f'Frame {frame_number}', frame)\n",
    "        # cv2.waitKey(0)  # Wait for a key press to close the image window\n",
    "        # cv2.destroyAllWindows()\n",
    "        frame_h, frame_w = frame_temp.shape[:2]\n",
    "        print(f\"Frame Width: {frame_h}\")\n",
    "        print(f\"Frame Height: {frame_w}\")\n",
    "        # Color Channels\n",
    "        channels = frame_temp.shape[2] if len(frame_temp.shape) == 3 else 1\n",
    "        print(f\"Color Channels: {channels}\")\n",
    "        # Data Type\n",
    "        data_type = frame_temp.dtype\n",
    "        print(f\"Data Type: {data_type}\")\n",
    "        # Aspect Ratio\n",
    "        aspect_ratio = frame_w / frame_h\n",
    "        print(f\"Aspect Ratio: {aspect_ratio}\")\n",
    "        # Resolution (assuming a standard display resolution of 96 PPI)\n",
    "        # Color Space (assuming default BGR)\n",
    "        color_space = \"BGR\" if channels == 3 else \"Grayscale\"\n",
    "        print(f\"Color Space: {color_space}\")\n",
    "        # Histogram for each channel\n",
    "        if channels > 1:\n",
    "            for i, col in enumerate(['Blue', 'Green', 'Red']):\n",
    "                hist = cv2.calcHist([frame_temp], [i], None, [256], [0, 256])\n",
    "                print(f\"Histogram for {col} channel: {np.array(hist).flatten()}\")\n",
    "        else:\n",
    "            hist = cv2.calcHist([frame_temp], [0], None, [256], [0, 256])\n",
    "            print(f\"Histogram for Grayscale: {np.array(hist).flatten()}\")\n",
    "    else:\n",
    "        print(\"Error: Unable to read the frame\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def inspect_given_a_frame(this_frame):\n",
    "    frame_h, frame_w = this_frame.shape[:2]\n",
    "    print(f\"Frame Width: {frame_h}\")\n",
    "    print(f\"Frame Height: {frame_w}\")\n",
    "    channels = this_frame.shape[2] if len(this_frame.shape) == 3 else 1\n",
    "    print(f\"Color Channels: {channels}\")\n",
    "    data_type = this_frame.dtype\n",
    "    print(f\"Data Type: {data_type}\")\n",
    "    aspect_ratio = frame_w / frame_h\n",
    "    print(f\"Aspect Ratio: {aspect_ratio}\")\n",
    "    color_space = \"BGR\" if channels == 3 else \"Grayscale\"\n",
    "    print(f\"Color Space: {color_space}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Color Channels: 3\n",
      "Data Type: uint8\n",
      "Aspect Ratio: 1.0\n",
      "Color Space: BGR\n",
      "Histogram for Blue channel: [      0.       0.       0. ...   31073.   57326. 3775011.]\n",
      "Histogram for Green channel: [      0.       0.       0. ...   31073.   57326. 3775011.]\n",
      "Histogram for Red channel: [      0.       0.       0. ...   31073.   57326. 3775011.]\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "video_file = 'sample.avi'\n",
    "frame_to_inspect = 100  # Adjust the frame number as needed\n",
    "inspect_frame_from_video(cap, frame_to_inspect)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Color Channels: 3\n",
      "Data Type: uint8\n",
      "Aspect Ratio: 1.0\n",
      "Color Space: BGR\n"
     ]
    }
   ],
   "source": [
    "ret, frame_for_use = cap.read()\n",
    "inspect_given_a_frame(frame_for_use)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Processing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Background subtraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 51"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     17\u001B[0m fgMask \u001B[38;5;241m=\u001B[39m backSub\u001B[38;5;241m.\u001B[39mapply(frame)\n\u001B[0;32m---> 18\u001B[0m out\u001B[38;5;241m.\u001B[39mwrite(fgMask)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124mProgress: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cv2\u001B[38;5;241m.\u001B[39mwaitKey(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0xFF\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('background_remove.avi', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "while True:\n",
    "    i += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    fgMask = backSub.apply(frame)\n",
    "    out.write(fgMask)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spatial Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1202"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "cap = cv2.VideoCapture('background_remove.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('background_remove_spatial_smoothed.avi', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "while True:\n",
    "    i += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    out.write(blurred_frame)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Temporal Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"background_remove_spatial_smooth.avi\"\n",
      "[ERROR:0@834.234] global cap.cpp:166 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.8.1) /Users/runner/work/opencv-python/opencv-python/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): background_remove_spatial_smooth.avi in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('background_remove_spatial_smooth.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') # You can also use 'XVID'\n",
    "out = cv2.VideoWriter('b_r_s_s_t_s.avi', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "buffer_size = 5\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_buffer.append(frame)\n",
    "    if len(frame_buffer) > buffer_size:\n",
    "        frame_buffer.pop(0)\n",
    "    # Temporal smoothing (average of frames in buffer)\n",
    "    temp_smoothed = np.mean(frame_buffer, axis=0).astype(np.uint8)\n",
    "    # Write frame to video\n",
    "    out.write(temp_smoothed)\n",
    "    # Break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "do everything all at once"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # You can also use 'XVID'\n",
    "out = cv2.VideoWriter('pre_dense.mp4', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "# Background subtractor\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "# Buffer for temporal smoothing\n",
    "buffer_size = 5\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Background subtraction\n",
    "    fgMask = backSub.apply(frame)\n",
    "    # Spatial smoothing (Gaussian blur)\n",
    "    blurred = cv2.GaussianBlur(fgMask, (5, 5), 0)\n",
    "    # Add frame to buffer for temporal smoothing\n",
    "    frame_buffer.append(blurred)\n",
    "    if len(frame_buffer) > buffer_size:\n",
    "        frame_buffer.pop(0)\n",
    "    # Temporal smoothing (average of frames in buffer)\n",
    "    temp_smoothed = np.mean(frame_buffer, axis=0).astype(np.uint8)\n",
    "    # Write frame to video\n",
    "    out.write(temp_smoothed)\n",
    "    # Display result\n",
    "    # cv2.imshow('Frame', frame)\n",
    "    # cv2.imshow('FG Mask', fgMask)\n",
    "    # cv2.imshow('Blurred', blurred)\n",
    "    # cv2.imshow('Temporally Smoothed', temp_smoothed)\n",
    "    # Break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dense opti flow\n",
    "this takes a very very long time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1201"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"pre_dense.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('dense_opti_flow_v2.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "ret, first_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error reading first frame\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "mask = np.zeros_like(first_frame)\n",
    "mask[..., 1] = 255\n",
    "i = 0\n",
    "while True:\n",
    "    i += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    out.write(rgb)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    prev_gray = gray\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "segment each worm in dense optical flow video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1200"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('dense_opti_flow_v2.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('dense_opt_segmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 3  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(motion_mask), connectivity=8)\n",
    "    min_area = 50  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # Display the result\n",
    "    out.write(frame2)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "segment each worm without optical flow processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1201"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('pre_dense.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('predense_degmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 3  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(motion_mask), connectivity=8)\n",
    "    min_area = 50  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # Display the result\n",
    "    out.write(frame2)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a function for video to image and use it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Define a function to extract and save frames from a video file\n",
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/raw_images'\n",
    "video_path = current_location + '/sample.avi'\n",
    "\n",
    "def video2image(video_path, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Load the video\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Initialize frame count\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through video frames\n",
    "    while True:\n",
    "        # Read a frame\n",
    "        success, frame = video.read()\n",
    "        # Break if no frame is read (end of video)\n",
    "        if not success:\n",
    "            break\n",
    "        # Save the frame as an image\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"frame_{count}.jpg\"), frame)\n",
    "        # Increment frame count\n",
    "        count += 1\n",
    "\n",
    "    # Release the video object\n",
    "    video.release()\n",
    "\n",
    "    return count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the video into images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m frame_count \u001B[38;5;241m=\u001B[39m video2image(video_path, output_folder)\n",
      "Cell \u001B[0;32mIn[13], line 25\u001B[0m, in \u001B[0;36mvideo2image\u001B[0;34m(video_path, output_folder)\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Save the frame as an image\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimwrite(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_folder, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframe_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcount\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m), frame)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Increment frame count\u001B[39;00m\n\u001B[1;32m     27\u001B[0m count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "frame_count = video2image(video_path, output_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Design a crop function that remove the dish"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def crop_circle(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Create a mask with the same dimensions as the image\n",
    "    mask = np.zeros_like(image)\n",
    "    rows, cols, _ = mask.shape\n",
    "    # Compute the center and radius of the circle\n",
    "    center = (cols // 2, rows // 2)\n",
    "    radius = min(center[0], center[1], rows - center[1], cols - center[0])\n",
    "    # Draw the circular mask\n",
    "    cv2.circle(mask, center, radius, (255, 255, 255), -1)\n",
    "    # Apply the mask\n",
    "    circular_image = cv2.bitwise_and(image, mask)\n",
    "    # Optionally, you can remove the black background\n",
    "    masked_data = cv2.cvtColor(circular_image, cv2.COLOR_BGR2BGRA)\n",
    "    masked_data[mask == 0] = [0, 0, 0, 0]\n",
    "    # Save or display the result\n",
    "    cv2.imwrite('circular_image.png', masked_data)\n",
    "    # cv2.imshow('Circular Image', masked_data)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "threshold the original video and set the threshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "thresh = 127"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "apply to original video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1202"
     ]
    }
   ],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('threshold_original.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "# Read until video is completed\n",
    "j = 0\n",
    "while cap.isOpened():\n",
    "    j += 1\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Convert to grayscale\n",
    "        # Apply threshold for each channel\n",
    "        _, red_channel = cv2.threshold(frame[:,:,0], thresh, 255, cv2.THRESH_BINARY)\n",
    "        _, green_channel = cv2.threshold(frame[:,:,1], thresh, 255, cv2.THRESH_BINARY)\n",
    "        _, blue_channel = cv2.threshold(frame[:,:,2], thresh, 255, cv2.THRESH_BINARY)\n",
    "    # Combine the channels back\n",
    "        thresh_frame = cv2.merge([red_channel, green_channel, blue_channel])\n",
    "        # Display the resulting frame\n",
    "        out.write(thresh_frame)\n",
    "        # Press Q on keyboard to exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        print(f'\\rProgress: {j}', end='')\n",
    "    else:\n",
    "        break\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "apply erode and dilate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1202"
     ]
    }
   ],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('pre_dense.mp4')\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('pre_dense_erode_dilate.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    # Read each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Apply erosion and then dilation\n",
    "    eroded_frame = cv2.erode(frame, kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, kernel, iterations=1)\n",
    "    # Display the processed frame\n",
    "    out.write(dilated_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    # Break the loop with a key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "motion segmentation using connectivity after erode and dilate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 412"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 38\u001B[0m\n\u001B[1;32m     36\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSegmented Frame\u001B[39m\u001B[38;5;124m'\u001B[39m, frame2)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Display the result\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m out\u001B[38;5;241m.\u001B[39mwrite(frame2)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# Update previous frame\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124mProgress: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mj\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('pre_dense_erode_dilate_segmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    cv2.imshow('Segmented Frame', motion_mask)\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(motion_mask), connectivity=8)\n",
    "    min_area = 300  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Display the result\n",
    "    out.write(frame2)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "erode and dilate also motion mask, save motion mask actually"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1201"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('motion_mask_segmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    save_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Display the result\n",
    "    rgb_frame = cv2.cvtColor(save_frame, cv2.COLOR_GRAY2RGB)\n",
    "    # inspect_given_a_frame(frame2)\n",
    "    # inspect_given_a_frame(rgb_frame)\n",
    "    out.write(save_frame)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1201"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('motion_mask_segmented_v2.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    t_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Display the result\n",
    "    rgb_frame = cv2.cvtColor(t_frame, cv2.COLOR_GRAY2RGB)\n",
    "    # inspect_given_a_frame(frame2)\n",
    "    # inspect_given_a_frame(rgb_frame)\n",
    "    # inspect_given_a_frame(rgb_frame)\n",
    "    out.write(rgb_frame)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dilate even more for segmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overlay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1201"
     ]
    }
   ],
   "source": [
    "original_cap = cv2.VideoCapture('sample.avi')\n",
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('overlay.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "not_useful, ori_frame = original_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    not_useful, ori_frame = original_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    out.write(ori_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize Paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/worm_segmentation'\n",
    "video_path = current_location + '/sample.avi'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize input videos and output videos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "motion_mask_cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "original_video_cap = cv2.VideoCapture('sample.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "f_worm_1 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_2 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_3 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_4 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_5 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_6 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_7 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_8 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_9 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_10 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "worm_1_out = cv2.VideoWriter(output_folder + '/worm_1_out.mp4', f_worm_1, frame_rate, (frame_width, frame_height), True)\n",
    "worm_2_out = cv2.VideoWriter(output_folder + '/worm_2_out.mp4', f_worm_2, frame_rate, (frame_width, frame_height), True)\n",
    "worm_3_out = cv2.VideoWriter(output_folder + '/worm_3_out.mp4', f_worm_3, frame_rate, (frame_width, frame_height), True)\n",
    "worm_4_out = cv2.VideoWriter(output_folder + '/worm_4_out.mp4', f_worm_4, frame_rate, (frame_width, frame_height), True)\n",
    "worm_5_out = cv2.VideoWriter(output_folder + '/worm_5_out.mp4', f_worm_5, frame_rate, (frame_width, frame_height), True)\n",
    "worm_6_out = cv2.VideoWriter(output_folder + '/worm_6_out.mp4', f_worm_6, frame_rate, (frame_width, frame_height), True)\n",
    "worm_7_out = cv2.VideoWriter(output_folder + '/worm_7_out.mp4', f_worm_7, frame_rate, (frame_width, frame_height), True)\n",
    "worm_8_out = cv2.VideoWriter(output_folder + '/worm_8_out.mp4', f_worm_8, frame_rate, (frame_width, frame_height), True)\n",
    "worm_9_out = cv2.VideoWriter(output_folder + '/worm_9_out.mp4', f_worm_9, frame_rate, (frame_width, frame_height), True)\n",
    "worm_10_out = cv2.VideoWriter(output_folder + '/worm_10_out.mp4', f_worm_10, frame_rate, (frame_width, frame_height), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "clean up make sure all number is good"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames in the motion mask: 1202\n",
      "Total number of frames in the original video: 1202\n",
      "to process the video need to iterate over: 1202\n"
     ]
    }
   ],
   "source": [
    "total_it_number = 0\n",
    "\n",
    "if not motion_mask_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(motion_mask_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the motion mask: {total_it_number}\")\n",
    "\n",
    "if not original_video_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(original_video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the original video: {total_it_number}\")\n",
    "\n",
    "print(f\"to process the video need to iterate over: {total_it_number}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motion frame read\n",
      "Shape of Frame (2160, 2160, 3)\n",
      "First Row [[122 125 123]\n",
      " [122 125 123]\n",
      " [122 125 123]\n",
      " ...\n",
      " [122 125 123]\n",
      " [122 125 123]\n",
      " [122 125 123]]\n",
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Color Channels: 1\n",
      "Data Type: uint8\n",
      "Aspect Ratio: 1.0\n",
      "Color Space: Grayscale\n",
      "Shape of Frame (2160, 2160)\n",
      "First Row (2160,)\n"
     ]
    }
   ],
   "source": [
    "# Read the first motion\n",
    "ret, motion_frame_init = motion_mask_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the motion ask\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"motion frame read\")\n",
    "print(\"Shape of Frame\", motion_frame_init.shape)\n",
    "print(\"First Row\", motion_frame_init[:,1])\n",
    "previous_motion_frame = cv2.cvtColor(motion_frame_init, cv2.COLOR_BGR2GRAY)\n",
    "inspect_given_a_frame(previous_motion_frame)\n",
    "print(\"Shape of Frame\", previous_motion_frame.shape)\n",
    "print(\"First Row\", previous_motion_frame[:,1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pilot the code a bit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels 20 \n",
      "\n",
      "labels [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "stats [[      0       0    2160    2160 3892687]\n",
      " [     59      11    1290     742  217899]\n",
      " [   1157      19     116      72    6481]\n",
      " ...\n",
      " [    223    1553    1687     535  347629]\n",
      " [    278    1614      76      76    5593]\n",
      " [    175    1622      57      60    3340]] \n",
      "\n",
      "centroids [[1097.18925077 1056.30238547]\n",
      " [ 637.53835493  294.37785396]\n",
      " [1213.91529085   54.33143033]\n",
      " [ 865.78622493   64.2190061 ]\n",
      " [1493.07880724  262.53887114]\n",
      " [1960.71808545  727.44079666]\n",
      " [ 758.97357724  821.72811132]\n",
      " [ 148.89168689  839.73988673]\n",
      " [1085.63219726  899.26891299]\n",
      " [ 836.11858407  956.59620733]\n",
      " [2026.1287264   964.47492953]\n",
      " [ 126.59711969  985.64298681]\n",
      " [ 501.42913001 1018.56304985]\n",
      " [1546.96204738 1177.76202156]\n",
      " [1978.63962196 1296.65338381]\n",
      " [ 555.16098081 1161.27078891]\n",
      " [1075.6705327  1314.63244551]\n",
      " [1079.36621513 1859.52991839]\n",
      " [ 315.59878419 1651.640801  ]\n",
      " [ 203.32005988 1651.22724551]] \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'frame2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 24\u001B[0m\n\u001B[1;32m     22\u001B[0m     x, y, w, h, area \u001B[38;5;241m=\u001B[39m stats[i]\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m area \u001B[38;5;241m>\u001B[39m min_area:\n\u001B[0;32m---> 24\u001B[0m         cv2\u001B[38;5;241m.\u001B[39mrectangle(frame2, (x, y), (x \u001B[38;5;241m+\u001B[39m w, y \u001B[38;5;241m+\u001B[39m h), (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m, \u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, num_labels):\n\u001B[1;32m     26\u001B[0m     x, y, w, h, area \u001B[38;5;241m=\u001B[39m stats[i]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'frame2' is not defined"
     ]
    }
   ],
   "source": [
    "for j in range(total_it_number):\n",
    "    ret, temporal_motion_frame = motion_mask_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    current_motion_frame = cv2.cvtColor(temporal_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    print('Number of labels', num_labels, '\\n')\n",
    "    print('labels', labels, '\\n')\n",
    "    print('stats', stats, '\\n')\n",
    "    print('centroids', centroids, '\\n')\n",
    "    min_area = 5000\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imshow('Segmented Frame', rgb_frame)\n",
    "    out.write(rgb_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "tye = num_labels, labels, stats, centroids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "num_la, la, st, cent = tye"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(num_la))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      0       0    2160    2160 3892687]\n",
      " [     59      11    1290     742  217899]\n",
      " [   1157      19     116      72    6481]\n",
      " ...\n",
      " [    223    1553    1687     535  347629]\n",
      " [    278    1614      76      76    5593]\n",
      " [    175    1622      57      60    3340]]\n"
     ]
    }
   ],
   "source": [
    "print(st)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "print(st[1][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 2)\n"
     ]
    }
   ],
   "source": [
    "print(centroids.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      0       0    2160    2160 4023733]\n",
      " [    944      11      70      54    3661]\n",
      " [    986      25     323     195   32555]\n",
      " ...\n",
      " [    381    1644     204     209   27822]\n",
      " [    652    1888     210     118   15770]\n",
      " [    793    1998      45      45    2025]]\n"
     ]
    }
   ],
   "source": [
    "stats_2 = stats\n",
    "print(stats_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "hum = stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0 2160 ...   45   45 2025]\n"
     ]
    }
   ],
   "source": [
    "hum = np.append(hum, stats_2)\n",
    "print(hum)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "make an object array and work with that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stats_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m hum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28;01mNone\u001B[39;00m,dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mobject\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(hum)\n\u001B[0;32m----> 3\u001B[0m hum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(hum, stats_2)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(hum)\n\u001B[1;32m      5\u001B[0m hum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(hum, stats_2)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'stats_2' is not defined"
     ]
    }
   ],
   "source": [
    "hum = np.array(None,dtype=object)\n",
    "print(hum)\n",
    "hum = np.append(hum, stats_2)\n",
    "print(hum)\n",
    "hum = np.append(hum, stats_2)\n",
    "print(hum)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(tye[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(tye[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      0       0    2160    2160 3761184]\n",
      " [    352      75     556     361  103374]\n",
      " [    176     452     206     251   24356]\n",
      " ...\n",
      " [     84    1176      52      58    2967]\n",
      " [    222    1451     454     517  112884]\n",
      " [    657    1601     315     269   52710]]\n"
     ]
    }
   ],
   "source": [
    "print(tye[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1084.05772517 1033.50448981]\n",
      " [ 664.56798615  246.686159  ]\n",
      " [ 277.20980457  572.43443094]\n",
      " [ 741.94100751  796.73690897]\n",
      " [1998.75183461  826.73745125]\n",
      " [ 129.54917511  936.83551182]\n",
      " [ 596.16124214 1012.1808911 ]\n",
      " [1149.79611286  949.72895092]\n",
      " [1346.26507138  996.13398069]\n",
      " [1612.56331062 1682.32551272]\n",
      " [1755.13875375 1066.63947831]\n",
      " [1564.36063957 1138.98831958]\n",
      " [1007.68984885 1243.8482752 ]\n",
      " [ 109.5082575  1204.80114594]\n",
      " [ 487.12448177 1718.76448389]\n",
      " [ 790.01952191 1721.53682413]]\n"
     ]
    }
   ],
   "source": [
    "print(tye[3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Construction of a Worm Object\n",
    "## the idea is that, to make a worm object, this object should be able to take each frame as input,\n",
    "## find the motion mask to correspond to the worm, and append to the worm object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "class Worm:\n",
    "    def __init__(self, worm_index, original_cap, label_history, stats_history, centroid_history, another_variable_in_case=None):\n",
    "        self.worm_index = worm_index\n",
    "        self.original_cap = original_cap\n",
    "        self.label_history = label_history\n",
    "        self.stats_history = stats_history\n",
    "        self.centroid_history = centroid_history\n",
    "        self.another_variable_in_case = another_variable_in_case\n",
    "\n",
    "    def display_info(self):\n",
    "        info = f\"worn index: {self.worm_index}, video_cap: {self.original_cap}, label_history: {self.label_history}, stats_history: {self.stats_history}, centroid_history: {self.centroid_history}\"\n",
    "        print(info)\n",
    "\n",
    "    def update_another_variable(self, another_variable_in_case):\n",
    "        \"\"\"Update the car's mileage.\"\"\"\n",
    "        if another_variable_in_case >= self.another_variable_in_case:\n",
    "            self.another_variable_in_case = another_variable_in_case\n",
    "        else:\n",
    "            print(\"Error: another_variable_in_case cannot be reduced.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pilot with Single Worm first before doing 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Basic set up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/worm_segmentation'\n",
    "video_path = current_location + '/sample.avi'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "motion_mask_cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "original_video_cap = cv2.VideoCapture('sample.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "f_worm_1 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "worm_1_out = cv2.VideoWriter(output_folder + '/worm_1_out.mp4', f_worm_1, frame_rate, (frame_width, frame_height), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loop through the first 1/10 of the video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames in the motion mask: 1202\n",
      "Total number of frames in the original video: 1202\n",
      "to process the video need to iterate over: 1202\n",
      "to process the video need to iterate over: 120\n"
     ]
    }
   ],
   "source": [
    "total_it_number = 0\n",
    "\n",
    "if not motion_mask_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(motion_mask_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the motion mask: {total_it_number}\")\n",
    "\n",
    "if not original_video_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(original_video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the original video: {total_it_number}\")\n",
    "\n",
    "print(f\"to process the video need to iterate over: {total_it_number}\")\n",
    "\n",
    "total_it_number = int(total_it_number / 10)\n",
    "\n",
    "print(f\"to process the video need to iterate over: {total_it_number}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "actually, construct the worm object before looping, that means, I need to make the first frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motion frame read\n",
      "Shape of Frame (2160, 2160, 3)\n",
      "First Row [[122 125 123]\n",
      " [122 125 123]\n",
      " [122 125 123]\n",
      " ...\n",
      " [122 125 123]\n",
      " [122 125 123]\n",
      " [122 125 123]]\n",
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Color Channels: 1\n",
      "Data Type: uint8\n",
      "Aspect Ratio: 1.0\n",
      "Color Space: Grayscale\n",
      "Shape of Frame (2160, 2160)\n",
      "First Row (2160,)\n"
     ]
    }
   ],
   "source": [
    "# Read the first motion\n",
    "ret, motion_frame_init = motion_mask_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the motion ask\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"motion frame read\")\n",
    "print(\"Shape of Frame\", motion_frame_init.shape)\n",
    "print(\"First Row\", motion_frame_init[:,1])\n",
    "previous_motion_frame = cv2.cvtColor(motion_frame_init, cv2.COLOR_BGR2GRAY)\n",
    "inspect_given_a_frame(previous_motion_frame)\n",
    "print(\"Shape of Frame\", previous_motion_frame.shape)\n",
    "print(\"First Row\", previous_motion_frame[:,1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "for worm initialization, let us analyze frame by frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels 20 \n",
      "\n",
      "labels [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "stats [[      0       0    2160    2160 3892687]\n",
      " [     59      11    1290     742  217899]\n",
      " [   1157      19     116      72    6481]\n",
      " ...\n",
      " [    223    1553    1687     535  347629]\n",
      " [    278    1614      76      76    5593]\n",
      " [    175    1622      57      60    3340]] \n",
      "\n",
      "centroids [[1097.18925077 1056.30238547]\n",
      " [ 637.53835493  294.37785396]\n",
      " [1213.91529085   54.33143033]\n",
      " [ 865.78622493   64.2190061 ]\n",
      " [1493.07880724  262.53887114]\n",
      " [1960.71808545  727.44079666]\n",
      " [ 758.97357724  821.72811132]\n",
      " [ 148.89168689  839.73988673]\n",
      " [1085.63219726  899.26891299]\n",
      " [ 836.11858407  956.59620733]\n",
      " [2026.1287264   964.47492953]\n",
      " [ 126.59711969  985.64298681]\n",
      " [ 501.42913001 1018.56304985]\n",
      " [1546.96204738 1177.76202156]\n",
      " [1978.63962196 1296.65338381]\n",
      " [ 555.16098081 1161.27078891]\n",
      " [1075.6705327  1314.63244551]\n",
      " [1079.36621513 1859.52991839]\n",
      " [ 315.59878419 1651.640801  ]\n",
      " [ 203.32005988 1651.22724551]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ret, current_motion_frame = motion_mask_cap.read()\n",
    "current_motion_frame = cv2.cvtColor(current_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "print('Number of labels', num_labels, '\\n')\n",
    "print('labels', labels, '\\n')\n",
    "print('stats', stats, '\\n')\n",
    "print('centroids', centroids, '\\n')\n",
    "min_area = 5000\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "previous_motion_frame = current_motion_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8409003\n",
      "Number of labels 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sum(sum(labels)))\n",
    "print('Number of labels', num_labels)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.imshow(labels, cmap='hot', interpolation='nearest')\n",
    "\n",
    "# Adding a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Adding titles and labels (optional)\n",
    "plt.title('Heatmap of a 2D NumPy Array')\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "let us look at next frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels 35 \n",
      "\n",
      "labels [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "stats [[      0       0    2160    2160 4023733]\n",
      " [    944      11      70      54    3661]\n",
      " [    986      25     323     195   32555]\n",
      " ...\n",
      " [    381    1644     204     209   27822]\n",
      " [    652    1888     210     118   15770]\n",
      " [    793    1998      45      45    2025]] \n",
      "\n",
      "centroids [[1078.6129015  1052.21719085]\n",
      " [ 978.28789948   37.2111445 ]\n",
      " [1141.87384426  134.53521732]\n",
      " ...\n",
      " [ 476.66389907 1733.55607074]\n",
      " [ 749.36689918 1942.67000634]\n",
      " [ 815.         2020.        ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ret, current_motion_frame = motion_mask_cap.read()\n",
    "current_motion_frame = cv2.cvtColor(current_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "print('Number of labels', num_labels, '\\n')\n",
    "print('labels', labels, '\\n')\n",
    "print('stats', stats, '\\n')\n",
    "print('centroids', centroids, '\\n')\n",
    "min_area = 5000\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "previous_motion_frame = current_motion_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14531526\n",
      "Number of labels 35\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sum(sum(labels)))\n",
    "print('Number of labels', num_labels)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.imshow(labels, cmap='hot', interpolation='nearest')\n",
    "\n",
    "# Adding a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Adding titles and labels (optional)\n",
    "plt.title('Heatmap of a 2D NumPy Array')\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "standard initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reset cap\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "# Read the first motion\n",
    "ret, motion_frame_init = motion_mask_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the motion ask\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"motion frame read\")\n",
    "print(\"Shape of Frame\", motion_frame_init.shape)\n",
    "print(\"First Row\", motion_frame_init[:,1])\n",
    "previous_motion_frame = cv2.cvtColor(motion_frame_init, cv2.COLOR_BGR2GRAY)\n",
    "inspect_given_a_frame(previous_motion_frame)\n",
    "print(\"Shape of Frame\", previous_motion_frame.shape)\n",
    "print(\"First Row\", previous_motion_frame[:,1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loop through the video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for j in range(total_it_number):\n",
    "    ret, temporal_motion_frame = motion_mask_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    current_motion_frame = cv2.cvtColor(temporal_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    print('Number of labels', num_labels, '\\n')\n",
    "    print('labels', labels, '\\n')\n",
    "    print('stats', stats, '\\n')\n",
    "    print('centroids', centroids, '\\n')\n",
    "    min_area = 5000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imshow('Segmented Frame', rgb_frame)\n",
    "    out.write(rgb_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cut to 1/4 of the original for easy processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 299"
     ]
    }
   ],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('shorter.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "for i in range(int(frame_count/4)):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    out.write(frame)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Background Subtraction, Spatial Smoothing, Temporal Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('shorter.mp4')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # You can also use 'XVID'\n",
    "out = cv2.VideoWriter('processed_v1.mp4', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "# Background subtractor\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "# Buffer for temporal smoothing\n",
    "buffer_size = 5\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Background subtraction\n",
    "    fgMask = backSub.apply(frame)\n",
    "    # Spatial smoothing (Gaussian blur)\n",
    "    blurred = cv2.GaussianBlur(fgMask, (5, 5), 0)\n",
    "    # Add frame to buffer for temporal smoothing\n",
    "    frame_buffer.append(blurred)\n",
    "    if len(frame_buffer) > buffer_size:\n",
    "        frame_buffer.pop(0)\n",
    "    # Temporal smoothing (average of frames in buffer)\n",
    "    temp_smoothed = np.mean(frame_buffer, axis=0).astype(np.uint8)\n",
    "    # Write frame to video\n",
    "    out.write(temp_smoothed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erode and Dilate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 300"
     ]
    }
   ],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('processed_v1.mp4')\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('processed_v2.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    # Read each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Apply erosion and then dilation\n",
    "    eroded_frame = cv2.erode(frame, kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, kernel, iterations=1)\n",
    "    # Display the processed frame\n",
    "    out.write(dilated_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    # Break the loop with a key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overlay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 299"
     ]
    }
   ],
   "source": [
    "original_cap = cv2.VideoCapture('shorter.mp4')\n",
    "cap = cv2.VideoCapture('processed_v2.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (75, 75))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('processed_v3.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "not_useful, ori_frame = original_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    not_useful, ori_frame = original_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    out.write(ori_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Worm Object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the squares overlap? True\n"
     ]
    }
   ],
   "source": [
    "def check_overlap(x1, y1, width1, height1, x2, y2, width2, height2):\n",
    "    # Check if one square is to the left of the other\n",
    "    if x1 + width1 <= x2 or x2 + width2 <= x1:\n",
    "        return False\n",
    "    # Check if one square is above the other\n",
    "    if y1 + height1 <= y2 or y2 + height2 <= y1:\n",
    "        return False\n",
    "    # If neither condition is true, squares must be overlapping\n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "x1, y1, width1, height1 = 10, 10, 30, 30  # Square 1\n",
    "x2, y2, width2, height2 = 20, 20, 30, 30  # Square 2\n",
    "\n",
    "overlap = check_overlap(x1, y1, width1, height1, x2, y2, width2, height2)\n",
    "print(\"Do the squares overlap?\", overlap)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "class Worm:\n",
    "    def __init__(self, worm_index, original_Cap, init_label, init_stats,init_centroid,another_variable_in_case=None):\n",
    "        self.worm_index = worm_index\n",
    "        self.original_cap = original_Cap\n",
    "        self.current_label = init_label\n",
    "        self.current_stats = init_stats\n",
    "        self.current_centroid = init_centroid\n",
    "        self.label_history = queue.Queue()\n",
    "        self.stats_history = queue.Queue()\n",
    "        self.centroid_history = queue.Queue()\n",
    "        self.another_variable_in_case = another_variable_in_case\n",
    "\n",
    "    def display_info(self):\n",
    "        info = f\"worn index: {self.worm_index}, video_cap: {self.original_cap}, label_history: {self.label_history}, stats_history: {self.stats_history}, centroid_history: {self.centroid_history}\"\n",
    "        print(info)\n",
    "\n",
    "    def update_another_variable(self, another_variable_in_case):\n",
    "        \"\"\"Update the car's mileage.\"\"\"\n",
    "        if another_variable_in_case >= self.another_variable_in_case:\n",
    "            self.another_variable_in_case = another_variable_in_case\n",
    "        else:\n",
    "            print(\"Error: another_variable_in_case cannot be reduced.\")\n",
    "\n",
    "    def take_the_bundle_in(self, bundle):\n",
    "\n",
    "        num_labels, labels, stats, centroids = bundle\n",
    "\n",
    "        # save the previous iteration\n",
    "        labels_modified = np.where(labels == self.current_label, self.current_label, 0)\n",
    "        self.label_history.put(labels_modified)\n",
    "        self.stats_history.put(self.current_stats)\n",
    "        self.centroid_history.put(self.current_centroid)\n",
    "\n",
    "        overlap_labels = queue.Queue()\n",
    "\n",
    "        # determine which one is the next label\n",
    "        for i in range(1, num_labels):\n",
    "            x, y, w, h, area = stats[i]\n",
    "            if area > min_area:\n",
    "                overlap_yes = check_overlap(x, y, w, h, self.current_stats[0], self.current_stats[1], self.current_stats[2], self.current_stats[3])\n",
    "                if overlap_yes:\n",
    "                    overlap_labels.put(i)\n",
    "\n",
    "        # find the closest centroid\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
