{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Computer Vision Algorithm for Tracking Planarian Motion\n",
    "developed by Hokin Deng xueqiandeng@yahoo.com"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Dependencies and Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import packages and make sure of the python technicality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.11.4 (main, Jul  5 2023, 08:41:25) [Clang 14.0.6 ]\n",
      "Python Executable: /Users/billdeng/anaconda3/envs/unlearning_Version1/bin/python\n",
      "Python Path: ['/Users/billdeng/PycharmProjects/unicellular', '/Users/billdeng/PycharmProjects/unicellular', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python311.zip', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11/lib-dynload', '', '/Users/billdeng/anaconda3/envs/unlearning_Version1/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "print(\"Python Version:\", sys.version)\n",
    "print(\"Python Executable:\", sys.executable)\n",
    "print(\"Python Path:\", sys.path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(threshold=50)\n",
    "import queue\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The video data should be named as \"sample.avi\" and put in the folder as the notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open a video file (replace 'sample.avi' with the path)\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "\n",
    "# Check if the video file was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display the video if want to have a look at it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#cv2.startWindowThread()\n",
    "# Loop to read and display frames\n",
    "#while True:\n",
    "    # Read a frame from the video\n",
    "#    ret, frame = cap.read()\n",
    "    # If the video has ended, break out of the loop\n",
    "#    if not ret:\n",
    "#        break\n",
    "    # Display the frame in a window\n",
    "#    cv2.imshow('Video', frame)\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "#    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#        break\n",
    "\n",
    "# Release the video capture object and close the window"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, get basic properties about our video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Count: 1202\n",
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Frame Rate: 10.0 frames per second\n",
      "Video Duration: 120.20 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get basic video properties\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "video_duration_sec = frame_count / frame_rate if frame_rate > 0 else 0\n",
    "\n",
    "# Print the video properties\n",
    "print(f\"Frame Count: {frame_count}\")\n",
    "print(f\"Frame Width: {frame_width}\")\n",
    "print(f\"Frame Height: {frame_height}\")\n",
    "print(f\"Frame Rate: {frame_rate} frames per second\")\n",
    "print(f\"Video Duration: {video_duration_sec:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret <class 'bool'>\n",
      "frame <class 'numpy.ndarray'>\n",
      "ret True\n",
      "frame [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "example_ret, example_frame = cap.read()\n",
    "print( 'ret', type(example_ret))\n",
    "print( 'frame', type(example_frame))\n",
    "print('ret', example_ret)\n",
    "print('frame', example_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# frame_number = 100  # The frame you want to access\n",
    "# Set the video position to the desired frame\n",
    "# cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)\n",
    "# Read the frame\n",
    "# ret, frame = cap.read()\n",
    "# if ret:\n",
    "    # Process the frame\n",
    "#     cv2.imshow('Frame 100', frame)\n",
    "#    cv2.waitKey(0)  # Wait for a key press to close the image window\n",
    "# else:\n",
    "#    print(\"Error: Unable to read the frame\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspect function for a frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def inspect_frame_from_video(cap_for_here, frame_number):\n",
    "    \"\"\"\n",
    "    Inspects a specific frame in a video.\n",
    "\n",
    "    :param cap_for_here: video reference\n",
    "    :param frame_number: The frame number to inspect (1-based index).\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Open the video file\n",
    "    if not cap_for_here.isOpened():\n",
    "        print(\"Error: Unable to open video file\")\n",
    "        return\n",
    "    # Check if the frame number is valid\n",
    "    total_frames = cap_for_here.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if frame_number < 1 or frame_number > total_frames:\n",
    "        print(f\"Frame number should be between 1 and {int(total_frames)}\")\n",
    "        return\n",
    "    # Set the video position to the desired frame (0-based index for frame_number)\n",
    "    cap_for_here.set(cv2.CAP_PROP_POS_FRAMES, frame_number - 1)\n",
    "    # Read the frame\n",
    "    ret_temp, frame_temp = cap_for_here.read()\n",
    "    if ret_temp:\n",
    "        # Display the frame\n",
    "        # cv2.imshow(f'Frame {frame_number}', frame)\n",
    "        # cv2.waitKey(0)  # Wait for a key press to close the image window\n",
    "        # cv2.destroyAllWindows()\n",
    "        frame_h, frame_w = frame_temp.shape[:2]\n",
    "        print(f\"Frame Width: {frame_h}\")\n",
    "        print(f\"Frame Height: {frame_w}\")\n",
    "        # Color Channels\n",
    "        channels = frame_temp.shape[2] if len(frame_temp.shape) == 3 else 1\n",
    "        print(f\"Color Channels: {channels}\")\n",
    "        # Data Type\n",
    "        data_type = frame_temp.dtype\n",
    "        print(f\"Data Type: {data_type}\")\n",
    "        # Aspect Ratio\n",
    "        aspect_ratio = frame_w / frame_h\n",
    "        print(f\"Aspect Ratio: {aspect_ratio}\")\n",
    "        # Resolution (assuming a standard display resolution of 96 PPI)\n",
    "        # Color Space (assuming default BGR)\n",
    "        color_space = \"BGR\" if channels == 3 else \"Grayscale\"\n",
    "        print(f\"Color Space: {color_space}\")\n",
    "        # Histogram for each channel\n",
    "        if channels > 1:\n",
    "            for i, col in enumerate(['Blue', 'Green', 'Red']):\n",
    "                hist = cv2.calcHist([frame_temp], [i], None, [256], [0, 256])\n",
    "                print(f\"Histogram for {col} channel: {np.array(hist).flatten()}\")\n",
    "        else:\n",
    "            hist = cv2.calcHist([frame_temp], [0], None, [256], [0, 256])\n",
    "            print(f\"Histogram for Grayscale: {np.array(hist).flatten()}\")\n",
    "    else:\n",
    "        print(\"Error: Unable to read the frame\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def inspect_given_a_frame(this_frame):\n",
    "    frame_h, frame_w = this_frame.shape[:2]\n",
    "    print(f\"Frame Width: {frame_h}\")\n",
    "    print(f\"Frame Height: {frame_w}\")\n",
    "    channels = this_frame.shape[2] if len(this_frame.shape) == 3 else 1\n",
    "    print(f\"Color Channels: {channels}\")\n",
    "    data_type = this_frame.dtype\n",
    "    print(f\"Data Type: {data_type}\")\n",
    "    aspect_ratio = frame_w / frame_h\n",
    "    print(f\"Aspect Ratio: {aspect_ratio}\")\n",
    "    color_space = \"BGR\" if channels == 3 else \"Grayscale\"\n",
    "    print(f\"Color Space: {color_space}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Color Channels: 3\n",
      "Data Type: uint8\n",
      "Aspect Ratio: 1.0\n",
      "Color Space: BGR\n",
      "Histogram for Blue channel: [      0.       0.       0. ...   31073.   57326. 3775011.]\n",
      "Histogram for Green channel: [      0.       0.       0. ...   31073.   57326. 3775011.]\n",
      "Histogram for Red channel: [      0.       0.       0. ...   31073.   57326. 3775011.]\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "video_file = 'sample.avi'\n",
    "frame_to_inspect = 100  # Adjust the frame number as needed\n",
    "inspect_frame_from_video(cap, frame_to_inspect)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Width: 2160\n",
      "Frame Height: 2160\n",
      "Color Channels: 3\n",
      "Data Type: uint8\n",
      "Aspect Ratio: 1.0\n",
      "Color Space: BGR\n"
     ]
    }
   ],
   "source": [
    "ret, frame_for_use = cap.read()\n",
    "inspect_given_a_frame(frame_for_use)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Processing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Background subtraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     13\u001B[0m     i \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 14\u001B[0m     ret, frame \u001B[38;5;241m=\u001B[39m cap\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ret:\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('background_remove.avi', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "while True:\n",
    "    i += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    fgMask = backSub.apply(frame)\n",
    "    out.write(fgMask)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spatial Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "cap = cv2.VideoCapture('background_remove.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('background_remove_spatial_smoothed.avi', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "while True:\n",
    "    i += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    out.write(blurred_frame)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Temporal Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('background_remove_spatial_smooth.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') # You can also use 'XVID'\n",
    "out = cv2.VideoWriter('b_r_s_s_t_s.avi', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "buffer_size = 5\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_buffer.append(frame)\n",
    "    if len(frame_buffer) > buffer_size:\n",
    "        frame_buffer.pop(0)\n",
    "    # Temporal smoothing (average of frames in buffer)\n",
    "    temp_smoothed = np.mean(frame_buffer, axis=0).astype(np.uint8)\n",
    "    # Write frame to video\n",
    "    out.write(temp_smoothed)\n",
    "    # Break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "do everything all at once"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # You can also use 'XVID'\n",
    "out = cv2.VideoWriter('pre_dense.mp4', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "# Background subtractor\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "# Buffer for temporal smoothing\n",
    "buffer_size = 5\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Background subtraction\n",
    "    fgMask = backSub.apply(frame)\n",
    "    # Spatial smoothing (Gaussian blur)\n",
    "    blurred = cv2.GaussianBlur(fgMask, (5, 5), 0)\n",
    "    # Add frame to buffer for temporal smoothing\n",
    "    frame_buffer.append(blurred)\n",
    "    if len(frame_buffer) > buffer_size:\n",
    "        frame_buffer.pop(0)\n",
    "    # Temporal smoothing (average of frames in buffer)\n",
    "    temp_smoothed = np.mean(frame_buffer, axis=0).astype(np.uint8)\n",
    "    # Write frame to video\n",
    "    out.write(temp_smoothed)\n",
    "    # Display result\n",
    "    # cv2.imshow('Frame', frame)\n",
    "    # cv2.imshow('FG Mask', fgMask)\n",
    "    # cv2.imshow('Blurred', blurred)\n",
    "    # cv2.imshow('Temporally Smoothed', temp_smoothed)\n",
    "    # Break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dense opti flow\n",
    "this takes a very very long time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"pre_dense.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('dense_opti_flow_v2.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "ret, first_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error reading first frame\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "mask = np.zeros_like(first_frame)\n",
    "mask[..., 1] = 255\n",
    "i = 0\n",
    "while True:\n",
    "    i += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    out.write(rgb)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    prev_gray = gray\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "segment each worm in dense optical flow video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('dense_opti_flow_v2.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('dense_opt_segmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 3  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(motion_mask), connectivity=8)\n",
    "    min_area = 50  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # Display the result\n",
    "    out.write(frame2)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "segment each worm without optical flow processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('pre_dense.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('predense_degmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 3  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(motion_mask), connectivity=8)\n",
    "    min_area = 50  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # Display the result\n",
    "    out.write(frame2)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a function for video to image and use it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to extract and save frames from a video file\n",
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/raw_images'\n",
    "video_path = current_location + '/sample.avi'\n",
    "\n",
    "def video2image(video_path, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Load the video\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Initialize frame count\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through video frames\n",
    "    while True:\n",
    "        # Read a frame\n",
    "        success, frame = video.read()\n",
    "        # Break if no frame is read (end of video)\n",
    "        if not success:\n",
    "            break\n",
    "        # Save the frame as an image\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"frame_{count}.jpg\"), frame)\n",
    "        # Increment frame count\n",
    "        count += 1\n",
    "\n",
    "    # Release the video object\n",
    "    video.release()\n",
    "\n",
    "    return count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the video into images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frame_count = video2image(video_path, output_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Design a crop function that remove the dish"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def crop_circle(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Create a mask with the same dimensions as the image\n",
    "    mask = np.zeros_like(image)\n",
    "    rows, cols, _ = mask.shape\n",
    "    # Compute the center and radius of the circle\n",
    "    center = (cols // 2, rows // 2)\n",
    "    radius = min(center[0], center[1], rows - center[1], cols - center[0])\n",
    "    # Draw the circular mask\n",
    "    cv2.circle(mask, center, radius, (255, 255, 255), -1)\n",
    "    # Apply the mask\n",
    "    circular_image = cv2.bitwise_and(image, mask)\n",
    "    # Optionally, you can remove the black background\n",
    "    masked_data = cv2.cvtColor(circular_image, cv2.COLOR_BGR2BGRA)\n",
    "    masked_data[mask == 0] = [0, 0, 0, 0]\n",
    "    # Save or display the result\n",
    "    cv2.imwrite('circular_image.png', masked_data)\n",
    "    # cv2.imshow('Circular Image', masked_data)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "threshold the original video and set the threshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thresh = 127"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "apply to original video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('threshold_original.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "# Read until video is completed\n",
    "j = 0\n",
    "while cap.isOpened():\n",
    "    j += 1\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Convert to grayscale\n",
    "        # Apply threshold for each channel\n",
    "        _, red_channel = cv2.threshold(frame[:,:,0], thresh, 255, cv2.THRESH_BINARY)\n",
    "        _, green_channel = cv2.threshold(frame[:,:,1], thresh, 255, cv2.THRESH_BINARY)\n",
    "        _, blue_channel = cv2.threshold(frame[:,:,2], thresh, 255, cv2.THRESH_BINARY)\n",
    "    # Combine the channels back\n",
    "        thresh_frame = cv2.merge([red_channel, green_channel, blue_channel])\n",
    "        # Display the resulting frame\n",
    "        out.write(thresh_frame)\n",
    "        # Press Q on keyboard to exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        print(f'\\rProgress: {j}', end='')\n",
    "    else:\n",
    "        break\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "apply erode and dilate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('pre_dense.mp4')\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Try 'XVID' if 'mp4v' does not work\n",
    "out = cv2.VideoWriter('pre_dense_erode_dilate.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    # Read each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Apply erosion and then dilation\n",
    "    eroded_frame = cv2.erode(frame, kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, kernel, iterations=1)\n",
    "    # Display the processed frame\n",
    "    out.write(dilated_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    # Break the loop with a key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "motion segmentation using connectivity after erode and dilate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('pre_dense_erode_dilate_segmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    cv2.imshow('Segmented Frame', motion_mask)\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(motion_mask), connectivity=8)\n",
    "    min_area = 300  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Display the result\n",
    "    out.write(frame2)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "erode and dilate also motion mask, save motion mask actually"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('motion_mask_segmented.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    save_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Display the result\n",
    "    rgb_frame = cv2.cvtColor(save_frame, cv2.COLOR_GRAY2RGB)\n",
    "    # inspect_given_a_frame(frame2)\n",
    "    # inspect_given_a_frame(rgb_frame)\n",
    "    out.write(save_frame)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('motion_mask_segmented_v2.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # Segment mask based on connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300  # Minimum area for connected components\n",
    "    # Draw bounding boxes around components\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    t_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    # cv2.imshow('Segmented Frame', dilated_frame)\n",
    "    # cv2.imshow('Segmented Frame', frame2)\n",
    "    # Display the result\n",
    "    rgb_frame = cv2.cvtColor(t_frame, cv2.COLOR_GRAY2RGB)\n",
    "    # inspect_given_a_frame(frame2)\n",
    "    # inspect_given_a_frame(rgb_frame)\n",
    "    # inspect_given_a_frame(rgb_frame)\n",
    "    out.write(rgb_frame)\n",
    "    # Update previous frame\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dilate even more for segmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overlay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_cap = cv2.VideoCapture('sample.avi')\n",
    "cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('overlay.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "not_useful, ori_frame = original_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    not_useful, ori_frame = original_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    out.write(ori_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize Paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/worm_segmentation'\n",
    "video_path = current_location + '/sample.avi'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize input videos and output videos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "motion_mask_cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "original_video_cap = cv2.VideoCapture('sample.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "f_worm_1 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_2 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_3 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_4 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_5 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_6 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_7 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_8 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_9 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "f_worm_10 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "worm_1_out = cv2.VideoWriter(output_folder + '/worm_1_out.mp4', f_worm_1, frame_rate, (frame_width, frame_height), True)\n",
    "worm_2_out = cv2.VideoWriter(output_folder + '/worm_2_out.mp4', f_worm_2, frame_rate, (frame_width, frame_height), True)\n",
    "worm_3_out = cv2.VideoWriter(output_folder + '/worm_3_out.mp4', f_worm_3, frame_rate, (frame_width, frame_height), True)\n",
    "worm_4_out = cv2.VideoWriter(output_folder + '/worm_4_out.mp4', f_worm_4, frame_rate, (frame_width, frame_height), True)\n",
    "worm_5_out = cv2.VideoWriter(output_folder + '/worm_5_out.mp4', f_worm_5, frame_rate, (frame_width, frame_height), True)\n",
    "worm_6_out = cv2.VideoWriter(output_folder + '/worm_6_out.mp4', f_worm_6, frame_rate, (frame_width, frame_height), True)\n",
    "worm_7_out = cv2.VideoWriter(output_folder + '/worm_7_out.mp4', f_worm_7, frame_rate, (frame_width, frame_height), True)\n",
    "worm_8_out = cv2.VideoWriter(output_folder + '/worm_8_out.mp4', f_worm_8, frame_rate, (frame_width, frame_height), True)\n",
    "worm_9_out = cv2.VideoWriter(output_folder + '/worm_9_out.mp4', f_worm_9, frame_rate, (frame_width, frame_height), True)\n",
    "worm_10_out = cv2.VideoWriter(output_folder + '/worm_10_out.mp4', f_worm_10, frame_rate, (frame_width, frame_height), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "clean up make sure all number is good"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_it_number = 0\n",
    "\n",
    "if not motion_mask_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(motion_mask_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the motion mask: {total_it_number}\")\n",
    "\n",
    "if not original_video_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(original_video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the original video: {total_it_number}\")\n",
    "\n",
    "print(f\"to process the video need to iterate over: {total_it_number}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the first motion\n",
    "ret, motion_frame_init = motion_mask_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the motion ask\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"motion frame read\")\n",
    "print(\"Shape of Frame\", motion_frame_init.shape)\n",
    "print(\"First Row\", motion_frame_init[:,1])\n",
    "previous_motion_frame = cv2.cvtColor(motion_frame_init, cv2.COLOR_BGR2GRAY)\n",
    "inspect_given_a_frame(previous_motion_frame)\n",
    "print(\"Shape of Frame\", previous_motion_frame.shape)\n",
    "print(\"First Row\", previous_motion_frame[:,1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pilot the code a bit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for j in range(total_it_number):\n",
    "    ret, temporal_motion_frame = motion_mask_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    current_motion_frame = cv2.cvtColor(temporal_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    print('Number of labels', num_labels, '\\n')\n",
    "    print('labels', labels, '\\n')\n",
    "    print('stats', stats, '\\n')\n",
    "    print('centroids', centroids, '\\n')\n",
    "    min_area = 5000\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imshow('Segmented Frame', rgb_frame)\n",
    "    out.write(rgb_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tye = num_labels, labels, stats, centroids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_la, la, st, cent = tye"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(num_la))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(centroids[2][0])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(st)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(st[1][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(centroids.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats_2 = stats\n",
    "print(stats_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hum = stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hum = np.append(hum, stats_2)\n",
    "print(hum)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "make an object array and work with that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hum = np.array(None,dtype=object)\n",
    "print(hum)\n",
    "hum = np.append(hum, stats_2)\n",
    "print(hum)\n",
    "hum = np.append(hum, stats_2)\n",
    "print(hum)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tye[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tye[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tye[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tye[3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Construction of a Worm Object\n",
    "## the idea is that, to make a worm object, this object should be able to take each frame as input,\n",
    "## find the motion mask to correspond to the worm, and append to the worm object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Worm:\n",
    "    def __init__(self, worm_index, original_cap, label_history, stats_history, centroid_history, another_variable_in_case=None):\n",
    "        self.worm_index = worm_index\n",
    "        self.original_cap = original_cap\n",
    "        self.label_history = label_history\n",
    "        self.stats_history = stats_history\n",
    "        self.centroid_history = centroid_history\n",
    "        self.another_variable_in_case = another_variable_in_case\n",
    "\n",
    "    def display_info(self):\n",
    "        info = f\"worn index: {self.worm_index}, video_cap: {self.original_cap}, label_history: {self.label_history}, stats_history: {self.stats_history}, centroid_history: {self.centroid_history}\"\n",
    "        print(info)\n",
    "\n",
    "    def update_another_variable(self, another_variable_in_case):\n",
    "        \"\"\"Update the car's mileage.\"\"\"\n",
    "        if another_variable_in_case >= self.another_variable_in_case:\n",
    "            self.another_variable_in_case = another_variable_in_case\n",
    "        else:\n",
    "            print(\"Error: another_variable_in_case cannot be reduced.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pilot with Single Worm first before doing 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Basic set up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/worm_segmentation'\n",
    "video_path = current_location + '/sample.avi'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "motion_mask_cap = cv2.VideoCapture('pre_dense_erode_dilate.mp4')\n",
    "original_video_cap = cv2.VideoCapture('sample.avi')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (45, 45))\n",
    "f_worm_1 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "worm_1_out = cv2.VideoWriter(output_folder + '/worm_1_out.mp4', f_worm_1, frame_rate, (frame_width, frame_height), True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loop through the first 1/10 of the video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_it_number = 0\n",
    "\n",
    "if not motion_mask_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(motion_mask_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the motion mask: {total_it_number}\")\n",
    "\n",
    "if not original_video_cap.isOpened():\n",
    "    print(\"Error: Could not open motion mask.\")\n",
    "else:\n",
    "    # Get the total number of frames in the video\n",
    "    total_it_number = int(original_video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in the original video: {total_it_number}\")\n",
    "\n",
    "print(f\"to process the video need to iterate over: {total_it_number}\")\n",
    "\n",
    "total_it_number = int(total_it_number / 10)\n",
    "\n",
    "print(f\"to process the video need to iterate over: {total_it_number}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "actually, construct the worm object before looping, that means, I need to make the first frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the first motion\n",
    "ret, motion_frame_init = motion_mask_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the motion ask\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"motion frame read\")\n",
    "print(\"Shape of Frame\", motion_frame_init.shape)\n",
    "print(\"First Row\", motion_frame_init[:,1])\n",
    "previous_motion_frame = cv2.cvtColor(motion_frame_init, cv2.COLOR_BGR2GRAY)\n",
    "inspect_given_a_frame(previous_motion_frame)\n",
    "print(\"Shape of Frame\", previous_motion_frame.shape)\n",
    "print(\"First Row\", previous_motion_frame[:,1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "for worm initialization, let us analyze frame by frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ret, current_motion_frame = motion_mask_cap.read()\n",
    "current_motion_frame = cv2.cvtColor(current_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "print('Number of labels', num_labels, '\\n')\n",
    "print('labels', labels, '\\n')\n",
    "print('stats', stats, '\\n')\n",
    "print('centroids', centroids, '\\n')\n",
    "min_area = 5000\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "previous_motion_frame = current_motion_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sum(sum(labels)))\n",
    "print('Number of labels', num_labels)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.imshow(labels, cmap='hot', interpolation='nearest')\n",
    "\n",
    "# Adding a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Adding titles and labels (optional)\n",
    "plt.title('Heatmap of a 2D NumPy Array')\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "let us look at next frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ret, current_motion_frame = motion_mask_cap.read()\n",
    "current_motion_frame = cv2.cvtColor(current_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "print('Number of labels', num_labels, '\\n')\n",
    "print('labels', labels, '\\n')\n",
    "print('stats', stats, '\\n')\n",
    "print('centroids', centroids, '\\n')\n",
    "min_area = 5000\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "previous_motion_frame = current_motion_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sum(sum(labels)))\n",
    "print('Number of labels', num_labels)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.imshow(labels, cmap='hot', interpolation='nearest')\n",
    "\n",
    "# Adding a colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Adding titles and labels (optional)\n",
    "plt.title('Heatmap of a 2D NumPy Array')\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "standard initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reset cap\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "# Read the first motion\n",
    "ret, motion_frame_init = motion_mask_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the motion ask\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"motion frame read\")\n",
    "print(\"Shape of Frame\", motion_frame_init.shape)\n",
    "print(\"First Row\", motion_frame_init[:,1])\n",
    "previous_motion_frame = cv2.cvtColor(motion_frame_init, cv2.COLOR_BGR2GRAY)\n",
    "inspect_given_a_frame(previous_motion_frame)\n",
    "print(\"Shape of Frame\", previous_motion_frame.shape)\n",
    "print(\"First Row\", previous_motion_frame[:,1].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loop through the video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for j in range(total_it_number):\n",
    "    ret, temporal_motion_frame = motion_mask_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    current_motion_frame = cv2.cvtColor(temporal_motion_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous_motion_frame, current_motion_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    print('Number of labels', num_labels, '\\n')\n",
    "    print('labels', labels, '\\n')\n",
    "    print('stats', stats, '\\n')\n",
    "    print('centroids', centroids, '\\n')\n",
    "    min_area = 5000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imshow('Segmented Frame', rgb_frame)\n",
    "    out.write(rgb_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cut to 1/4 of the original for easy processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('sample.avi')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('shorter.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "for i in range(int(frame_count/4)):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    out.write(frame)\n",
    "    print(f'\\rProgress: {i}', end='')\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Background Subtraction, Spatial Smoothing, Temporal Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('shorter.mp4')\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # You can also use 'XVID'\n",
    "out = cv2.VideoWriter('processed_v1.mp4', fourcc, frame_rate, (frame_width, frame_height), False)\n",
    "# Background subtractor\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "# Buffer for temporal smoothing\n",
    "buffer_size = 5\n",
    "frame_buffer = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Background subtraction\n",
    "    fgMask = backSub.apply(frame)\n",
    "    # Spatial smoothing (Gaussian blur)\n",
    "    blurred = cv2.GaussianBlur(fgMask, (5, 5), 0)\n",
    "    # Add frame to buffer for temporal smoothing\n",
    "    frame_buffer.append(blurred)\n",
    "    if len(frame_buffer) > buffer_size:\n",
    "        frame_buffer.pop(0)\n",
    "    # Temporal smoothing (average of frames in buffer)\n",
    "    temp_smoothed = np.mean(frame_buffer, axis=0).astype(np.uint8)\n",
    "    # Write frame to video\n",
    "    out.write(temp_smoothed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Erode and Dilate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the video\n",
    "cap = cv2.VideoCapture('processed_v1.mp4')\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('processed_v2.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    # Read each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Apply erosion and then dilation\n",
    "    eroded_frame = cv2.erode(frame, kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, kernel, iterations=1)\n",
    "    # Display the processed frame\n",
    "    out.write(dilated_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    # Break the loop with a key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overlay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_cap = cv2.VideoCapture('shorter.mp4')\n",
    "cap = cv2.VideoCapture('processed_v2.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (75, 75))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('processed_v3.mp4', fourcc, frame_rate, (frame_width, frame_height), True)\n",
    "# Read the first frame\n",
    "ret, frame1 = cap.read()\n",
    "not_useful, ori_frame = original_cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read video\")\n",
    "    cap.release()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "j = 0\n",
    "while True:\n",
    "    j += 1\n",
    "    ret, frame2 = cap.read()\n",
    "    not_useful, ori_frame = original_cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate Optical Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    # Compute magnitude and angle of the flow\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Create motion mask\n",
    "    thresh = 1  # Set threshold for motion detection\n",
    "    motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "    dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "    min_area = 300\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    for i in range(1, num_labels):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "    temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "    out.write(ori_frame)\n",
    "    print(f'\\rProgress: {j}', end='')\n",
    "    prvs = next\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Worm Object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make Minimum Area a Global Parameter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "min_area = 2000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the squares overlap? True\n"
     ]
    }
   ],
   "source": [
    "def check_overlap(x1, y1, width1, height1, x2, y2, width2, height2):\n",
    "    # Check if one square is to the left of the other\n",
    "    if x1 + width1 <= x2 or x2 + width2 <= x1:\n",
    "        return False\n",
    "    # Check if one square is above the other\n",
    "    if y1 + height1 <= y2 or y2 + height2 <= y1:\n",
    "        return False\n",
    "    # If neither condition is true, squares must be overlapping\n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "x1, y1, width1, height1 = 10, 10, 30, 30  # Square 1\n",
    "x2, y2, width2, height2 = 20, 20, 30, 30  # Square 2\n",
    "\n",
    "overlap = check_overlap(x1, y1, width1, height1, x2, y2, width2, height2)\n",
    "print(\"Do the squares overlap?\", overlap)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2nd item in the queue is: item2\n"
     ]
    }
   ],
   "source": [
    "def get_nth_item(q, n):\n",
    "    if n >= q.qsize():\n",
    "        return None  # or raise an exception if you prefer\n",
    "\n",
    "    for _ in range(n - 1):\n",
    "        q.get()\n",
    "\n",
    "    nth_item = q.get()\n",
    "    return nth_item\n",
    "\n",
    "# Example\n",
    "q = queue.Queue()\n",
    "q.put('item1')\n",
    "q.put('item2')\n",
    "q.put('item3')\n",
    "\n",
    "nth_item = get_nth_item(q, 2)  # Get the 2nd item\n",
    "print(\"The 2nd item in the queue is:\", nth_item)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the points is: 5.0\n"
     ]
    }
   ],
   "source": [
    "def distance_between_points(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "# Example usage\n",
    "x1, y1 = 1, 2\n",
    "x2, y2 = 4, 6\n",
    "distance = distance_between_points(x1, y1, x2, y2)\n",
    "print(\"The distance between the points is:\", distance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def white_outside_rectangle(fra, x, y, width, height):\n",
    "    \"\"\"\n",
    "    Makes everything outside a specified rectangle in the frame purely white.\n",
    "    :param fra: The original image/frame.\n",
    "    :param x: The x-coordinate of the top-left corner of the rectangle.\n",
    "    :param y: The y-coordinate of the top-left corner of the rectangle.\n",
    "    :param width: The width of the rectangle.\n",
    "    :param height: The height of the rectangle.\n",
    "    :return: Modified frame with white outside the specified rectangle.\n",
    "    \"\"\"\n",
    "    # Make a copy of the frame\n",
    "    modified_frame = np.copy(fra)\n",
    "    # Draw white rectangles over the areas outside the specified rectangle\n",
    "    # Top\n",
    "    modified_frame[0:y, :] = 255\n",
    "    # Bottom\n",
    "    modified_frame[y+height:fra.shape[0], :] = 255\n",
    "    # Left\n",
    "    modified_frame[:, 0:x] = 255\n",
    "    # Right\n",
    "    modified_frame[:, x+width:fra.shape[1]] = 255\n",
    "    return modified_frame\n",
    "# Example usage\n",
    "# frame = cv2.imread('path_to_your_image.jpg')  # Load your frame or image\n",
    "# modified_frame = white_outside_rectangle(frame, 50, 50, 100, 100)\n",
    "# cv2.imshow('Modified Frame', modified_frame)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "current_location = os.getcwd();\n",
    "output_folder = current_location + '/pilot_images'\n",
    "monitor_folder = current_location + '/monitor_images'\n",
    "video_path = current_location + '/sample.avi'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "if not os.path.exists(monitor_folder):\n",
    "    os.makedirs(monitor_folder)\n",
    "\n",
    "class Worm:\n",
    "    def __init__(self, worm_index, original_Cap, init_label, init_stats,init_centroid,another_variable_in_case=None):\n",
    "        self.worm_index = worm_index\n",
    "        self.original_cap = original_Cap\n",
    "        self.current_label = init_label\n",
    "        self.current_stats = init_stats\n",
    "        self.current_centroid = init_centroid\n",
    "        self.label_history = queue.Queue()\n",
    "        self.stats_history = queue.Queue()\n",
    "        self.centroid_history = queue.Queue()\n",
    "        self.another_variable_in_case = another_variable_in_case\n",
    "        # also establish the output flow\n",
    "        self.frame_width = int(original_Cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.frame_height = int(original_Cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.frame_rate = original_Cap.get(cv2.CAP_PROP_FPS)\n",
    "        cur_location = os.getcwd()\n",
    "        text = '/worm_' + str(worm_index)\n",
    "        self.output_folder = cur_location + text\n",
    "        if not os.path.exists(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "\n",
    "    def display_info(self):\n",
    "        info = f\"worn index: {self.worm_index}, video_cap: {self.original_cap}, label_history: {self.label_history}, stats_history: {self.stats_history}, centroid_history: {self.centroid_history}, \\n\"\n",
    "        print(info)\n",
    "        info = f\"current label: {self.current_label}, current_stats: {self.current_stats}, current_centroid: {self.current_centroid}, stats_history: {self.stats_history}, centroid_history: {self.centroid_history}, \\n\"\n",
    "        print(info)\n",
    "        print('Current Stats \\n')\n",
    "        print(self.current_stats)\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('Current Label \\n')\n",
    "        print(self.current_label)\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('Current Centroid\\n')\n",
    "        print(self.current_centroid)\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "\n",
    "    def update_another_variable(self, another_variable_in_case):\n",
    "        \"\"\"Update the car's mileage.\"\"\"\n",
    "        if another_variable_in_case >= self.another_variable_in_case:\n",
    "            self.another_variable_in_case = another_variable_in_case\n",
    "        else:\n",
    "            print(\"Error: another_variable_in_case cannot be reduced.\")\n",
    "\n",
    "    def take_the_bundle_in(self, bundle):\n",
    "        num_labels, labels, stats, centroids = bundle\n",
    "        # save the previous iteration\n",
    "        labels_modified = np.where(labels == self.current_label, self.current_label, 0)\n",
    "        self.label_history.put(labels_modified)\n",
    "        self.stats_history.put(self.current_stats)\n",
    "        self.centroid_history.put(self.current_centroid)\n",
    "        overlap_labels = queue.Queue()\n",
    "        # determine which one is the next label\n",
    "        for i in range(1, num_labels):\n",
    "            x, y, w, h, area = stats[i]\n",
    "            if area > min_area:\n",
    "                overlap_yes = check_overlap(x, y, w, h, self.current_stats[0], self.current_stats[1], self.current_stats[2], self.current_stats[3])\n",
    "                if overlap_yes:\n",
    "                    overlap_labels.put(i)\n",
    "        # find the closest centroid\n",
    "        centroid_distance = 10000000000 # first assume that the two centroids are very far away\n",
    "        best_label = -1 # let us not know which one is the best label at the beginning\n",
    "        for j in range(overlap_labels.qsize()):\n",
    "            this_label_selected = get_nth_item(overlap_labels, j)\n",
    "            this_centroid = centroids[this_label_selected]\n",
    "            this_distance = distance_between_points(this_centroid[0], this_centroid[1], self.current_centroid[0], self.current_centroid[1])\n",
    "            if this_distance < centroid_distance:\n",
    "                centroid_distance = this_distance\n",
    "                best_label = this_label_selected\n",
    "        # update the current frame\n",
    "        if best_label == -1: # make sure some labels are selected\n",
    "            print('No Criterion satisfied, jump to the nearest frame')\n",
    "        self.current_label = best_label\n",
    "        self.current_stats = stats[best_label]\n",
    "        self.current_centroid = centroids[best_label]\n",
    "\n",
    "    def write_frame(self, n_th_frame):\n",
    "        self.original_cap.set(cv2.CAP_PROP_POS_FRAMES, n_th_frame)\n",
    "        get, this_frame = original_cap.read()\n",
    "        if not get:\n",
    "            print('something wrong happened')\n",
    "        x, y, w, h, area = self.current_stats\n",
    "        cv2.rectangle(this_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        this_frame = white_outside_rectangle(this_frame, x, y, w, h)\n",
    "        cv2.imwrite(os.path.join(self.output_folder, f\"frame_{n_th_frame}.jpg\"), this_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Frame-by-frame processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the First Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_cap = cv2.VideoCapture('shorter.mp4')\n",
    "\n",
    "cap = cv2.VideoCapture('processed_v2.mp4')\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (75, 75))\n",
    "\n",
    "# Read the first frame\n",
    "ret1, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{1}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{1}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the Second Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{2}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{2}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the Third Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{3}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{3}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Up the First Worm Object: Worm_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 4, video_cap: < cv2.VideoCapture 0x12afe09f0>, label_history: <queue.Queue object at 0x12affca50>, stats_history: <queue.Queue object at 0x12affdb50>, centroid_history: <queue.Queue object at 0x12afffb50>, \n",
      "\n",
      "current label: 4, current_stats: [1010  120   86   87 7454], current_centroid: [1052.49946338  163.04292997], stats_history: <queue.Queue object at 0x12affdb50>, centroid_history: <queue.Queue object at 0x12afffb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1010  120   86   87 7454]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1052.49946338  163.04292997]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worm_1 = Worm(4, original_cap, 4, stats[4], centroids[4])\n",
    "worm_1.display_info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process the Fourth Frame and take the bundle in by the Worm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "bundle = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "worm_1.take_the_bundle_in(bundle)\n",
    "worm_1.write_frame(4)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{4}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{4}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 4, video_cap: < cv2.VideoCapture 0x12afe09f0>, label_history: <queue.Queue object at 0x12affca50>, stats_history: <queue.Queue object at 0x12affdb50>, centroid_history: <queue.Queue object at 0x12afffb50>, \n",
      "\n",
      "current label: 1, current_stats: [ 1026   117   210    97 18763], current_centroid: [1129.28305708  165.21739594], stats_history: <queue.Queue object at 0x12affdb50>, centroid_history: <queue.Queue object at 0x12afffb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[ 1026   117   210    97 18763]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1129.28305708  165.21739594]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/Users/billdeng/PycharmProjects/unicellular/worm_4\n"
     ]
    }
   ],
   "source": [
    "worm_1.display_info()\n",
    "print(worm_1.output_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Proceed to the Fifth Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "bundle = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "worm_1.take_the_bundle_in(bundle)\n",
    "worm_1.write_frame(5)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{5}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{5}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 4, video_cap: < cv2.VideoCapture 0x12afe09f0>, label_history: <queue.Queue object at 0x12affca50>, stats_history: <queue.Queue object at 0x12affdb50>, centroid_history: <queue.Queue object at 0x12afffb50>, \n",
      "\n",
      "current label: 1, current_stats: [1027  119   88   86 7537], current_centroid: [1070.38675866  161.48401221], stats_history: <queue.Queue object at 0x12affdb50>, centroid_history: <queue.Queue object at 0x12afffb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[1027  119   88   86 7537]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[1070.38675866  161.48401221]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/Users/billdeng/PycharmProjects/unicellular/worm_4\n"
     ]
    }
   ],
   "source": [
    "worm_1.display_info()\n",
    "print(worm_1.output_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Proceed to the Sixth Frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something is wrong: no labels are selected\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the second frame\n",
    "ret2, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "# Read the original frame\n",
    "ret3, ori_frame = original_cap.read()\n",
    "\n",
    "# Calculate Optical Flow\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "# Compute magnitude and angle of the flow\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "# Create motion mask\n",
    "thresh = 1  # Set threshold for motion detection\n",
    "motion_mask = cv2.threshold(mag, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "eroded_frame = cv2.erode(motion_mask, erode_kernel, iterations=1)\n",
    "dilated_frame = cv2.dilate(eroded_frame, dilate_kernel, iterations=1)\n",
    "bundle = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(np.uint8(dilated_frame), connectivity=8)\n",
    "worm_1.take_the_bundle_in(bundle)\n",
    "worm_1.write_frame(6)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(dilated_frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "for i in range(1, num_labels):\n",
    "    x, y, w, h, area = stats[i]\n",
    "    if area > min_area:\n",
    "        cv2.rectangle(ori_frame, (x, y), (x + w, y + h), (250,128,114), 2)\n",
    "temp_frame = cv2.normalize(dilated_frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_GRAY2RGB)\n",
    "prvs = next\n",
    "cv2.imwrite(os.path.join(monitor_folder, f\"frame_{6}.jpg\"), rgb_frame)\n",
    "cv2.imwrite(os.path.join(output_folder, f\"frame_{6}.jpg\"), ori_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worn index: 4, video_cap: < cv2.VideoCapture 0x12afe09f0>, label_history: <queue.Queue object at 0x12affca50>, stats_history: <queue.Queue object at 0x12affdb50>, centroid_history: <queue.Queue object at 0x12afffb50>, \n",
      "\n",
      "current label: -1, current_stats: [  385  1627   223   232 41013], current_centroid: [ 487.40562748 1729.43593495], stats_history: <queue.Queue object at 0x12affdb50>, centroid_history: <queue.Queue object at 0x12afffb50>, \n",
      "\n",
      "Current Stats \n",
      "\n",
      "[  385  1627   223   232 41013]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Label \n",
      "\n",
      "-1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Current Centroid\n",
      "\n",
      "[ 487.40562748 1729.43593495]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/Users/billdeng/PycharmProjects/unicellular/worm_4\n"
     ]
    }
   ],
   "source": [
    "worm_1.display_info()\n",
    "print(worm_1.output_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
